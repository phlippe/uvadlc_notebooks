{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2: Introduction to PyTorch\n",
    "\n",
    "![Status](https://img.shields.io/static/v1.svg?label=Status&message=Finished&color=green)\n",
    "\n",
    "**Filled notebook:** \n",
    "[![View filled on Github](https://img.shields.io/static/v1.svg?logo=github&label=Repo&message=View%20On%20Github&color=lightgrey)](https://github.com/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial2/Introduction_to_PyTorch.ipynb)\n",
    "[![Open filled In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial2/Introduction_to_PyTorch.ipynb)  \n",
    "**Empty notebook:** \n",
    "[![View empty on Github](https://img.shields.io/static/v1.svg?logo=github&label=Repo&message=View%20On%20Github&color=lightgrey)](https://github.com/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial2/Introduction_to_PyTorch_empty.ipynb)\n",
    "[![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial2/Introduction_to_PyTorch_empty.ipynb)  \n",
    "**Recordings:** \n",
    "[![YouTube - Part 1](https://img.shields.io/static/v1.svg?logo=youtube&label=YouTube&message=Part%201&color=red)](https://youtu.be/wnKZZgFQY-E)\n",
    "[![YouTube - Part 2](https://img.shields.io/static/v1.svg?logo=youtube&label=YouTube&message=Part%202&color=red)](https://youtu.be/schbjeU5X2g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to our PyTorch tutorial for the Deep Learning course 2020 at the University of Amsterdam! The following notebook is meant to give a short introduction to PyTorch basics, and get you setup for writing your own neural networks. PyTorch is an open source machine learning framework that allows you to write your own neural networks and optimize them efficiently. However, PyTorch is not the only framework of its kind. Alternatives to PyTorch include [TensorFlow](https://www.tensorflow.org/), [JAX](https://github.com/google/jax#quickstart-colab-in-the-cloud) and [Caffe](http://caffe.berkeleyvision.org/). We choose to teach PyTorch at the University of Amsterdam because it is well established, has a huge developer community (originally developed by Facebook), is very flexible and especially used in research. Many current papers publish their code in PyTorch, and thus it is good to be familiar with PyTorch as well. \n",
    "Meanwhile, TensorFlow (developed by Google) is usually known for being a production-grade deep learning library. Still, if you know one machine learning framework in depth, it is very easy to learn another one because many of them use the same concepts and ideas. For instance, TensorFlow's version 2 was heavily inspired by the most popular features of PyTorch, making the frameworks even more similar. \n",
    "If you are already familiar with PyTorch and have created your own neural network projects, feel free to just skim this notebook.\n",
    "\n",
    "We are of course not the first ones to create a PyTorch tutorial. There are many great tutorials online, including the [\"60-min blitz\"](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html) on the official [PyTorch website](https://pytorch.org/tutorials/). Yet, we choose to create our own tutorial which is designed to give you the basics particularly necessary for the practicals, but still understand how PyTorch works under the hood. Over the next few weeks, we will also keep exploring new PyTorch features in the series of Jupyter notebook tutorials about deep learning. \n",
    "\n",
    "We will use a set of standard libraries that are often used in machine learning projects. If you are running this notebook on Google Colab, all libraries should be pre-installed. If you are running this notebook locally, make sure you have installed our `dl2020` environment and have activated it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import math\n",
    "import numpy as np \n",
    "import time\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "from matplotlib.colors import to_rgba\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "## Progress bar\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Basics of PyTorch\n",
    "\n",
    "We will start with reviewing the very basic concepts of PyTorch. As a prerequisite, we recommend to be familiar with the `numpy` package as most machine learning frameworks are based on very similar concepts. If you are not familiar with numpy yet, don't worry: here is a [tutorial](https://numpy.org/devdocs/user/quickstart.html) to go through. \n",
    "\n",
    "So, let's start with importing PyTorch. The package is called `torch`, based on its original framework [Torch](http://torch.ch/). As a first step, we can check its version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using torch 1.9.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Using torch\", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the time of writing this tutorial (mid of August 2021), the current stable version is 1.9. You should therefore see the output `Using torch 1.9.0`, eventually with some extension for the CUDA version on Colab. In case you use the `dl2020` environment, you should see `Using torch 1.6.0` since the environment was provided in October 2020. It is recommended to update the PyTorch version to the newest one. If you see a lower version number than 1.6, make sure you have installed the correct the environment, or ask one of your TAs. In case PyTorch 1.10 or newer will be published during the time of the course, don't worry. The interface between PyTorch versions doesn't change too much, and hence all code should also be runnable with newer versions.\n",
    "\n",
    "As in every machine learning framework, PyTorch provides functions that are stochastic like generating random numbers. However, a very good practice is to setup your code to be reproducible with the exact same random numbers. This is why we set a seed below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f785df1a480>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42) # Setting the seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors\n",
    "\n",
    "Tensors are the PyTorch equivalent to Numpy arrays, with the addition to also have support for GPU acceleration (more on that later).\n",
    "The name \"tensor\" is a generalization of concepts you already know. For instance, a vector is a 1-D tensor, and a matrix a 2-D tensor. When working with neural networks, we will use tensors of various shapes and number of dimensions.\n",
    "\n",
    "Most common functions you know from numpy can be used on tensors as well. Actually, since numpy arrays are so similar to tensors, we can convert most tensors to numpy arrays (and back) but we don't need it too often.\n",
    "\n",
    "#### Initialization\n",
    "\n",
    "Let's first start by looking at different ways of creating a tensor. There are many possible options, the most simple one is to call `torch.Tensor` passing the desired shape as input argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.0949e-32, 1.3563e-19, 1.7589e+22, 1.2412e+28],\n",
      "         [6.6830e+22, 1.7199e+11, 4.8617e+30, 1.8499e+20],\n",
      "         [1.5265e-19, 2.0702e-19, 1.0951e+21, 2.0339e+32]],\n",
      "\n",
      "        [[1.9346e-19, 1.2711e+31, 1.9346e-19, 1.9432e-19],\n",
      "         [4.5317e-11, 1.3563e-19, 2.1973e-18, 1.3563e-19],\n",
      "         [6.7722e+22, 1.6020e-19, 2.6563e+20, 1.7613e+19]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(2, 3, 4)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `torch.Tensor` allocates memory for the desired tensor, but reuses any values that have already been in the memory. To directly assign values to the tensor during initialization, there are many alternatives including:\n",
    "\n",
    "* `torch.zeros`: Creates a tensor filled with zeros\n",
    "* `torch.ones`: Creates a tensor filled with ones\n",
    "* `torch.rand`: Creates a tensor with random values uniformly sampled between 0 and 1\n",
    "* `torch.randn`: Creates a tensor with random values sampled from a normal distribution with mean 0 and variance 1\n",
    "* `torch.arange`: Creates a tensor containing the values $N,N+1,N+2,...,M$\n",
    "* `torch.Tensor` (input list): Creates a tensor from the list elements you provide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor from a (nested) list\n",
    "x = torch.Tensor([[1, 2], [3, 4]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "         [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "         [0.9408, 0.1332, 0.9346, 0.5936]],\n",
      "\n",
      "        [[0.8694, 0.5677, 0.7411, 0.4294],\n",
      "         [0.8854, 0.5739, 0.2666, 0.6274],\n",
      "         [0.2696, 0.4414, 0.2969, 0.8317]]])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor with random values between 0 and 1 with the shape [2, 3, 4]\n",
    "x = torch.rand(2, 3, 4)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can obtain the shape of a tensor in the same way as in numpy (`x.shape`), or using the `.size` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([2, 3, 4])\n",
      "Size: torch.Size([2, 3, 4])\n",
      "Size: 2 3 4\n"
     ]
    }
   ],
   "source": [
    "shape = x.shape\n",
    "print(\"Shape:\", x.shape)\n",
    "\n",
    "size = x.size()\n",
    "print(\"Size:\", size)\n",
    "\n",
    "dim1, dim2, dim3 = x.size()\n",
    "print(\"Size:\", dim1, dim2, dim3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor to Numpy, and Numpy to Tensor\n",
    "\n",
    "Tensors can be converted to numpy arrays, and numpy arrays back to tensors. To transform a numpy array into a tensor, we can use the function `torch.from_numpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy array: [[1 2]\n",
      " [3 4]]\n",
      "PyTorch tensor: tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "np_arr = np.array([[1, 2], [3, 4]])\n",
    "tensor = torch.from_numpy(np_arr)\n",
    "\n",
    "print(\"Numpy array:\", np_arr)\n",
    "print(\"PyTorch tensor:\", tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To transform a PyTorch tensor back to a numpy array, we can use the function `.numpy()` on tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch tensor: tensor([0, 1, 2, 3])\n",
      "Numpy array: [0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(4)\n",
    "np_arr = tensor.numpy()\n",
    "\n",
    "print(\"PyTorch tensor:\", tensor)\n",
    "print(\"Numpy array:\", np_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conversion of tensors to numpy require the tensor to be on the CPU, and not the GPU (more on GPU support in a later section). In case you have a tensor on GPU, you need to call `.cpu()` on the tensor beforehand. Hence, you get a line like `np_arr = tensor.cpu().numpy()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operations\n",
    "\n",
    "Most operations that exist in numpy, also exist in PyTorch. A full list of operations can be found in the [PyTorch documentation](https://pytorch.org/docs/stable/tensors.html#), but we will review the most important ones here.\n",
    "\n",
    "The simplest operation is to add two tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 tensor([[0.1053, 0.2695, 0.3588],\n",
      "        [0.1994, 0.5472, 0.0062]])\n",
      "X2 tensor([[0.9516, 0.0753, 0.8860],\n",
      "        [0.5832, 0.3376, 0.8090]])\n",
      "Y tensor([[1.0569, 0.3448, 1.2448],\n",
      "        [0.7826, 0.8848, 0.8151]])\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.rand(2, 3)\n",
    "x2 = torch.rand(2, 3)\n",
    "y = x1 + x2\n",
    "\n",
    "print(\"X1\", x1)\n",
    "print(\"X2\", x2)\n",
    "print(\"Y\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling `x1 + x2` creates a new tensor containing the sum of the two inputs. However, we can also use in-place operations that are applied directly on the memory of a tensor. We therefore change the values of `x2` without the chance to re-accessing the values of `x2` before the operation. An example is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 (before) tensor([[0.5779, 0.9040, 0.5547],\n",
      "        [0.3423, 0.6343, 0.3644]])\n",
      "X2 (before) tensor([[0.7104, 0.9464, 0.7890],\n",
      "        [0.2814, 0.7886, 0.5895]])\n",
      "X1 (after) tensor([[0.5779, 0.9040, 0.5547],\n",
      "        [0.3423, 0.6343, 0.3644]])\n",
      "X2 (after) tensor([[1.2884, 1.8504, 1.3437],\n",
      "        [0.6237, 1.4230, 0.9539]])\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.rand(2, 3)\n",
    "x2 = torch.rand(2, 3)\n",
    "print(\"X1 (before)\", x1)\n",
    "print(\"X2 (before)\", x2)\n",
    "\n",
    "x2.add_(x1)\n",
    "print(\"X1 (after)\", x1)\n",
    "print(\"X2 (after)\", x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In-place operations are usually marked with a underscore postfix (e.g. \"add_\" instead of \"add\").\n",
    "\n",
    "Another common operation aims at changing the shape of a tensor. A tensor of size (2,3) can be re-organized to any other shape with the same number of elements (e.g. a tensor of size (6), or (3,2), ...). In PyTorch, this operation is called `view`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X tensor([0, 1, 2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(6)\n",
    "print(\"X\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "x = x.view(2, 3)\n",
    "print(\"X\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X tensor([[0, 3],\n",
      "        [1, 4],\n",
      "        [2, 5]])\n"
     ]
    }
   ],
   "source": [
    "x = x.permute(1, 0) # Swapping dimension 0 and 1\n",
    "print(\"X\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other commonly used operations include matrix multiplications, which are essential for neural networks. Quite often, we have an input vector $\\mathbf{x}$, which is transformed using a learned weight matrix $\\mathbf{W}$. There are multiple ways and functions to perform matrix multiplication, some of which we list below:\n",
    "\n",
    "* `torch.matmul`: Performs the matrix product over two tensors, where the specific behavior depends on the dimensions. If both inputs are matrices (2-dimensional tensors), it performs the standard matrix product. For higher dimensional inputs, the function supports broadcasting (for details see the [documentation](https://pytorch.org/docs/stable/generated/torch.matmul.html?highlight=matmul#torch.matmul)). Can also be written as `a @ b`, similar to numpy. \n",
    "* `torch.mm`: Performs the matrix product over two matrices, but doesn't support broadcasting (see [documentation](https://pytorch.org/docs/stable/generated/torch.mm.html?highlight=torch%20mm#torch.mm))\n",
    "* `torch.bmm`: Performs the matrix product with a support batch dimension. If the first tensor $T$ is of shape ($b\\times n\\times m$), and the second tensor $R$ ($b\\times m\\times p$), the output $O$ is of shape ($b\\times n\\times p$), and has been calculated by performing $b$ matrix multiplications of the submatrices of $T$ and $R$: $O_i = T_i @ R_i$\n",
    "* `torch.einsum`: Performs matrix multiplications and more (i.e. sums of products) using the Einstein summation convention. Explanation of the Einstein sum can be found in assignment 1.\n",
    "\n",
    "Usually, we use `torch.matmul` or `torch.bmm`. We can try a matrix multiplication with `torch.matmul` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(6)\n",
    "x = x.view(2, 3)\n",
    "print(\"X\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "W = torch.arange(9).view(3, 3) # We can also stack multiple operations in a single line\n",
    "print(\"W\", W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h tensor([[15, 18, 21],\n",
      "        [42, 54, 66]])\n"
     ]
    }
   ],
   "source": [
    "h = torch.matmul(x, W) # Verify the result by calculating it by hand too!\n",
    "print(\"h\", h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing\n",
    "\n",
    "We often have the situation where we need to select a part of a tensor. Indexing works just like in numpy, so let's try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(12).view(3, 4)\n",
    "print(\"X\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 5, 9])\n"
     ]
    }
   ],
   "source": [
    "print(x[:, 1])   # Second column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x[0])      # First row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 7])\n"
     ]
    }
   ],
   "source": [
    "print(x[:2, -1]) # First two rows, last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "print(x[1:3, :]) # Middle two rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Computation Graph and Backpropagation\n",
    "\n",
    "One of the main reasons for using PyTorch in Deep Learning projects is that we can automatically get **gradients/derivatives** of functions that we define. We will mainly use PyTorch for implementing neural networks, and they are just fancy functions. If we use weight matrices in our function that we want to learn, then those are called the **parameters** or simply the **weights**.\n",
    "\n",
    "If our neural network would output a single scalar value, we would talk about taking the **derivative**, but you will see that quite often we will have **multiple** output variables (\"values\"); in that case we talk about **gradients**. It's a more general term.\n",
    "\n",
    "Given an input $\\mathbf{x}$, we define our function by **manipulating** that input, usually by matrix-multiplications with weight matrices and additions with so-called bias vectors. As we manipulate our input, we are automatically creating a **computational graph**. This graph shows how to arrive at our output from our input. \n",
    "PyTorch is a **define-by-run** framework; this means that we can just do our manipulations, and PyTorch will keep track of that graph for us. Thus, we create a dynamic computation graph along the way.\n",
    "\n",
    "So, to recap: the only thing we have to do is to compute the **output**, and then we can ask PyTorch to automatically get the **gradients**. \n",
    "\n",
    "> **Note:  Why do we want gradients?** Consider that we have defined a function, a neural net, that is supposed to compute a certain output $y$ for an input vector $\\mathbf{x}$. We then define an **error measure** that tells us how wrong our network is; how bad it is in predicting output $y$ from input $\\mathbf{x}$. Based on this error measure, we can use the gradients to **update** the weights $\\mathbf{W}$ that were responsible for the output, so that the next time we present input $\\mathbf{x}$ to our network, the output will be closer to what we want.\n",
    "\n",
    "The first thing we have to do is to specify which tensors require gradients. By default, when we create a tensor, it does not require gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones((3,))\n",
    "print(x.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can change this for an existing tensor using the function `requires_grad_()` (underscore indicating that this is a in-place operation). Alternatively, when creating a tensor, you can pass the argument `requires_grad=True` to most initializers we have seen above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "x.requires_grad_(True)\n",
    "print(x.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get familiar with the concept of a computation graph, we will create one for the following function:\n",
    "\n",
    "$$y = \\frac{1}{|x|}\\sum_i \\left[(x_i + 2)^2 + 3\\right]$$\n",
    "\n",
    "You could imagine that $x$ are our parameters, and we want to optimize (either maximize or minimize) the output $y$. For this, we want to obtain the gradients $\\partial y / \\partial \\mathbf{x}$. For our example, we'll use $\\mathbf{x}=[0,1,2]$ as our input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X tensor([0., 1., 2.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(3, dtype=torch.float32, requires_grad=True) # Only float tensors can have gradients\n",
    "print(\"X\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build the computation graph step by step. You can combine multiple operations in a single line, but we will separate them here to get a better understanding of how each operation is added to the computation graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y tensor(12.6667, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a = x + 2\n",
    "b = a ** 2\n",
    "c = b + 3\n",
    "y = c.mean()\n",
    "print(\"Y\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the statements above, we have created a computation graph that looks similar to the figure below:\n",
    "\n",
    "<center style=\"width: 100%\"><img src=\"pytorch_computation_graph.svg\" width=\"200px\"></center>\n",
    "\n",
    "We calculate $a$ based on the inputs $x$ and the constant $2$, $b$ is $a$ squared, and so on. The visualization is an abstraction of the dependencies between inputs and outputs of the operations we have applied.\n",
    "Each node of the computation graph has automatically defined a function for calculating the gradients with respect to its inputs, `grad_fn`. You can see this when we printed the output tensor $y$. This is why the computation graph is usually visualized in the reverse direction (arrows point from the result to the inputs). We can perform backpropagation on the computation graph by calling the function `backward()` on the last output, which effectively calculates the gradients for each tensor that has the property `requires_grad=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`x.grad` will now contain the gradient $\\partial y/ \\partial \\mathcal{x}$, and this gradient indicates how a change in $\\mathbf{x}$ will affect output $y$ given the current input $\\mathbf{x}=[0,1,2]$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.3333, 2.0000, 2.6667])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also verify these gradients by hand. We will calculate the gradients using the chain rule, in the same way as PyTorch did it:\n",
    "\n",
    "$$\\frac{\\partial y}{\\partial x_i} = \\frac{\\partial y}{\\partial c_i}\\frac{\\partial c_i}{\\partial b_i}\\frac{\\partial b_i}{\\partial a_i}\\frac{\\partial a_i}{\\partial x_i}$$\n",
    "\n",
    "Note that we have simplified this equation to index notation, and by using the fact that all operation besides the mean do not combine the elements in the tensor. The partial derivatives are:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial a_i}{\\partial x_i} = 1,\\hspace{1cm}\n",
    "\\frac{\\partial b_i}{\\partial a_i} = 2\\cdot a_i\\hspace{1cm}\n",
    "\\frac{\\partial c_i}{\\partial b_i} = 1\\hspace{1cm}\n",
    "\\frac{\\partial y}{\\partial c_i} = \\frac{1}{3}\n",
    "$$\n",
    "\n",
    "Hence, with the input being $\\mathbf{x}=[0,1,2]$, our gradients are $\\partial y/\\partial \\mathbf{x}=[4/3,2,8/3]$. The previous code cell should have printed the same result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU support\n",
    "\n",
    "A crucial feature of PyTorch is the support of GPUs, short for Graphics Processing Unit. A GPU can perform many thousands of small operations in parallel, making it very well suitable for performing large matrix operations in neural networks. When comparing GPUs to CPUs, we can list the following main differences (credit: [Kevin Krewell, 2009](https://blogs.nvidia.com/blog/2009/12/16/whats-the-difference-between-a-cpu-and-a-gpu/)) \n",
    "\n",
    "<center style=\"width: 100%\"><img src=\"comparison_CPU_GPU.png\" width=\"700px\"></center>\n",
    "\n",
    "CPUs and GPUs have both different advantages and disadvantages, which is why many computers contain both components and use them for different tasks. In case you are not familiar with GPUs, you can read up more details in this [NVIDIA blog post](https://blogs.nvidia.com/blog/2009/12/16/whats-the-difference-between-a-cpu-and-a-gpu/) or [here](https://www.intel.com/content/www/us/en/products/docs/processors/what-is-a-gpu.html). \n",
    "\n",
    "GPUs can accelerate the training of your network up to a factor of $100$ which is essential for large neural networks. PyTorch implements a lot of functionality for supporting GPUs (mostly those of NVIDIA due to the libraries [CUDA](https://developer.nvidia.com/cuda-zone) and [cuDNN](https://developer.nvidia.com/cudnn)). First, let's check whether you have a GPU available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the GPU available? True\n"
     ]
    }
   ],
   "source": [
    "gpu_avail = torch.cuda.is_available()\n",
    "print(f\"Is the GPU available? {gpu_avail}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a GPU on your computer but the command above returns False, make sure you have the correct CUDA-version installed. The `dl2020` environment comes with the CUDA-toolkit 10.1, which is selected for the Lisa supercomputer. Please change it if necessary (CUDA 10.2 is currently common). On Google Colab, make sure that you have selected a GPU in your runtime setup (in the menu, check under `Runtime -> Change runtime type`). \n",
    "\n",
    "By default, all tensors you create are stored on the CPU. We can push a tensor to the GPU by using the function `.to(...)`, or `.cuda()`. However, it is often a good practice to define a `device` object in your code which points to the GPU if you have one, and otherwise to the CPU. Then, you can write your code with respect to this device object, and it allows you to run the same code on both a CPU-only system, and one with a GPU. Let's try it below. We can specify the device as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a tensor and push it to the device:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(2, 3)\n",
    "x = x.to(device)\n",
    "print(\"X\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you have a GPU, you should now see the attribute `device='cuda:0'` being printed next to your tensor. The zero next to cuda indicates that this is the zero-th GPU device on your computer. PyTorch also supports multi-GPU systems, but this you will only need once you have very big networks to train (if interested, see the [PyTorch documentation](https://pytorch.org/docs/stable/distributed.html#distributed-basics)). We can also compare the runtime of a large matrix multiplication on the CPU with a operation on the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU time: 0.19239s\n",
      "GPU time: 0.00008s\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(5000, 5000)\n",
    "\n",
    "## CPU version\n",
    "start_time = time.time()\n",
    "_ = torch.matmul(x, x)\n",
    "end_time = time.time()\n",
    "print(f\"CPU time: {(end_time - start_time):6.5f}s\")\n",
    "\n",
    "## GPU version\n",
    "x = x.to(device)\n",
    "# The first operation on a CUDA device can be slow as it has to establish a CPU-GPU communication first. \n",
    "# Hence, we run an arbitrary command first without timing it for a fair comparison.\n",
    "if torch.cuda.is_available():\n",
    "    _ = torch.matmul(x*0.0, x)\n",
    "start_time = time.time()\n",
    "_ = torch.matmul(x, x)\n",
    "end_time = time.time()\n",
    "print(f\"GPU time: {(end_time - start_time):6.5f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the size of the operation and the CPU/GPU in your system, the speedup of this operation can be >500x. As `matmul` operations are very common in neural networks, we can already see the great benefit of training a NN on a GPU. The time estimate can be relatively noisy here because we haven't run it for multiple times. Feel free to extend this, but it also takes longer to run.\n",
    "\n",
    "When generating random numbers, the seed between CPU and GPU is not synchronized. Hence, we need to set the seed on the GPU separately to ensure a reproducible code. Note that due to different GPU architectures, running the same code on different GPUs does not guarantee the same random numbers. Still, we don't want that our code gives us a different output every time we run it on the exact same hardware. Hence, we also set the seed on the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU operations have a separate seed we also want to set\n",
    "if torch.cuda.is_available(): \n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    \n",
    "# Additionally, some operations on a GPU are implemented stochastic for efficiency\n",
    "# We want to ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.determinstic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning by example: Continuous XOR\n",
    "\n",
    "If we want to build a neural network in PyTorch, we could specify all our parameters (weight matrices, bias vectors) using `Tensors` (with `requires_grad=True`), ask PyTorch to calculate the gradients and then adjust the parameters. But things can quickly get cumbersome if we have a lot of parameters. In PyTorch, there is a package called `torch.nn` that makes building neural networks more convenient. \n",
    "\n",
    "We will introduce the libraries and all additional parts you might need to train a neural network in PyTorch, using a simple example classifier on a simple yet well known example: XOR. Given two binary inputs $x_1$ and $x_2$, the label to predict is $1$ if either $x_1$ or $x_2$ is $1$ while the other is $0$, or the label is $0$ in all other cases. The example became famous by the fact that a single neuron, i.e. a linear classifier, cannot learn this simple function.\n",
    "Hence, we will learn how to build a small neural network that can learn this function. \n",
    "To make it a little bit more interesting, we move the XOR into continuous space and introduce some gaussian noise on the binary inputs. Our desired separation of an XOR dataset could look as follows:\n",
    "\n",
    "<center style=\"width: 100%\"><img src=\"continuous_xor.svg\" width=\"350px\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model\n",
    "\n",
    "The package `torch.nn` defines a series of useful classes like linear networks layers, activation functions, loss functions etc. A full list can be found [here](https://pytorch.org/docs/stable/nn.html). In case you need a certain network layer, check the documentation of the package first before writing the layer yourself as the package likely contains the code for it already. We import it below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally to `torch.nn`, there is also `torch.nn.functional`. It contains functions that are used in network layers. This is in contrast to `torch.nn` which defines them as `nn.Modules` (more on it below), and `torch.nn` actually uses a lot of functionalities from `torch.nn.functional`. Hence, the functional package is useful in many situations, and so we import it as well here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn.Module\n",
    "\n",
    "In PyTorch, a neural network is build up out of modules. Modules can contain other modules, and a neural network is considered to be a module itself as well. The basic template of a module is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Some init for my module\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Function for performing the calculation of the module.\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The forward function is where the computation of the module is taken place, and is executed when you call the module (`nn = MyModule(); nn(x)`). In the init function, we usually create the parameters of the module, using `nn.Parameter`, or defining other modules that are used in the forward function. The backward calculation is done automatically, but could be overwritten as well if wanted.\n",
    "\n",
    "#### Simple classifier\n",
    "We can now make use of the pre-defined modules in the `torch.nn` package, and define our own small neural network. We will use a minimal network with a input layer, one hidden layer with tanh as activation function, and a output layer. In other words, our networks should look something like this:\n",
    "\n",
    "<center width=\"100%\"><img src=\"small_neural_network.svg\" width=\"300px\"></center>\n",
    "\n",
    "The input neurons are shown in blue, which represent the coordinates $x_1$ and $x_2$ of a data point. The hidden neurons including a tanh activation are shown in white, and the output neuron in red.\n",
    "In PyTorch, we can define this as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
    "        super().__init__()\n",
    "        # Initialize the modules we need to build the network\n",
    "        self.linear1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.act_fn = nn.Tanh()\n",
    "        self.linear2 = nn.Linear(num_hidden, num_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Perform the calculation of the model to determine the prediction\n",
    "        x = self.linear1(x)\n",
    "        x = self.act_fn(x)\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the examples in this notebook, we will use a tiny neural network with two input neurons and four hidden neurons. As we perform binary classification, we will use a single output neuron. Note that we do not apply a sigmoid on the output yet. This is because other functions, especially the loss, are more efficient and precise to calculate on the original outputs instead of the sigmoid output. We will discuss the detailed reason later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleClassifier(\n",
      "  (linear1): Linear(in_features=2, out_features=4, bias=True)\n",
      "  (act_fn): Tanh()\n",
      "  (linear2): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = SimpleClassifier(num_inputs=2, num_hidden=4, num_outputs=1)\n",
    "# Printing a module shows all its submodules\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the model lists all submodules it contains. The parameters of a module can be obtained by using its `parameters()` functions, or `named_parameters()` to get a name to each parameter object. For our small neural network, we have the following parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter linear1.weight, shape torch.Size([4, 2])\n",
      "Parameter linear1.bias, shape torch.Size([4])\n",
      "Parameter linear2.weight, shape torch.Size([1, 4])\n",
      "Parameter linear2.bias, shape torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"Parameter {name}, shape {param.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each linear layer has a weight matrix of the shape `[output, input]`, and a bias of the shape `[output]`. The tanh activation function does not have any parameters. Note that parameters are only registered for `nn.Module` objects that are direct object attributes, i.e. `self.a = ...`. If you define a list of modules, the parameters of those are not registered for the outer module and can cause some issues when you try to optimize your module. There are alternatives, like `nn.ModuleList`, `nn.ModuleDict` and `nn.Sequential`, that allow you to have different data structures of modules. We will use them in a few later tutorials and explain them there. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data\n",
    "\n",
    "PyTorch also provides a few functionalities to load the training and test data efficiently, summarized in the package `torch.utils.data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data package defines two classes which are the standard interface for handling data in PyTorch: `data.Dataset`, and `data.DataLoader`. The dataset class provides an uniform interface to access the training/test data, while the data loader makes sure to efficiently load and stack the data points from the dataset into batches during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The dataset class\n",
    "\n",
    "The dataset class summarizes the basic functionality of a dataset in a natural way. To define a dataset in PyTorch, we simply specify two functions: `__getitem__`, and `__len__`. The get-item function has to return the $i$-th data point in the dataset, while the len function returns the size of the dataset. For the XOR dataset, we can define the dataset class as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XORDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, size, std=0.1):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            size - Number of data points we want to generate\n",
    "            std - Standard deviation of the noise (see generate_continuous_xor function)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        self.std = std\n",
    "        self.generate_continuous_xor()\n",
    "\n",
    "    def generate_continuous_xor(self):\n",
    "        # Each data point in the XOR dataset has two variables, x and y, that can be either 0 or 1\n",
    "        # The label is their XOR combination, i.e. 1 if only x or only y is 1 while the other is 0.\n",
    "        # If x=y, the label is 0.\n",
    "        data = torch.randint(low=0, high=2, size=(self.size, 2), dtype=torch.float32)\n",
    "        label = (data.sum(dim=1) == 1).to(torch.long)\n",
    "        # To make it slightly more challenging, we add a bit of gaussian noise to the data points.\n",
    "        data += self.std * torch.randn(data.shape)\n",
    "\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        # Number of data point we have. Alternatively self.data.shape[0], or self.label.shape[0]\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return the idx-th data point of the dataset\n",
    "        # If we have multiple things to return (data point and label), we can return them as tuple\n",
    "        data_point = self.data[idx]\n",
    "        data_label = self.label[idx]\n",
    "        return data_point, data_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to create such a dataset and inspect it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 200\n",
      "Data point 0: (tensor([0.9632, 0.1117]), tensor(1))\n"
     ]
    }
   ],
   "source": [
    "dataset = XORDataset(size=200)\n",
    "print(\"Size of dataset:\", len(dataset))\n",
    "print(\"Data point 0:\", dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better relate to the dataset, we visualize the samples below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_samples(data, label):\n",
    "    if isinstance(data, torch.Tensor):\n",
    "        data = data.cpu().numpy()\n",
    "    if isinstance(label, torch.Tensor):\n",
    "        label = label.cpu().numpy()\n",
    "    data_0 = data[label == 0]\n",
    "    data_1 = data[label == 1]\n",
    "    \n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.scatter(data_0[:,0], data_0[:,1], edgecolor=\"#333\", label=\"Class 0\")\n",
    "    plt.scatter(data_1[:,0], data_1[:,1], edgecolor=\"#333\", label=\"Class 1\")\n",
    "    plt.title(\"Dataset samples\")\n",
    "    plt.ylabel(r\"$x_2$\")\n",
    "    plt.xlabel(r\"$x_1$\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/pdf": "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\n",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"280.963594pt\" version=\"1.1\" viewBox=\"0 0 283.789062 280.963594\" width=\"283.789062pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2020-11-08T21:41:12.740109</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 280.963594 \n",
       "L 283.789062 280.963594 \n",
       "L 283.789062 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 53.389062 239.229375 \n",
       "L 276.589063 239.229375 \n",
       "L 276.589063 21.789375 \n",
       "L 53.389062 21.789375 \n",
       "z\n",
       "\" style=\"fill:#eaeaf2;\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path clip-path=\"url(#pc28445eaad)\" d=\"M 98.50043 239.229375 \n",
       "L 98.50043 21.789375 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0.0 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(90.85543 256.602969)scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path d=\"M 4.15625 35.296875 \n",
       "Q 4.15625 48 6.765625 55.734375 \n",
       "Q 9.375 63.484375 14.515625 67.671875 \n",
       "Q 19.671875 71.875 27.484375 71.875 \n",
       "Q 33.25 71.875 37.59375 69.546875 \n",
       "Q 41.9375 67.234375 44.765625 62.859375 \n",
       "Q 47.609375 58.5 49.21875 52.21875 \n",
       "Q 50.828125 45.953125 50.828125 35.296875 \n",
       "Q 50.828125 22.703125 48.234375 14.96875 \n",
       "Q 45.65625 7.234375 40.5 3 \n",
       "Q 35.359375 -1.21875 27.484375 -1.21875 \n",
       "Q 17.140625 -1.21875 11.234375 6.203125 \n",
       "Q 4.15625 15.140625 4.15625 35.296875 \n",
       "z\n",
       "M 13.1875 35.296875 \n",
       "Q 13.1875 17.671875 17.3125 11.828125 \n",
       "Q 21.4375 6 27.484375 6 \n",
       "Q 33.546875 6 37.671875 11.859375 \n",
       "Q 41.796875 17.71875 41.796875 35.296875 \n",
       "Q 41.796875 52.984375 37.671875 58.78125 \n",
       "Q 33.546875 64.59375 27.390625 64.59375 \n",
       "Q 21.34375 64.59375 17.71875 59.46875 \n",
       "Q 13.1875 52.9375 13.1875 35.296875 \n",
       "z\n",
       "\" id=\"ArialMT-48\"/>\n",
       "        <path d=\"M 9.078125 0 \n",
       "L 9.078125 10.015625 \n",
       "L 19.09375 10.015625 \n",
       "L 19.09375 0 \n",
       "z\n",
       "\" id=\"ArialMT-46\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-48\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-46\"/>\n",
       "       <use x=\"83.398438\" xlink:href=\"#ArialMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <path clip-path=\"url(#pc28445eaad)\" d=\"M 167.852486 239.229375 \n",
       "L 167.852486 21.789375 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 0.5 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(160.207486 256.602969)scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path d=\"M 4.15625 18.75 \n",
       "L 13.375 19.53125 \n",
       "Q 14.40625 12.796875 18.140625 9.390625 \n",
       "Q 21.875 6 27.15625 6 \n",
       "Q 33.5 6 37.890625 10.78125 \n",
       "Q 42.28125 15.578125 42.28125 23.484375 \n",
       "Q 42.28125 31 38.0625 35.34375 \n",
       "Q 33.84375 39.703125 27 39.703125 \n",
       "Q 22.75 39.703125 19.328125 37.765625 \n",
       "Q 15.921875 35.84375 13.96875 32.765625 \n",
       "L 5.71875 33.84375 \n",
       "L 12.640625 70.609375 \n",
       "L 48.25 70.609375 \n",
       "L 48.25 62.203125 \n",
       "L 19.671875 62.203125 \n",
       "L 15.828125 42.96875 \n",
       "Q 22.265625 47.46875 29.34375 47.46875 \n",
       "Q 38.71875 47.46875 45.15625 40.96875 \n",
       "Q 51.609375 34.46875 51.609375 24.265625 \n",
       "Q 51.609375 14.546875 45.953125 7.46875 \n",
       "Q 39.0625 -1.21875 27.15625 -1.21875 \n",
       "Q 17.390625 -1.21875 11.203125 4.25 \n",
       "Q 5.03125 9.71875 4.15625 18.75 \n",
       "z\n",
       "\" id=\"ArialMT-53\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-48\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-46\"/>\n",
       "       <use x=\"83.398438\" xlink:href=\"#ArialMT-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path clip-path=\"url(#pc28445eaad)\" d=\"M 237.204542 239.229375 \n",
       "L 237.204542 21.789375 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 1.0 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(229.559542 256.602969)scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path d=\"M 37.25 0 \n",
       "L 28.46875 0 \n",
       "L 28.46875 56 \n",
       "Q 25.296875 52.984375 20.140625 49.953125 \n",
       "Q 14.984375 46.921875 10.890625 45.40625 \n",
       "L 10.890625 53.90625 \n",
       "Q 18.265625 57.375 23.78125 62.296875 \n",
       "Q 29.296875 67.234375 31.59375 71.875 \n",
       "L 37.25 71.875 \n",
       "z\n",
       "\" id=\"ArialMT-49\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-49\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-46\"/>\n",
       "       <use x=\"83.398438\" xlink:href=\"#ArialMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_4\">\n",
       "     <!-- $x_1$ -->\n",
       "     <g style=\"fill:#262626;\" transform=\"translate(158.569063 271.378594)scale(0.12 -0.12)\">\n",
       "      <defs>\n",
       "       <path d=\"M 60.015625 54.6875 \n",
       "L 34.90625 27.875 \n",
       "L 50.296875 0 \n",
       "L 39.984375 0 \n",
       "L 28.421875 21.6875 \n",
       "L 8.296875 0 \n",
       "L -2.59375 0 \n",
       "L 24.3125 28.8125 \n",
       "L 10.015625 54.6875 \n",
       "L 20.3125 54.6875 \n",
       "L 30.8125 34.90625 \n",
       "L 49.125 54.6875 \n",
       "z\n",
       "\" id=\"DejaVuSans-Oblique-120\"/>\n",
       "       <path d=\"M 12.40625 8.296875 \n",
       "L 28.515625 8.296875 \n",
       "L 28.515625 63.921875 \n",
       "L 10.984375 60.40625 \n",
       "L 10.984375 69.390625 \n",
       "L 28.421875 72.90625 \n",
       "L 38.28125 72.90625 \n",
       "L 38.28125 8.296875 \n",
       "L 54.390625 8.296875 \n",
       "L 54.390625 0 \n",
       "L 12.40625 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-49\"/>\n",
       "      </defs>\n",
       "      <use transform=\"translate(0 0.3125)\" xlink:href=\"#DejaVuSans-Oblique-120\"/>\n",
       "      <use transform=\"translate(59.179688 -16.09375)scale(0.7)\" xlink:href=\"#DejaVuSans-49\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <path clip-path=\"url(#pc28445eaad)\" d=\"M 53.389062 223.41392 \n",
       "L 276.589063 223.41392 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 0.2 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(22.174375 227.350717)scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path d=\"M 52.828125 31.203125 \n",
       "L 5.5625 31.203125 \n",
       "L 5.5625 39.40625 \n",
       "L 52.828125 39.40625 \n",
       "z\n",
       "\" id=\"ArialMT-8722\"/>\n",
       "        <path d=\"M 50.34375 8.453125 \n",
       "L 50.34375 0 \n",
       "L 3.03125 0 \n",
       "Q 2.9375 3.171875 4.046875 6.109375 \n",
       "Q 5.859375 10.9375 9.828125 15.625 \n",
       "Q 13.8125 20.3125 21.34375 26.46875 \n",
       "Q 33.015625 36.03125 37.109375 41.625 \n",
       "Q 41.21875 47.21875 41.21875 52.203125 \n",
       "Q 41.21875 57.421875 37.46875 61 \n",
       "Q 33.734375 64.59375 27.734375 64.59375 \n",
       "Q 21.390625 64.59375 17.578125 60.78125 \n",
       "Q 13.765625 56.984375 13.71875 50.25 \n",
       "L 4.6875 51.171875 \n",
       "Q 5.609375 61.28125 11.65625 66.578125 \n",
       "Q 17.71875 71.875 27.9375 71.875 \n",
       "Q 38.234375 71.875 44.234375 66.15625 \n",
       "Q 50.25 60.453125 50.25 52 \n",
       "Q 50.25 47.703125 48.484375 43.546875 \n",
       "Q 46.734375 39.40625 42.65625 34.8125 \n",
       "Q 38.578125 30.21875 29.109375 22.21875 \n",
       "Q 21.1875 15.578125 18.9375 13.203125 \n",
       "Q 16.703125 10.84375 15.234375 8.453125 \n",
       "z\n",
       "\" id=\"ArialMT-50\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-8722\"/>\n",
       "       <use x=\"58.398438\" xlink:href=\"#ArialMT-48\"/>\n",
       "       <use x=\"114.013672\" xlink:href=\"#ArialMT-46\"/>\n",
       "       <use x=\"141.796875\" xlink:href=\"#ArialMT-50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path clip-path=\"url(#pc28445eaad)\" d=\"M 53.389062 195.806867 \n",
       "L 276.589063 195.806867 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 0.0 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(28.599062 199.743664)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-48\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-46\"/>\n",
       "       <use x=\"83.398438\" xlink:href=\"#ArialMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <path clip-path=\"url(#pc28445eaad)\" d=\"M 53.389062 168.199814 \n",
       "L 276.589063 168.199814 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 0.2 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(28.599062 172.136611)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-48\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-46\"/>\n",
       "       <use x=\"83.398438\" xlink:href=\"#ArialMT-50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path clip-path=\"url(#pc28445eaad)\" d=\"M 53.389062 140.59276 \n",
       "L 276.589063 140.59276 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.4 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(28.599062 144.529557)scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path d=\"M 32.328125 0 \n",
       "L 32.328125 17.140625 \n",
       "L 1.265625 17.140625 \n",
       "L 1.265625 25.203125 \n",
       "L 33.9375 71.578125 \n",
       "L 41.109375 71.578125 \n",
       "L 41.109375 25.203125 \n",
       "L 50.78125 25.203125 \n",
       "L 50.78125 17.140625 \n",
       "L 41.109375 17.140625 \n",
       "L 41.109375 0 \n",
       "z\n",
       "M 32.328125 25.203125 \n",
       "L 32.328125 57.46875 \n",
       "L 9.90625 25.203125 \n",
       "z\n",
       "\" id=\"ArialMT-52\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-48\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-46\"/>\n",
       "       <use x=\"83.398438\" xlink:href=\"#ArialMT-52\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <path clip-path=\"url(#pc28445eaad)\" d=\"M 53.389062 112.985707 \n",
       "L 276.589063 112.985707 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.6 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(28.599062 116.922504)scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path d=\"M 49.75 54.046875 \n",
       "L 41.015625 53.375 \n",
       "Q 39.84375 58.546875 37.703125 60.890625 \n",
       "Q 34.125 64.65625 28.90625 64.65625 \n",
       "Q 24.703125 64.65625 21.53125 62.3125 \n",
       "Q 17.390625 59.28125 14.984375 53.46875 \n",
       "Q 12.59375 47.65625 12.5 36.921875 \n",
       "Q 15.671875 41.75 20.265625 44.09375 \n",
       "Q 24.859375 46.4375 29.890625 46.4375 \n",
       "Q 38.671875 46.4375 44.84375 39.96875 \n",
       "Q 51.03125 33.5 51.03125 23.25 \n",
       "Q 51.03125 16.5 48.125 10.71875 \n",
       "Q 45.21875 4.9375 40.140625 1.859375 \n",
       "Q 35.0625 -1.21875 28.609375 -1.21875 \n",
       "Q 17.625 -1.21875 10.6875 6.859375 \n",
       "Q 3.765625 14.9375 3.765625 33.5 \n",
       "Q 3.765625 54.25 11.421875 63.671875 \n",
       "Q 18.109375 71.875 29.4375 71.875 \n",
       "Q 37.890625 71.875 43.28125 67.140625 \n",
       "Q 48.6875 62.40625 49.75 54.046875 \n",
       "z\n",
       "M 13.875 23.1875 \n",
       "Q 13.875 18.65625 15.796875 14.5 \n",
       "Q 17.71875 10.359375 21.1875 8.171875 \n",
       "Q 24.65625 6 28.46875 6 \n",
       "Q 34.03125 6 38.03125 10.484375 \n",
       "Q 42.046875 14.984375 42.046875 22.703125 \n",
       "Q 42.046875 30.125 38.078125 34.390625 \n",
       "Q 34.125 38.671875 28.125 38.671875 \n",
       "Q 22.171875 38.671875 18.015625 34.390625 \n",
       "Q 13.875 30.125 13.875 23.1875 \n",
       "z\n",
       "\" id=\"ArialMT-54\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-48\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-46\"/>\n",
       "       <use x=\"83.398438\" xlink:href=\"#ArialMT-54\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path clip-path=\"url(#pc28445eaad)\" d=\"M 53.389062 85.378654 \n",
       "L 276.589063 85.378654 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.8 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(28.599062 89.315451)scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path d=\"M 17.671875 38.8125 \n",
       "Q 12.203125 40.828125 9.5625 44.53125 \n",
       "Q 6.9375 48.25 6.9375 53.421875 \n",
       "Q 6.9375 61.234375 12.546875 66.546875 \n",
       "Q 18.171875 71.875 27.484375 71.875 \n",
       "Q 36.859375 71.875 42.578125 66.421875 \n",
       "Q 48.296875 60.984375 48.296875 53.171875 \n",
       "Q 48.296875 48.1875 45.671875 44.5 \n",
       "Q 43.0625 40.828125 37.75 38.8125 \n",
       "Q 44.34375 36.671875 47.78125 31.875 \n",
       "Q 51.21875 27.09375 51.21875 20.453125 \n",
       "Q 51.21875 11.28125 44.71875 5.03125 \n",
       "Q 38.234375 -1.21875 27.640625 -1.21875 \n",
       "Q 17.046875 -1.21875 10.546875 5.046875 \n",
       "Q 4.046875 11.328125 4.046875 20.703125 \n",
       "Q 4.046875 27.6875 7.59375 32.390625 \n",
       "Q 11.140625 37.109375 17.671875 38.8125 \n",
       "z\n",
       "M 15.921875 53.71875 \n",
       "Q 15.921875 48.640625 19.1875 45.40625 \n",
       "Q 22.46875 42.1875 27.6875 42.1875 \n",
       "Q 32.765625 42.1875 36.015625 45.375 \n",
       "Q 39.265625 48.578125 39.265625 53.21875 \n",
       "Q 39.265625 58.0625 35.90625 61.359375 \n",
       "Q 32.5625 64.65625 27.59375 64.65625 \n",
       "Q 22.5625 64.65625 19.234375 61.421875 \n",
       "Q 15.921875 58.203125 15.921875 53.71875 \n",
       "z\n",
       "M 13.09375 20.65625 \n",
       "Q 13.09375 16.890625 14.875 13.375 \n",
       "Q 16.65625 9.859375 20.171875 7.921875 \n",
       "Q 23.6875 6 27.734375 6 \n",
       "Q 34.03125 6 38.125 10.046875 \n",
       "Q 42.234375 14.109375 42.234375 20.359375 \n",
       "Q 42.234375 26.703125 38.015625 30.859375 \n",
       "Q 33.796875 35.015625 27.4375 35.015625 \n",
       "Q 21.234375 35.015625 17.15625 30.90625 \n",
       "Q 13.09375 26.8125 13.09375 20.65625 \n",
       "z\n",
       "\" id=\"ArialMT-56\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-48\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-46\"/>\n",
       "       <use x=\"83.398438\" xlink:href=\"#ArialMT-56\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <path clip-path=\"url(#pc28445eaad)\" d=\"M 53.389062 57.771601 \n",
       "L 276.589063 57.771601 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 1.0 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(28.599062 61.708397)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-49\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-46\"/>\n",
       "       <use x=\"83.398438\" xlink:href=\"#ArialMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_8\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path clip-path=\"url(#pc28445eaad)\" d=\"M 53.389062 30.164547 \n",
       "L 276.589063 30.164547 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 1.2 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(28.599062 34.101344)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-49\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-46\"/>\n",
       "       <use x=\"83.398438\" xlink:href=\"#ArialMT-50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_13\">\n",
       "     <!-- $x_2$ -->\n",
       "     <g style=\"fill:#262626;\" transform=\"translate(15.789375 136.929375)rotate(-90)scale(0.12 -0.12)\">\n",
       "      <defs>\n",
       "       <path d=\"M 19.1875 8.296875 \n",
       "L 53.609375 8.296875 \n",
       "L 53.609375 0 \n",
       "L 7.328125 0 \n",
       "L 7.328125 8.296875 \n",
       "Q 12.9375 14.109375 22.625 23.890625 \n",
       "Q 32.328125 33.6875 34.8125 36.53125 \n",
       "Q 39.546875 41.84375 41.421875 45.53125 \n",
       "Q 43.3125 49.21875 43.3125 52.78125 \n",
       "Q 43.3125 58.59375 39.234375 62.25 \n",
       "Q 35.15625 65.921875 28.609375 65.921875 \n",
       "Q 23.96875 65.921875 18.8125 64.3125 \n",
       "Q 13.671875 62.703125 7.8125 59.421875 \n",
       "L 7.8125 69.390625 \n",
       "Q 13.765625 71.78125 18.9375 73 \n",
       "Q 24.125 74.21875 28.421875 74.21875 \n",
       "Q 39.75 74.21875 46.484375 68.546875 \n",
       "Q 53.21875 62.890625 53.21875 53.421875 \n",
       "Q 53.21875 48.921875 51.53125 44.890625 \n",
       "Q 49.859375 40.875 45.40625 35.40625 \n",
       "Q 44.1875 33.984375 37.640625 27.21875 \n",
       "Q 31.109375 20.453125 19.1875 8.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-50\"/>\n",
       "      </defs>\n",
       "      <use transform=\"translate(0 0.3125)\" xlink:href=\"#DejaVuSans-Oblique-120\"/>\n",
       "      <use transform=\"translate(59.179688 -16.09375)scale(0.7)\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"PathCollection_1\">\n",
       "    <defs>\n",
       "     <path d=\"M 0 3 \n",
       "C 0.795609 3 1.55874 2.683901 2.12132 2.12132 \n",
       "C 2.683901 1.55874 3 0.795609 3 0 \n",
       "C 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \n",
       "C 1.55874 -2.683901 0.795609 -3 0 -3 \n",
       "C -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \n",
       "C -2.683901 -1.55874 -3 -0.795609 -3 0 \n",
       "C -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \n",
       "C -1.55874 2.683901 -0.795609 3 0 3 \n",
       "z\n",
       "\" id=\"m4bbbbefdf1\" style=\"stroke:#333333;\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#pc28445eaad)\">\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"97.539805\" xlink:href=\"#m4bbbbefdf1\" y=\"192.796594\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"233.285782\" xlink:href=\"#m4bbbbefdf1\" y=\"61.616299\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"260.207567\" xlink:href=\"#m4bbbbefdf1\" y=\"63.251712\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"110.141493\" xlink:href=\"#m4bbbbefdf1\" y=\"203.880828\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"102.553933\" xlink:href=\"#m4bbbbefdf1\" y=\"204.514265\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"72.211579\" xlink:href=\"#m4bbbbefdf1\" y=\"189.031679\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"244.113666\" xlink:href=\"#m4bbbbefdf1\" y=\"58.037383\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"233.244834\" xlink:href=\"#m4bbbbefdf1\" y=\"50.911771\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"95.207068\" xlink:href=\"#m4bbbbefdf1\" y=\"204.021937\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"238.767099\" xlink:href=\"#m4bbbbefdf1\" y=\"53.043297\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"104.771234\" xlink:href=\"#m4bbbbefdf1\" y=\"199.781085\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"256.783223\" xlink:href=\"#m4bbbbefdf1\" y=\"31.673011\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"239.286127\" xlink:href=\"#m4bbbbefdf1\" y=\"62.060973\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"233.398186\" xlink:href=\"#m4bbbbefdf1\" y=\"57.225703\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"95.492302\" xlink:href=\"#m4bbbbefdf1\" y=\"212.097418\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"90.45996\" xlink:href=\"#m4bbbbefdf1\" y=\"184.508921\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"252.495546\" xlink:href=\"#m4bbbbefdf1\" y=\"90.284942\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"256.043604\" xlink:href=\"#m4bbbbefdf1\" y=\"83.224352\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"227.333462\" xlink:href=\"#m4bbbbefdf1\" y=\"58.609485\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"83.251017\" xlink:href=\"#m4bbbbefdf1\" y=\"208.673493\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"255.201254\" xlink:href=\"#m4bbbbefdf1\" y=\"32.09617\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"246.379035\" xlink:href=\"#m4bbbbefdf1\" y=\"59.427048\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"115.650112\" xlink:href=\"#m4bbbbefdf1\" y=\"175.30868\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"229.885909\" xlink:href=\"#m4bbbbefdf1\" y=\"31.807499\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"101.009139\" xlink:href=\"#m4bbbbefdf1\" y=\"194.248465\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"229.0353\" xlink:href=\"#m4bbbbefdf1\" y=\"50.97616\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"88.109479\" xlink:href=\"#m4bbbbefdf1\" y=\"178.963998\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"251.955188\" xlink:href=\"#m4bbbbefdf1\" y=\"48.24534\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"247.624405\" xlink:href=\"#m4bbbbefdf1\" y=\"60.983995\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"241.407644\" xlink:href=\"#m4bbbbefdf1\" y=\"43.16526\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"93.569105\" xlink:href=\"#m4bbbbefdf1\" y=\"183.844502\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"105.73424\" xlink:href=\"#m4bbbbefdf1\" y=\"209.180969\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"88.588564\" xlink:href=\"#m4bbbbefdf1\" y=\"169.096852\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"98.973611\" xlink:href=\"#m4bbbbefdf1\" y=\"200.790079\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"113.430582\" xlink:href=\"#m4bbbbefdf1\" y=\"200.338872\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"94.61486\" xlink:href=\"#m4bbbbefdf1\" y=\"195.173102\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"114.190533\" xlink:href=\"#m4bbbbefdf1\" y=\"211.683003\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"215.151649\" xlink:href=\"#m4bbbbefdf1\" y=\"39.091573\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"254.637069\" xlink:href=\"#m4bbbbefdf1\" y=\"64.076079\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"239.430724\" xlink:href=\"#m4bbbbefdf1\" y=\"63.231036\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"94.562884\" xlink:href=\"#m4bbbbefdf1\" y=\"204.881855\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"223.92514\" xlink:href=\"#m4bbbbefdf1\" y=\"88.563896\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"247.295643\" xlink:href=\"#m4bbbbefdf1\" y=\"56.252615\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"99.136481\" xlink:href=\"#m4bbbbefdf1\" y=\"211.598331\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"111.837037\" xlink:href=\"#m4bbbbefdf1\" y=\"217.149042\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"120.506731\" xlink:href=\"#m4bbbbefdf1\" y=\"176.49922\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"230.6594\" xlink:href=\"#m4bbbbefdf1\" y=\"71.339329\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"218.336148\" xlink:href=\"#m4bbbbefdf1\" y=\"43.829963\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"91.649126\" xlink:href=\"#m4bbbbefdf1\" y=\"205.284806\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"231.865739\" xlink:href=\"#m4bbbbefdf1\" y=\"67.956937\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"99.870646\" xlink:href=\"#m4bbbbefdf1\" y=\"200.504594\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"243.524679\" xlink:href=\"#m4bbbbefdf1\" y=\"33.080514\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"96.395169\" xlink:href=\"#m4bbbbefdf1\" y=\"188.231284\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"228.888058\" xlink:href=\"#m4bbbbefdf1\" y=\"76.047203\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"240.390719\" xlink:href=\"#m4bbbbefdf1\" y=\"46.907755\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"72.21366\" xlink:href=\"#m4bbbbefdf1\" y=\"190.080253\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"218.212807\" xlink:href=\"#m4bbbbefdf1\" y=\"46.668317\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"248.57056\" xlink:href=\"#m4bbbbefdf1\" y=\"65.08615\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"84.170637\" xlink:href=\"#m4bbbbefdf1\" y=\"196.294339\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"95.838332\" xlink:href=\"#m4bbbbefdf1\" y=\"229.345739\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"95.293269\" xlink:href=\"#m4bbbbefdf1\" y=\"199.343495\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"77.154625\" xlink:href=\"#m4bbbbefdf1\" y=\"199.478787\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"262.790256\" xlink:href=\"#m4bbbbefdf1\" y=\"65.223862\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"228.879584\" xlink:href=\"#m4bbbbefdf1\" y=\"73.230825\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"254.79415\" xlink:href=\"#m4bbbbefdf1\" y=\"39.151107\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"77.718849\" xlink:href=\"#m4bbbbefdf1\" y=\"184.792307\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"240.12565\" xlink:href=\"#m4bbbbefdf1\" y=\"81.900837\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"250.451214\" xlink:href=\"#m4bbbbefdf1\" y=\"89.132839\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"119.616061\" xlink:href=\"#m4bbbbefdf1\" y=\"217.774818\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"109.938832\" xlink:href=\"#m4bbbbefdf1\" y=\"206.541797\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"96.188484\" xlink:href=\"#m4bbbbefdf1\" y=\"189.495096\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"97.03243\" xlink:href=\"#m4bbbbefdf1\" y=\"187.182806\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"240.737471\" xlink:href=\"#m4bbbbefdf1\" y=\"53.340674\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"228.199143\" xlink:href=\"#m4bbbbefdf1\" y=\"87.625356\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"96.144984\" xlink:href=\"#m4bbbbefdf1\" y=\"194.992808\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"108.219394\" xlink:href=\"#m4bbbbefdf1\" y=\"186.321721\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"109.796082\" xlink:href=\"#m4bbbbefdf1\" y=\"193.589053\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"240.455536\" xlink:href=\"#m4bbbbefdf1\" y=\"37.061723\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"239.545509\" xlink:href=\"#m4bbbbefdf1\" y=\"35.225533\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"98.222624\" xlink:href=\"#m4bbbbefdf1\" y=\"207.579594\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"251.260163\" xlink:href=\"#m4bbbbefdf1\" y=\"37.172844\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"233.587526\" xlink:href=\"#m4bbbbefdf1\" y=\"71.845948\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"249.427841\" xlink:href=\"#m4bbbbefdf1\" y=\"33.045119\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"89.657172\" xlink:href=\"#m4bbbbefdf1\" y=\"192.42429\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"235.498695\" xlink:href=\"#m4bbbbefdf1\" y=\"47.466685\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"99.764129\" xlink:href=\"#m4bbbbefdf1\" y=\"211.986675\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"109.028232\" xlink:href=\"#m4bbbbefdf1\" y=\"203.781956\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"88.954921\" xlink:href=\"#m4bbbbefdf1\" y=\"190.687839\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"214.045123\" xlink:href=\"#m4bbbbefdf1\" y=\"53.312601\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"226.396293\" xlink:href=\"#m4bbbbefdf1\" y=\"47.312386\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"203.870869\" xlink:href=\"#m4bbbbefdf1\" y=\"44.164363\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"88.209656\" xlink:href=\"#m4bbbbefdf1\" y=\"191.006099\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"117.915548\" xlink:href=\"#m4bbbbefdf1\" y=\"206.446396\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"93.004906\" xlink:href=\"#m4bbbbefdf1\" y=\"209.289121\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"227.120221\" xlink:href=\"#m4bbbbefdf1\" y=\"90.176684\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"103.315363\" xlink:href=\"#m4bbbbefdf1\" y=\"194.774524\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"96.133368\" xlink:href=\"#m4bbbbefdf1\" y=\"188.619367\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"90.744113\" xlink:href=\"#m4bbbbefdf1\" y=\"199.694644\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"100.395289\" xlink:href=\"#m4bbbbefdf1\" y=\"207.677376\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"212.80607\" xlink:href=\"#m4bbbbefdf1\" y=\"57.339227\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"221.979538\" xlink:href=\"#m4bbbbefdf1\" y=\"40.940845\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"73.365903\" xlink:href=\"#m4bbbbefdf1\" y=\"213.916732\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"237.144488\" xlink:href=\"#m4bbbbefdf1\" y=\"79.936174\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"PathCollection_2\">\n",
       "    <defs>\n",
       "     <path d=\"M 0 3 \n",
       "C 0.795609 3 1.55874 2.683901 2.12132 2.12132 \n",
       "C 2.683901 1.55874 3 0.795609 3 0 \n",
       "C 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \n",
       "C 1.55874 -2.683901 0.795609 -3 0 -3 \n",
       "C -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \n",
       "C -2.683901 -1.55874 -3 -0.795609 -3 0 \n",
       "C -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \n",
       "C -1.55874 2.683901 -0.795609 3 0 3 \n",
       "z\n",
       "\" id=\"m6f2f99ee68\" style=\"stroke:#333333;\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#pc28445eaad)\">\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"232.105188\" xlink:href=\"#m6f2f99ee68\" y=\"180.384807\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"245.070552\" xlink:href=\"#m6f2f99ee68\" y=\"180.655236\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"233.245222\" xlink:href=\"#m6f2f99ee68\" y=\"198.403574\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"90.974501\" xlink:href=\"#m6f2f99ee68\" y=\"44.864248\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"251.914562\" xlink:href=\"#m6f2f99ee68\" y=\"201.070978\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"101.62853\" xlink:href=\"#m6f2f99ee68\" y=\"63.024739\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"221.090163\" xlink:href=\"#m6f2f99ee68\" y=\"210.821264\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"131.826785\" xlink:href=\"#m6f2f99ee68\" y=\"59.070277\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"248.764183\" xlink:href=\"#m6f2f99ee68\" y=\"216.668216\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"216.025291\" xlink:href=\"#m6f2f99ee68\" y=\"185.029159\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"231.135032\" xlink:href=\"#m6f2f99ee68\" y=\"172.489138\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"66.959267\" xlink:href=\"#m6f2f99ee68\" y=\"44.038054\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"117.813699\" xlink:href=\"#m6f2f99ee68\" y=\"45.004264\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"97.705625\" xlink:href=\"#m6f2f99ee68\" y=\"75.967075\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"98.016512\" xlink:href=\"#m6f2f99ee68\" y=\"41.562716\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"76.936672\" xlink:href=\"#m6f2f99ee68\" y=\"38.501823\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"235.150182\" xlink:href=\"#m6f2f99ee68\" y=\"201.228468\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"217.510895\" xlink:href=\"#m6f2f99ee68\" y=\"180.237981\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"227.173678\" xlink:href=\"#m6f2f99ee68\" y=\"182.303982\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"109.116969\" xlink:href=\"#m6f2f99ee68\" y=\"58.73029\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"213.494439\" xlink:href=\"#m6f2f99ee68\" y=\"191.618659\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"258.317538\" xlink:href=\"#m6f2f99ee68\" y=\"200.013787\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"249.756222\" xlink:href=\"#m6f2f99ee68\" y=\"197.579163\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"224.503784\" xlink:href=\"#m6f2f99ee68\" y=\"201.58701\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"255.852775\" xlink:href=\"#m6f2f99ee68\" y=\"175.927404\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"84.428858\" xlink:href=\"#m6f2f99ee68\" y=\"69.646627\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"252.952221\" xlink:href=\"#m6f2f99ee68\" y=\"178.861314\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"112.047412\" xlink:href=\"#m6f2f99ee68\" y=\"54.594453\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"233.354476\" xlink:href=\"#m6f2f99ee68\" y=\"178.140314\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"69.726027\" xlink:href=\"#m6f2f99ee68\" y=\"56.444876\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"96.454791\" xlink:href=\"#m6f2f99ee68\" y=\"65.591494\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"224.621099\" xlink:href=\"#m6f2f99ee68\" y=\"208.143884\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"216.173386\" xlink:href=\"#m6f2f99ee68\" y=\"182.604972\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"101.433743\" xlink:href=\"#m6f2f99ee68\" y=\"60.132881\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"245.355299\" xlink:href=\"#m6f2f99ee68\" y=\"183.33084\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"102.010224\" xlink:href=\"#m6f2f99ee68\" y=\"68.005257\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"98.914098\" xlink:href=\"#m6f2f99ee68\" y=\"70.755643\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"262.469315\" xlink:href=\"#m6f2f99ee68\" y=\"208.828836\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"232.764406\" xlink:href=\"#m6f2f99ee68\" y=\"179.545819\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"85.660167\" xlink:href=\"#m6f2f99ee68\" y=\"55.297348\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"115.932552\" xlink:href=\"#m6f2f99ee68\" y=\"57.352621\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"119.367708\" xlink:href=\"#m6f2f99ee68\" y=\"39.753775\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"245.559437\" xlink:href=\"#m6f2f99ee68\" y=\"205.799575\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"86.16558\" xlink:href=\"#m6f2f99ee68\" y=\"59.456289\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"230.339153\" xlink:href=\"#m6f2f99ee68\" y=\"184.725889\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"101.093971\" xlink:href=\"#m6f2f99ee68\" y=\"72.97568\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"109.002647\" xlink:href=\"#m6f2f99ee68\" y=\"49.599445\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"107.909658\" xlink:href=\"#m6f2f99ee68\" y=\"53.04751\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"221.52822\" xlink:href=\"#m6f2f99ee68\" y=\"185.625392\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"86.159265\" xlink:href=\"#m6f2f99ee68\" y=\"76.979359\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"106.719623\" xlink:href=\"#m6f2f99ee68\" y=\"47.632849\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"213.246003\" xlink:href=\"#m6f2f99ee68\" y=\"181.675673\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"240.008649\" xlink:href=\"#m6f2f99ee68\" y=\"210.063284\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"104.149069\" xlink:href=\"#m6f2f99ee68\" y=\"48.142529\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"110.455243\" xlink:href=\"#m6f2f99ee68\" y=\"67.262491\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"220.144636\" xlink:href=\"#m6f2f99ee68\" y=\"194.581985\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"211.640596\" xlink:href=\"#m6f2f99ee68\" y=\"197.278796\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"107.637359\" xlink:href=\"#m6f2f99ee68\" y=\"61.841289\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"63.534517\" xlink:href=\"#m6f2f99ee68\" y=\"69.010581\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"93.062578\" xlink:href=\"#m6f2f99ee68\" y=\"76.940427\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"110.711384\" xlink:href=\"#m6f2f99ee68\" y=\"51.587615\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"88.755485\" xlink:href=\"#m6f2f99ee68\" y=\"62.694493\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"95.262724\" xlink:href=\"#m6f2f99ee68\" y=\"55.240035\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"111.341492\" xlink:href=\"#m6f2f99ee68\" y=\"67.732333\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"258.54643\" xlink:href=\"#m6f2f99ee68\" y=\"201.788971\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"80.99024\" xlink:href=\"#m6f2f99ee68\" y=\"39.319229\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"259.276624\" xlink:href=\"#m6f2f99ee68\" y=\"184.484016\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"246.017287\" xlink:href=\"#m6f2f99ee68\" y=\"171.336552\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"215.702515\" xlink:href=\"#m6f2f99ee68\" y=\"210.770601\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"219.61596\" xlink:href=\"#m6f2f99ee68\" y=\"226.724914\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"99.475157\" xlink:href=\"#m6f2f99ee68\" y=\"40.818617\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"222.319345\" xlink:href=\"#m6f2f99ee68\" y=\"178.431076\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"209.011362\" xlink:href=\"#m6f2f99ee68\" y=\"164.49609\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"85.714514\" xlink:href=\"#m6f2f99ee68\" y=\"46.591554\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"109.548621\" xlink:href=\"#m6f2f99ee68\" y=\"59.318354\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"248.253075\" xlink:href=\"#m6f2f99ee68\" y=\"183.765191\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"93.252248\" xlink:href=\"#m6f2f99ee68\" y=\"50.871243\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"105.204158\" xlink:href=\"#m6f2f99ee68\" y=\"61.049791\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"103.603578\" xlink:href=\"#m6f2f99ee68\" y=\"64.288037\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"231.755146\" xlink:href=\"#m6f2f99ee68\" y=\"176.642577\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"239.712924\" xlink:href=\"#m6f2f99ee68\" y=\"167.421426\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"248.56813\" xlink:href=\"#m6f2f99ee68\" y=\"184.651214\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"136.036725\" xlink:href=\"#m6f2f99ee68\" y=\"58.775961\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"214.954778\" xlink:href=\"#m6f2f99ee68\" y=\"213.049411\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"266.443608\" xlink:href=\"#m6f2f99ee68\" y=\"212.097698\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"228.067567\" xlink:href=\"#m6f2f99ee68\" y=\"209.064452\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"89.68311\" xlink:href=\"#m6f2f99ee68\" y=\"69.273533\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"87.428766\" xlink:href=\"#m6f2f99ee68\" y=\"58.77272\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"250.936693\" xlink:href=\"#m6f2f99ee68\" y=\"211.938418\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"87.867838\" xlink:href=\"#m6f2f99ee68\" y=\"66.205754\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"73.777213\" xlink:href=\"#m6f2f99ee68\" y=\"61.2591\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"117.555359\" xlink:href=\"#m6f2f99ee68\" y=\"48.087733\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"90.852757\" xlink:href=\"#m6f2f99ee68\" y=\"51.062813\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"258.598101\" xlink:href=\"#m6f2f99ee68\" y=\"209.454152\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"210.562353\" xlink:href=\"#m6f2f99ee68\" y=\"191.426962\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"99.36688\" xlink:href=\"#m6f2f99ee68\" y=\"44.037528\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"255.847203\" xlink:href=\"#m6f2f99ee68\" y=\"207.03156\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 53.389062 239.229375 \n",
       "L 53.389062 21.789375 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 276.589063 239.229375 \n",
       "L 276.589063 21.789375 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 53.389063 239.229375 \n",
       "L 276.589062 239.229375 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 53.389063 21.789375 \n",
       "L 276.589062 21.789375 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n",
       "   </g>\n",
       "   <g id=\"text_14\">\n",
       "    <!-- Dataset samples -->\n",
       "    <g style=\"fill:#262626;\" transform=\"translate(120.305 15.789375)scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path d=\"M 7.71875 0 \n",
       "L 7.71875 71.578125 \n",
       "L 32.375 71.578125 \n",
       "Q 40.71875 71.578125 45.125 70.5625 \n",
       "Q 51.265625 69.140625 55.609375 65.4375 \n",
       "Q 61.28125 60.640625 64.078125 53.1875 \n",
       "Q 66.890625 45.75 66.890625 36.1875 \n",
       "Q 66.890625 28.03125 64.984375 21.734375 \n",
       "Q 63.09375 15.4375 60.109375 11.296875 \n",
       "Q 57.125 7.171875 53.578125 4.796875 \n",
       "Q 50.046875 2.4375 45.046875 1.21875 \n",
       "Q 40.046875 0 33.546875 0 \n",
       "z\n",
       "M 17.1875 8.453125 \n",
       "L 32.46875 8.453125 \n",
       "Q 39.546875 8.453125 43.578125 9.765625 \n",
       "Q 47.609375 11.078125 50 13.484375 \n",
       "Q 53.375 16.84375 55.25 22.53125 \n",
       "Q 57.125 28.21875 57.125 36.328125 \n",
       "Q 57.125 47.5625 53.4375 53.59375 \n",
       "Q 49.75 59.625 44.484375 61.671875 \n",
       "Q 40.671875 63.140625 32.234375 63.140625 \n",
       "L 17.1875 63.140625 \n",
       "z\n",
       "\" id=\"ArialMT-68\"/>\n",
       "      <path d=\"M 40.4375 6.390625 \n",
       "Q 35.546875 2.25 31.03125 0.53125 \n",
       "Q 26.515625 -1.171875 21.34375 -1.171875 \n",
       "Q 12.796875 -1.171875 8.203125 3 \n",
       "Q 3.609375 7.171875 3.609375 13.671875 \n",
       "Q 3.609375 17.484375 5.34375 20.625 \n",
       "Q 7.078125 23.78125 9.890625 25.6875 \n",
       "Q 12.703125 27.59375 16.21875 28.5625 \n",
       "Q 18.796875 29.25 24.03125 29.890625 \n",
       "Q 34.671875 31.15625 39.703125 32.90625 \n",
       "Q 39.75 34.71875 39.75 35.203125 \n",
       "Q 39.75 40.578125 37.25 42.78125 \n",
       "Q 33.890625 45.75 27.25 45.75 \n",
       "Q 21.046875 45.75 18.09375 43.578125 \n",
       "Q 15.140625 41.40625 13.71875 35.890625 \n",
       "L 5.125 37.0625 \n",
       "Q 6.296875 42.578125 8.984375 45.96875 \n",
       "Q 11.671875 49.359375 16.75 51.1875 \n",
       "Q 21.828125 53.03125 28.515625 53.03125 \n",
       "Q 35.15625 53.03125 39.296875 51.46875 \n",
       "Q 43.453125 49.90625 45.40625 47.53125 \n",
       "Q 47.359375 45.171875 48.140625 41.546875 \n",
       "Q 48.578125 39.3125 48.578125 33.453125 \n",
       "L 48.578125 21.734375 \n",
       "Q 48.578125 9.46875 49.140625 6.21875 \n",
       "Q 49.703125 2.984375 51.375 0 \n",
       "L 42.1875 0 \n",
       "Q 40.828125 2.734375 40.4375 6.390625 \n",
       "z\n",
       "M 39.703125 26.03125 \n",
       "Q 34.90625 24.078125 25.34375 22.703125 \n",
       "Q 19.921875 21.921875 17.671875 20.9375 \n",
       "Q 15.4375 19.96875 14.203125 18.09375 \n",
       "Q 12.984375 16.21875 12.984375 13.921875 \n",
       "Q 12.984375 10.40625 15.640625 8.0625 \n",
       "Q 18.3125 5.71875 23.4375 5.71875 \n",
       "Q 28.515625 5.71875 32.46875 7.9375 \n",
       "Q 36.421875 10.15625 38.28125 14.015625 \n",
       "Q 39.703125 17 39.703125 22.796875 \n",
       "z\n",
       "\" id=\"ArialMT-97\"/>\n",
       "      <path d=\"M 25.78125 7.859375 \n",
       "L 27.046875 0.09375 \n",
       "Q 23.34375 -0.6875 20.40625 -0.6875 \n",
       "Q 15.625 -0.6875 12.984375 0.828125 \n",
       "Q 10.359375 2.34375 9.28125 4.8125 \n",
       "Q 8.203125 7.28125 8.203125 15.1875 \n",
       "L 8.203125 45.015625 \n",
       "L 1.765625 45.015625 \n",
       "L 1.765625 51.859375 \n",
       "L 8.203125 51.859375 \n",
       "L 8.203125 64.703125 \n",
       "L 16.9375 69.96875 \n",
       "L 16.9375 51.859375 \n",
       "L 25.78125 51.859375 \n",
       "L 25.78125 45.015625 \n",
       "L 16.9375 45.015625 \n",
       "L 16.9375 14.703125 \n",
       "Q 16.9375 10.9375 17.40625 9.859375 \n",
       "Q 17.875 8.796875 18.921875 8.15625 \n",
       "Q 19.96875 7.515625 21.921875 7.515625 \n",
       "Q 23.390625 7.515625 25.78125 7.859375 \n",
       "z\n",
       "\" id=\"ArialMT-116\"/>\n",
       "      <path d=\"M 3.078125 15.484375 \n",
       "L 11.765625 16.84375 \n",
       "Q 12.5 11.625 15.84375 8.84375 \n",
       "Q 19.1875 6.0625 25.203125 6.0625 \n",
       "Q 31.25 6.0625 34.171875 8.515625 \n",
       "Q 37.109375 10.984375 37.109375 14.3125 \n",
       "Q 37.109375 17.28125 34.515625 19 \n",
       "Q 32.71875 20.171875 25.53125 21.96875 \n",
       "Q 15.875 24.421875 12.140625 26.203125 \n",
       "Q 8.40625 27.984375 6.46875 31.125 \n",
       "Q 4.546875 34.28125 4.546875 38.09375 \n",
       "Q 4.546875 41.546875 6.125 44.5 \n",
       "Q 7.71875 47.46875 10.453125 49.421875 \n",
       "Q 12.5 50.921875 16.03125 51.96875 \n",
       "Q 19.578125 53.03125 23.640625 53.03125 \n",
       "Q 29.734375 53.03125 34.34375 51.265625 \n",
       "Q 38.96875 49.515625 41.15625 46.5 \n",
       "Q 43.359375 43.5 44.1875 38.484375 \n",
       "L 35.59375 37.3125 \n",
       "Q 35.015625 41.3125 32.203125 43.546875 \n",
       "Q 29.390625 45.796875 24.265625 45.796875 \n",
       "Q 18.21875 45.796875 15.625 43.796875 \n",
       "Q 13.03125 41.796875 13.03125 39.109375 \n",
       "Q 13.03125 37.40625 14.109375 36.03125 \n",
       "Q 15.1875 34.625 17.484375 33.6875 \n",
       "Q 18.796875 33.203125 25.25 31.453125 \n",
       "Q 34.578125 28.953125 38.25 27.359375 \n",
       "Q 41.9375 25.78125 44.03125 22.75 \n",
       "Q 46.140625 19.734375 46.140625 15.234375 \n",
       "Q 46.140625 10.84375 43.578125 6.953125 \n",
       "Q 41.015625 3.078125 36.171875 0.953125 \n",
       "Q 31.34375 -1.171875 25.25 -1.171875 \n",
       "Q 15.140625 -1.171875 9.84375 3.03125 \n",
       "Q 4.546875 7.234375 3.078125 15.484375 \n",
       "z\n",
       "\" id=\"ArialMT-115\"/>\n",
       "      <path d=\"M 42.09375 16.703125 \n",
       "L 51.171875 15.578125 \n",
       "Q 49.03125 7.625 43.21875 3.21875 \n",
       "Q 37.40625 -1.171875 28.375 -1.171875 \n",
       "Q 17 -1.171875 10.328125 5.828125 \n",
       "Q 3.65625 12.84375 3.65625 25.484375 \n",
       "Q 3.65625 38.578125 10.390625 45.796875 \n",
       "Q 17.140625 53.03125 27.875 53.03125 \n",
       "Q 38.28125 53.03125 44.875 45.953125 \n",
       "Q 51.46875 38.875 51.46875 26.03125 \n",
       "Q 51.46875 25.25 51.421875 23.6875 \n",
       "L 12.75 23.6875 \n",
       "Q 13.234375 15.140625 17.578125 10.59375 \n",
       "Q 21.921875 6.0625 28.421875 6.0625 \n",
       "Q 33.25 6.0625 36.671875 8.59375 \n",
       "Q 40.09375 11.140625 42.09375 16.703125 \n",
       "z\n",
       "M 13.234375 30.90625 \n",
       "L 42.1875 30.90625 \n",
       "Q 41.609375 37.453125 38.875 40.71875 \n",
       "Q 34.671875 45.796875 27.984375 45.796875 \n",
       "Q 21.921875 45.796875 17.796875 41.75 \n",
       "Q 13.671875 37.703125 13.234375 30.90625 \n",
       "z\n",
       "\" id=\"ArialMT-101\"/>\n",
       "      <path id=\"ArialMT-32\"/>\n",
       "      <path d=\"M 6.59375 0 \n",
       "L 6.59375 51.859375 \n",
       "L 14.453125 51.859375 \n",
       "L 14.453125 44.578125 \n",
       "Q 16.890625 48.390625 20.9375 50.703125 \n",
       "Q 25 53.03125 30.171875 53.03125 \n",
       "Q 35.9375 53.03125 39.625 50.640625 \n",
       "Q 43.3125 48.25 44.828125 43.953125 \n",
       "Q 50.984375 53.03125 60.84375 53.03125 \n",
       "Q 68.5625 53.03125 72.703125 48.75 \n",
       "Q 76.859375 44.484375 76.859375 35.59375 \n",
       "L 76.859375 0 \n",
       "L 68.109375 0 \n",
       "L 68.109375 32.671875 \n",
       "Q 68.109375 37.9375 67.25 40.25 \n",
       "Q 66.40625 42.578125 64.15625 43.984375 \n",
       "Q 61.921875 45.40625 58.890625 45.40625 \n",
       "Q 53.421875 45.40625 49.796875 41.765625 \n",
       "Q 46.1875 38.140625 46.1875 30.125 \n",
       "L 46.1875 0 \n",
       "L 37.40625 0 \n",
       "L 37.40625 33.6875 \n",
       "Q 37.40625 39.546875 35.25 42.46875 \n",
       "Q 33.109375 45.40625 28.21875 45.40625 \n",
       "Q 24.515625 45.40625 21.359375 43.453125 \n",
       "Q 18.21875 41.5 16.796875 37.734375 \n",
       "Q 15.375 33.984375 15.375 26.90625 \n",
       "L 15.375 0 \n",
       "z\n",
       "\" id=\"ArialMT-109\"/>\n",
       "      <path d=\"M 6.59375 -19.875 \n",
       "L 6.59375 51.859375 \n",
       "L 14.59375 51.859375 \n",
       "L 14.59375 45.125 \n",
       "Q 17.4375 49.078125 21 51.046875 \n",
       "Q 24.5625 53.03125 29.640625 53.03125 \n",
       "Q 36.28125 53.03125 41.359375 49.609375 \n",
       "Q 46.4375 46.1875 49.015625 39.953125 \n",
       "Q 51.609375 33.734375 51.609375 26.3125 \n",
       "Q 51.609375 18.359375 48.75 11.984375 \n",
       "Q 45.90625 5.609375 40.453125 2.21875 \n",
       "Q 35.015625 -1.171875 29 -1.171875 \n",
       "Q 24.609375 -1.171875 21.109375 0.6875 \n",
       "Q 17.625 2.546875 15.375 5.375 \n",
       "L 15.375 -19.875 \n",
       "z\n",
       "M 14.546875 25.640625 \n",
       "Q 14.546875 15.625 18.59375 10.84375 \n",
       "Q 22.65625 6.0625 28.421875 6.0625 \n",
       "Q 34.28125 6.0625 38.453125 11.015625 \n",
       "Q 42.625 15.96875 42.625 26.375 \n",
       "Q 42.625 36.28125 38.546875 41.203125 \n",
       "Q 34.46875 46.140625 28.8125 46.140625 \n",
       "Q 23.1875 46.140625 18.859375 40.890625 \n",
       "Q 14.546875 35.640625 14.546875 25.640625 \n",
       "z\n",
       "\" id=\"ArialMT-112\"/>\n",
       "      <path d=\"M 6.390625 0 \n",
       "L 6.390625 71.578125 \n",
       "L 15.1875 71.578125 \n",
       "L 15.1875 0 \n",
       "z\n",
       "\" id=\"ArialMT-108\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#ArialMT-68\"/>\n",
       "     <use x=\"72.216797\" xlink:href=\"#ArialMT-97\"/>\n",
       "     <use x=\"127.832031\" xlink:href=\"#ArialMT-116\"/>\n",
       "     <use x=\"155.615234\" xlink:href=\"#ArialMT-97\"/>\n",
       "     <use x=\"211.230469\" xlink:href=\"#ArialMT-115\"/>\n",
       "     <use x=\"261.230469\" xlink:href=\"#ArialMT-101\"/>\n",
       "     <use x=\"316.845703\" xlink:href=\"#ArialMT-116\"/>\n",
       "     <use x=\"344.628906\" xlink:href=\"#ArialMT-32\"/>\n",
       "     <use x=\"372.412109\" xlink:href=\"#ArialMT-115\"/>\n",
       "     <use x=\"422.412109\" xlink:href=\"#ArialMT-97\"/>\n",
       "     <use x=\"478.027344\" xlink:href=\"#ArialMT-109\"/>\n",
       "     <use x=\"561.328125\" xlink:href=\"#ArialMT-112\"/>\n",
       "     <use x=\"616.943359\" xlink:href=\"#ArialMT-108\"/>\n",
       "     <use x=\"639.160156\" xlink:href=\"#ArialMT-101\"/>\n",
       "     <use x=\"694.775391\" xlink:href=\"#ArialMT-115\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 197.010937 147.719219 \n",
       "L 268.889063 147.719219 \n",
       "Q 271.089063 147.719219 271.089063 145.519219 \n",
       "L 271.089063 115.499531 \n",
       "Q 271.089063 113.299531 268.889063 113.299531 \n",
       "L 197.010937 113.299531 \n",
       "Q 194.810937 113.299531 194.810937 115.499531 \n",
       "L 194.810937 145.519219 \n",
       "Q 194.810937 147.719219 197.010937 147.719219 \n",
       "z\n",
       "\" style=\"fill:#eaeaf2;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n",
       "    </g>\n",
       "    <g id=\"PathCollection_3\">\n",
       "     <g>\n",
       "      <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"210.210938\" xlink:href=\"#m4bbbbefdf1\" y=\"122.685625\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_15\">\n",
       "     <!-- Class 0 -->\n",
       "     <g style=\"fill:#262626;\" transform=\"translate(230.010938 125.573125)scale(0.11 -0.11)\">\n",
       "      <defs>\n",
       "       <path d=\"M 58.796875 25.09375 \n",
       "L 68.265625 22.703125 \n",
       "Q 65.28125 11.03125 57.546875 4.90625 \n",
       "Q 49.8125 -1.21875 38.625 -1.21875 \n",
       "Q 27.046875 -1.21875 19.796875 3.484375 \n",
       "Q 12.546875 8.203125 8.765625 17.140625 \n",
       "Q 4.984375 26.078125 4.984375 36.328125 \n",
       "Q 4.984375 47.515625 9.25 55.828125 \n",
       "Q 13.53125 64.15625 21.40625 68.46875 \n",
       "Q 29.296875 72.796875 38.765625 72.796875 \n",
       "Q 49.515625 72.796875 56.828125 67.328125 \n",
       "Q 64.15625 61.859375 67.046875 51.953125 \n",
       "L 57.71875 49.75 \n",
       "Q 55.21875 57.5625 50.484375 61.125 \n",
       "Q 45.75 64.703125 38.578125 64.703125 \n",
       "Q 30.328125 64.703125 24.78125 60.734375 \n",
       "Q 19.234375 56.78125 16.984375 50.109375 \n",
       "Q 14.75 43.453125 14.75 36.375 \n",
       "Q 14.75 27.25 17.40625 20.4375 \n",
       "Q 20.0625 13.625 25.671875 10.25 \n",
       "Q 31.296875 6.890625 37.84375 6.890625 \n",
       "Q 45.796875 6.890625 51.3125 11.46875 \n",
       "Q 56.84375 16.0625 58.796875 25.09375 \n",
       "z\n",
       "\" id=\"ArialMT-67\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#ArialMT-67\"/>\n",
       "      <use x=\"72.216797\" xlink:href=\"#ArialMT-108\"/>\n",
       "      <use x=\"94.433594\" xlink:href=\"#ArialMT-97\"/>\n",
       "      <use x=\"150.048828\" xlink:href=\"#ArialMT-115\"/>\n",
       "      <use x=\"200.048828\" xlink:href=\"#ArialMT-115\"/>\n",
       "      <use x=\"250.048828\" xlink:href=\"#ArialMT-32\"/>\n",
       "      <use x=\"277.832031\" xlink:href=\"#ArialMT-48\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"PathCollection_4\">\n",
       "     <g>\n",
       "      <use style=\"fill:#dd8452;stroke:#333333;\" x=\"210.210938\" xlink:href=\"#m6f2f99ee68\" y=\"138.245469\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_16\">\n",
       "     <!-- Class 1 -->\n",
       "     <g style=\"fill:#262626;\" transform=\"translate(230.010938 141.132969)scale(0.11 -0.11)\">\n",
       "      <use xlink:href=\"#ArialMT-67\"/>\n",
       "      <use x=\"72.216797\" xlink:href=\"#ArialMT-108\"/>\n",
       "      <use x=\"94.433594\" xlink:href=\"#ArialMT-97\"/>\n",
       "      <use x=\"150.048828\" xlink:href=\"#ArialMT-115\"/>\n",
       "      <use x=\"200.048828\" xlink:href=\"#ArialMT-115\"/>\n",
       "      <use x=\"250.048828\" xlink:href=\"#ArialMT-32\"/>\n",
       "      <use x=\"277.832031\" xlink:href=\"#ArialMT-49\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pc28445eaad\">\n",
       "   <rect height=\"217.44\" width=\"223.2\" x=\"53.389062\" y=\"21.789375\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_samples(dataset.data, dataset.label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The data loader class\n",
    "\n",
    "The class `torch.utils.data.DataLoader` represents a Python iterable over a dataset with support for automatic batching, multi-process data loading and many more features. The data loader communicates with the dataset using the function `__getitem__`, and stacks its outputs as tensors over the first dimension to form a batch.\n",
    "In contrast to the dataset class, we usually don't have to define our own data loader class, but can just create an object of it with the dataset as input. Additionally, we can configure our data loader with the following input arguments (only a selection, see full list [here](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)):\n",
    "\n",
    "* `batch_size`: Number of samples to stack per batch\n",
    "* `shuffle`: If True, the data is returned in a random order. This is important during training for introducing stochasticity. \n",
    "* `num_workers`: Number of subprocesses to use for data loading. The default, 0, means that the data will be loaded in the main process which can slow down training for datasets where loading a data point takes a considerable amount of time (e.g. large images). More workers are recommended for those, but can cause issues on Windows computers. For tiny datasets as ours, 0 workers are usually faster.\n",
    "* `pin_memory`: If True, the data loader will copy Tensors into CUDA pinned memory before returning them. This can save some time for large data points on GPUs. Usually a good practice to use for a training set, but not necessarily for validation and test to save memory on the GPU.\n",
    "* `drop_last`: If True, the last batch is dropped in case it is smaller than the specified batch size. This occurs when the dataset size is not a multiple of the batch size. Only potentially helpful during training to keep a consistent batch size.\n",
    "\n",
    "Let's create a simple data loader below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = data.DataLoader(dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inputs torch.Size([8, 2]) \n",
      " tensor([[ 0.9717,  0.9721],\n",
      "        [ 0.0062,  1.0995],\n",
      "        [-0.0020, -0.0853],\n",
      "        [ 0.0368,  0.9528],\n",
      "        [ 1.0661,  0.9880],\n",
      "        [-0.0715,  0.1935],\n",
      "        [ 0.0765,  0.9931],\n",
      "        [ 0.0678,  1.0342]])\n",
      "Data labels torch.Size([8]) \n",
      " tensor([0, 1, 0, 1, 0, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# next(iter(...)) catches the first batch of the data loader\n",
    "# If shuffle is True, this will return a different batch every time we run this cell\n",
    "# For iterating over the whole dataset, we can simple use \"for batch in data_loader: ...\"\n",
    "data_inputs, data_labels = next(iter(data_loader))\n",
    "\n",
    "# The shape of the outputs are [batch_size, d_1,...,d_N] where d_1,...,d_N are the \n",
    "# dimensions of the data point returned from the dataset class\n",
    "print(\"Data inputs\", data_inputs.shape, \"\\n\", data_inputs)\n",
    "print(\"Data labels\", data_labels.shape, \"\\n\", data_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization\n",
    "\n",
    "After defining the model and the dataset, it is time to prepare the optimization of the model. During training, we will perform the following steps:\n",
    "\n",
    "1. Get a batch from the data loader\n",
    "2. Obtain the predictions from the model for the batch\n",
    "3. Calculate the loss based on the difference between predictions and labels\n",
    "4. Backpropagation: calculate the gradients for every parameter with respect to the loss\n",
    "5. Update the parameters of the model in the direction of the gradients\n",
    "\n",
    "We have seen how we can do step 1, 2 and 4 in PyTorch. Now, we will look at step 3 and 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss modules\n",
    "\n",
    "We can calculate the loss for a batch by simply performing a few tensor operations as those are automatically added to the computation graph. For instance, for binary classification, we can use Binary Cross Entropy (BCE) which is defined as follows:\n",
    "\n",
    "$$\\mathcal{L}_{BCE} = -\\sum_i \\left[ y_i \\log x_i + (1 - y_i) \\log (1 - x_i) \\right]$$\n",
    "\n",
    "where $y$ are our labels, and $x$ our predictions, both in the range of $[0,1]$. However, PyTorch already provides a list of predefined loss functions which we can use (see [here](https://pytorch.org/docs/stable/nn.html#loss-functions) for a full list). For instance, for BCE, PyTorch has two modules: `nn.BCELoss()`, `nn.BCEWithLogitsLoss()`. While `nn.BCELoss` expects the inputs $x$ to be in the range $[0,1]$, i.e. the output of a sigmoid, `nn.BCEWithLogitsLoss` combines a sigmoid layer and the BCE loss in a single class. This version is numerically more stable than using a plain Sigmoid followed by a BCE loss because of the logarithms applied in the loss function. Hence, it is adviced to use loss functions applied on \"logits\" where possible (remember to not apply a sigmoid on the output of the model in this case!). For our model defined above, we therefore use the module `nn.BCEWithLogitsLoss`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_module = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stochastic Gradient Descent\n",
    "\n",
    "For updating the parameters, PyTorch provides the package `torch.optim` that has most popular optimizers implemented. We will discuss the specific optimizers and their differences later in the course, but will for now use the simplest of them: `torch.optim.SGD`. Stochastic Gradient Descent updates parameters by multiplying the gradients with a small constant, called learning rate, and subtracting those from the parameters (hence minimizing the loss). Therefore, we slowly move towards the direction of minimizing the loss. A good default value of the learning rate for a small network as ours is 0.1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input to the optimizer are the parameters of the model: model.parameters()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimizer provides two useful functions: `optimizer.step()`, and `optimizer.zero_grad()`. The step function updates the parameters based on the gradients as explained above. The function `optimizer.zero_grad()` sets the gradients of all parameters to zero. While this function seems less relevant at first, it is a crucial pre-step before performing backpropagation. If we would call the `backward` function on the loss while the parameter gradients are non-zero from the previous batch, the new gradients would actually be added to the previous ones instead of overwriting them. This is done because a parameter might occur multiple times in a computation graph, and we need to sum the gradients in this case instead of replacing them. Hence, remember to call `optimizer.zero_grad()` before calculating the gradients of a batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Finally, we are ready to train our model. As a first step, we create a slightly larger dataset and specify a data loader with a larger batch size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = XORDataset(size=1000)\n",
    "train_data_loader = data.DataLoader(train_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can write a small training function. Remember our five steps: load a batch, obtain the predictions, calculate the loss, backpropagate, and update. Additionally, we have to push all data and model parameters to the device of our choice (GPU if available). For the tiny neural network we have, communicating the data to the GPU actually takes much more time than we could save from running the operation on GPU. For large networks, the communication time is significantly smaller than the actual runtime making a GPU crucial in these cases. Still, to practice, we will push the data to GPU here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleClassifier(\n",
       "  (linear1): Linear(in_features=2, out_features=4, bias=True)\n",
       "  (act_fn): Tanh()\n",
       "  (linear2): Linear(in_features=4, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Push model to device. Has to be only done once\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we set our model to training mode. This is done by calling `model.train()`. There exist certain modules that need to perform a different forward step during training than during testing (e.g. BatchNorm and Dropout), and we can switch between them using `model.train()` and `model.eval()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, data_loader, loss_module, num_epochs=100):\n",
    "    # Set model to train mode\n",
    "    model.train() \n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        for data_inputs, data_labels in data_loader:\n",
    "            \n",
    "            ## Step 1: Move input data to device (only strictly necessary if we use GPU)\n",
    "            data_inputs = data_inputs.to(device)\n",
    "            data_labels = data_labels.to(device)\n",
    "            \n",
    "            ## Step 2: Run the model on the input data\n",
    "            preds = model(data_inputs)\n",
    "            preds = preds.squeeze(dim=1) # Output is [Batch size, 1], but we want [Batch size]\n",
    "            \n",
    "            ## Step 3: Calculate the loss\n",
    "            loss = loss_module(preds, data_labels.float())\n",
    "            \n",
    "            ## Step 4: Perform backpropagation\n",
    "            # Before calculating the gradients, we need to ensure that they are all zero. \n",
    "            # The gradients would not be overwritten, but actually added to the existing ones.\n",
    "            optimizer.zero_grad() \n",
    "            # Perform backpropagation\n",
    "            loss.backward()\n",
    "            \n",
    "            ## Step 5: Update the parameters\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d531dc0268c48d2ae7764a5ab20d6f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model, optimizer, train_data_loader, loss_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving a model\n",
    "\n",
    "After finish training a model, we save the model to disk so that we can load the same weights at a later time. For this, we extract the so-called `state_dict` from the model which contains all learnable parameters. For our simple model, the state dict contains the following entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('linear1.weight', tensor([[-2.0565, -2.2963],\n",
      "        [ 1.2971, -1.8472],\n",
      "        [-1.5020, -0.4974],\n",
      "        [-0.6973, -0.8355]], device='cuda:0')), ('linear1.bias', tensor([ 0.7125, -0.8742,  1.2787, -0.2221], device='cuda:0')), ('linear2.weight', tensor([[-2.5847,  1.9542,  2.1130, -0.3597]], device='cuda:0')), ('linear2.bias', tensor([-0.9603], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "state_dict = model.state_dict()\n",
    "print(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save the state dictionary, we can use `torch.save`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(object, filename). For the filename, any extension can be used\n",
    "torch.save(state_dict, \"our_model.tar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load a model from a state dict, we use the function `torch.load` to load the state dict from the disk, and the module function `load_state_dict` to overwrite our parameters with the new values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model\n",
      " OrderedDict([('linear1.weight', tensor([[-2.0565, -2.2963],\n",
      "        [ 1.2971, -1.8472],\n",
      "        [-1.5020, -0.4974],\n",
      "        [-0.6973, -0.8355]], device='cuda:0')), ('linear1.bias', tensor([ 0.7125, -0.8742,  1.2787, -0.2221], device='cuda:0')), ('linear2.weight', tensor([[-2.5847,  1.9542,  2.1130, -0.3597]], device='cuda:0')), ('linear2.bias', tensor([-0.9603], device='cuda:0'))])\n",
      "\n",
      "Loaded model\n",
      " OrderedDict([('linear1.weight', tensor([[-2.0565, -2.2963],\n",
      "        [ 1.2971, -1.8472],\n",
      "        [-1.5020, -0.4974],\n",
      "        [-0.6973, -0.8355]])), ('linear1.bias', tensor([ 0.7125, -0.8742,  1.2787, -0.2221])), ('linear2.weight', tensor([[-2.5847,  1.9542,  2.1130, -0.3597]])), ('linear2.bias', tensor([-0.9603]))])\n"
     ]
    }
   ],
   "source": [
    "# Load state dict from the disk (make sure it is the same name as above)\n",
    "state_dict = torch.load(\"our_model.tar\")\n",
    "\n",
    "# Create a new model and load the state\n",
    "new_model = SimpleClassifier(num_inputs=2, num_hidden=4, num_outputs=1)\n",
    "new_model.load_state_dict(state_dict)\n",
    "\n",
    "# Verify that the parameters are the same\n",
    "print(\"Original model\\n\", model.state_dict())\n",
    "print(\"\\nLoaded model\\n\", new_model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A detailed tutorial on saving and loading models in PyTorch can be found [here](https://pytorch.org/tutorials/beginner/saving_loading_models.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "Once we have trained a model, it is time to evaluate it on a held-out test set. As our dataset consist of randomly generated data points, we need to first create a test set with a corresponding data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = XORDataset(size=500)\n",
    "# drop_last -> Don't drop the last batch although it is smaller than 128\n",
    "test_data_loader = data.DataLoader(test_dataset, batch_size=128, shuffle=False, drop_last=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As metric, we will use accuracy which is calculated as follows:\n",
    "\n",
    "$$acc = \\frac{\\#\\text{correct predictions}}{\\#\\text{all predictions}} = \\frac{TP+TN}{TP+TN+FP+FN}$$\n",
    "\n",
    "where TP are the true positives, TN true negatives, FP false positives, and FN the fale negatives. \n",
    "\n",
    "When evaluating the model, we don't need to keep track of the computation graph as we don't intend to calculate the gradients. This reduces the required memory and speed up the model. In PyTorch, we can deactivate the computation graph using `with torch.no_grad(): ...`. Remember to additionally set the model to eval mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader):\n",
    "    model.eval() # Set model to eval mode\n",
    "    true_preds, num_preds = 0., 0.\n",
    "    \n",
    "    with torch.no_grad(): # Deactivate gradients for the following code\n",
    "        for data_inputs, data_labels in data_loader:\n",
    "            \n",
    "            # Determine prediction of model on dev set\n",
    "            data_inputs, data_labels = data_inputs.to(device), data_labels.to(device)\n",
    "            preds = model(data_inputs)\n",
    "            preds = preds.squeeze(dim=1)\n",
    "            preds = torch.sigmoid(preds) # Sigmoid to map predictions between 0 and 1\n",
    "            pred_labels = (preds >= 0.5).long() # Binarize predictions to 0 and 1\n",
    "            \n",
    "            # Keep records of predictions for the accuracy metric (true_preds=TP+TN, num_preds=TP+TN+FP+FN)\n",
    "            true_preds += (pred_labels == data_labels).sum()\n",
    "            num_preds += data_labels.shape[0]\n",
    "            \n",
    "    acc = true_preds / num_preds\n",
    "    print(f\"Accuracy of the model: {100.0*acc:4.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 100.00%\n"
     ]
    }
   ],
   "source": [
    "eval_model(model, test_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we trained our model correctly, we should see a score close to 100% accuracy. However, this is only possible because of our simple task, and unfortunately, we usually don't get such high scores on test sets of more complex tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing classification boundaries\n",
    "\n",
    "To visualize what our model has learned, we can perform a prediction for every data point in a range of $[-0.5, 1.5]$, and visualize the predicted class as in the sample figure at the beginning of this section. This shows where the model has created decision boundaries, and which points would be classified as $0$, and which as $1$. We therefore get a background image out of blue (class 0) and orange (class 1). The spots where the model is uncertain we will see a blurry overlap. The specific code is less relevant compared to the output figure which should hopefully show us a clear separation of classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/pdf": "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\n",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"280.963594pt\" version=\"1.1\" viewBox=\"0 0 291.791094 280.963594\" width=\"291.791094pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2020-11-08T21:41:14.918749</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 280.963594 \n",
       "L 291.791094 280.963594 \n",
       "L 291.791094 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 59.506094 239.229375 \n",
       "L 276.946094 239.229375 \n",
       "L 276.946094 21.789375 \n",
       "L 59.506094 21.789375 \n",
       "z\n",
       "\" style=\"fill:#eaeaf2;\"/>\n",
       "   </g>\n",
       "   <g clip-path=\"url(#p3f2878dc3e)\">\n",
       "    <image height=\"218\" id=\"image2a329c4203\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"59.506094\" xlink:href=\"data:image/png;base64,\n",
       "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\" y=\"-21.229375\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0.5 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(48.64875 256.602969)scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path d=\"M 52.828125 31.203125 \n",
       "L 5.5625 31.203125 \n",
       "L 5.5625 39.40625 \n",
       "L 52.828125 39.40625 \n",
       "z\n",
       "\" id=\"ArialMT-8722\"/>\n",
       "        <path d=\"M 4.15625 35.296875 \n",
       "Q 4.15625 48 6.765625 55.734375 \n",
       "Q 9.375 63.484375 14.515625 67.671875 \n",
       "Q 19.671875 71.875 27.484375 71.875 \n",
       "Q 33.25 71.875 37.59375 69.546875 \n",
       "Q 41.9375 67.234375 44.765625 62.859375 \n",
       "Q 47.609375 58.5 49.21875 52.21875 \n",
       "Q 50.828125 45.953125 50.828125 35.296875 \n",
       "Q 50.828125 22.703125 48.234375 14.96875 \n",
       "Q 45.65625 7.234375 40.5 3 \n",
       "Q 35.359375 -1.21875 27.484375 -1.21875 \n",
       "Q 17.140625 -1.21875 11.234375 6.203125 \n",
       "Q 4.15625 15.140625 4.15625 35.296875 \n",
       "z\n",
       "M 13.1875 35.296875 \n",
       "Q 13.1875 17.671875 17.3125 11.828125 \n",
       "Q 21.4375 6 27.484375 6 \n",
       "Q 33.546875 6 37.671875 11.859375 \n",
       "Q 41.796875 17.71875 41.796875 35.296875 \n",
       "Q 41.796875 52.984375 37.671875 58.78125 \n",
       "Q 33.546875 64.59375 27.390625 64.59375 \n",
       "Q 21.34375 64.59375 17.71875 59.46875 \n",
       "Q 13.1875 52.9375 13.1875 35.296875 \n",
       "z\n",
       "\" id=\"ArialMT-48\"/>\n",
       "        <path d=\"M 9.078125 0 \n",
       "L 9.078125 10.015625 \n",
       "L 19.09375 10.015625 \n",
       "L 19.09375 0 \n",
       "z\n",
       "\" id=\"ArialMT-46\"/>\n",
       "        <path d=\"M 4.15625 18.75 \n",
       "L 13.375 19.53125 \n",
       "Q 14.40625 12.796875 18.140625 9.390625 \n",
       "Q 21.875 6 27.15625 6 \n",
       "Q 33.5 6 37.890625 10.78125 \n",
       "Q 42.28125 15.578125 42.28125 23.484375 \n",
       "Q 42.28125 31 38.0625 35.34375 \n",
       "Q 33.84375 39.703125 27 39.703125 \n",
       "Q 22.75 39.703125 19.328125 37.765625 \n",
       "Q 15.921875 35.84375 13.96875 32.765625 \n",
       "L 5.71875 33.84375 \n",
       "L 12.640625 70.609375 \n",
       "L 48.25 70.609375 \n",
       "L 48.25 62.203125 \n",
       "L 19.671875 62.203125 \n",
       "L 15.828125 42.96875 \n",
       "Q 22.265625 47.46875 29.34375 47.46875 \n",
       "Q 38.71875 47.46875 45.15625 40.96875 \n",
       "Q 51.609375 34.46875 51.609375 24.265625 \n",
       "Q 51.609375 14.546875 45.953125 7.46875 \n",
       "Q 39.0625 -1.21875 27.15625 -1.21875 \n",
       "Q 17.390625 -1.21875 11.203125 4.25 \n",
       "Q 5.03125 9.71875 4.15625 18.75 \n",
       "z\n",
       "\" id=\"ArialMT-53\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-8722\"/>\n",
       "       <use x=\"58.398438\" xlink:href=\"#ArialMT-48\"/>\n",
       "       <use x=\"114.013672\" xlink:href=\"#ArialMT-46\"/>\n",
       "       <use x=\"141.796875\" xlink:href=\"#ArialMT-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 0.0 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(106.221094 256.602969)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-48\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-46\"/>\n",
       "       <use x=\"83.398438\" xlink:href=\"#ArialMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 0.5 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(160.581094 256.602969)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-48\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-46\"/>\n",
       "       <use x=\"83.398438\" xlink:href=\"#ArialMT-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 1.0 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(214.941094 256.602969)scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path d=\"M 37.25 0 \n",
       "L 28.46875 0 \n",
       "L 28.46875 56 \n",
       "Q 25.296875 52.984375 20.140625 49.953125 \n",
       "Q 14.984375 46.921875 10.890625 45.40625 \n",
       "L 10.890625 53.90625 \n",
       "Q 18.265625 57.375 23.78125 62.296875 \n",
       "Q 29.296875 67.234375 31.59375 71.875 \n",
       "L 37.25 71.875 \n",
       "z\n",
       "\" id=\"ArialMT-49\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-49\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-46\"/>\n",
       "       <use x=\"83.398438\" xlink:href=\"#ArialMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 1.5 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(269.301094 256.602969)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-49\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-46\"/>\n",
       "       <use x=\"83.398438\" xlink:href=\"#ArialMT-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_6\">\n",
       "     <!-- $x_1$ -->\n",
       "     <g style=\"fill:#262626;\" transform=\"translate(161.806094 271.378594)scale(0.12 -0.12)\">\n",
       "      <defs>\n",
       "       <path d=\"M 60.015625 54.6875 \n",
       "L 34.90625 27.875 \n",
       "L 50.296875 0 \n",
       "L 39.984375 0 \n",
       "L 28.421875 21.6875 \n",
       "L 8.296875 0 \n",
       "L -2.59375 0 \n",
       "L 24.3125 28.8125 \n",
       "L 10.015625 54.6875 \n",
       "L 20.3125 54.6875 \n",
       "L 30.8125 34.90625 \n",
       "L 49.125 54.6875 \n",
       "z\n",
       "\" id=\"DejaVuSans-Oblique-120\"/>\n",
       "       <path d=\"M 12.40625 8.296875 \n",
       "L 28.515625 8.296875 \n",
       "L 28.515625 63.921875 \n",
       "L 10.984375 60.40625 \n",
       "L 10.984375 69.390625 \n",
       "L 28.421875 72.90625 \n",
       "L 38.28125 72.90625 \n",
       "L 38.28125 8.296875 \n",
       "L 54.390625 8.296875 \n",
       "L 54.390625 0 \n",
       "L 12.40625 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-49\"/>\n",
       "      </defs>\n",
       "      <use transform=\"translate(0 0.3125)\" xlink:href=\"#DejaVuSans-Oblique-120\"/>\n",
       "      <use transform=\"translate(59.179688 -16.09375)scale(0.7)\" xlink:href=\"#DejaVuSans-49\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 0.50 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(22.174375 243.166172)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-8722\"/>\n",
       "       <use x=\"58.398438\" xlink:href=\"#ArialMT-48\"/>\n",
       "       <use x=\"114.013672\" xlink:href=\"#ArialMT-46\"/>\n",
       "       <use x=\"141.796875\" xlink:href=\"#ArialMT-53\"/>\n",
       "       <use x=\"197.412109\" xlink:href=\"#ArialMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.25 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(22.174375 215.986172)scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path d=\"M 50.34375 8.453125 \n",
       "L 50.34375 0 \n",
       "L 3.03125 0 \n",
       "Q 2.9375 3.171875 4.046875 6.109375 \n",
       "Q 5.859375 10.9375 9.828125 15.625 \n",
       "Q 13.8125 20.3125 21.34375 26.46875 \n",
       "Q 33.015625 36.03125 37.109375 41.625 \n",
       "Q 41.21875 47.21875 41.21875 52.203125 \n",
       "Q 41.21875 57.421875 37.46875 61 \n",
       "Q 33.734375 64.59375 27.734375 64.59375 \n",
       "Q 21.390625 64.59375 17.578125 60.78125 \n",
       "Q 13.765625 56.984375 13.71875 50.25 \n",
       "L 4.6875 51.171875 \n",
       "Q 5.609375 61.28125 11.65625 66.578125 \n",
       "Q 17.71875 71.875 27.9375 71.875 \n",
       "Q 38.234375 71.875 44.234375 66.15625 \n",
       "Q 50.25 60.453125 50.25 52 \n",
       "Q 50.25 47.703125 48.484375 43.546875 \n",
       "Q 46.734375 39.40625 42.65625 34.8125 \n",
       "Q 38.578125 30.21875 29.109375 22.21875 \n",
       "Q 21.1875 15.578125 18.9375 13.203125 \n",
       "Q 16.703125 10.84375 15.234375 8.453125 \n",
       "z\n",
       "\" id=\"ArialMT-50\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-8722\"/>\n",
       "       <use x=\"58.398438\" xlink:href=\"#ArialMT-48\"/>\n",
       "       <use x=\"114.013672\" xlink:href=\"#ArialMT-46\"/>\n",
       "       <use x=\"141.796875\" xlink:href=\"#ArialMT-50\"/>\n",
       "       <use x=\"197.412109\" xlink:href=\"#ArialMT-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.00 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(28.599062 188.806172)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-48\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-46\"/>\n",
       "       <use x=\"83.398438\" xlink:href=\"#ArialMT-48\"/>\n",
       "       <use x=\"139.013672\" xlink:href=\"#ArialMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.25 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(28.599062 161.626172)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-48\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-46\"/>\n",
       "       <use x=\"83.398438\" xlink:href=\"#ArialMT-50\"/>\n",
       "       <use x=\"139.013672\" xlink:href=\"#ArialMT-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 0.50 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(28.599062 134.446172)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-48\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-46\"/>\n",
       "       <use x=\"83.398438\" xlink:href=\"#ArialMT-53\"/>\n",
       "       <use x=\"139.013672\" xlink:href=\"#ArialMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 0.75 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(28.599062 107.266172)scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path d=\"M 4.734375 62.203125 \n",
       "L 4.734375 70.65625 \n",
       "L 51.078125 70.65625 \n",
       "L 51.078125 63.8125 \n",
       "Q 44.234375 56.546875 37.515625 44.484375 \n",
       "Q 30.8125 32.421875 27.15625 19.671875 \n",
       "Q 24.515625 10.6875 23.78125 0 \n",
       "L 14.75 0 \n",
       "Q 14.890625 8.453125 18.0625 20.40625 \n",
       "Q 21.234375 32.375 27.171875 43.484375 \n",
       "Q 33.109375 54.59375 39.796875 62.203125 \n",
       "z\n",
       "\" id=\"ArialMT-55\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-48\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-46\"/>\n",
       "       <use x=\"83.398438\" xlink:href=\"#ArialMT-55\"/>\n",
       "       <use x=\"139.013672\" xlink:href=\"#ArialMT-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 1.00 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(28.599062 80.086172)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-49\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-46\"/>\n",
       "       <use x=\"83.398438\" xlink:href=\"#ArialMT-48\"/>\n",
       "       <use x=\"139.013672\" xlink:href=\"#ArialMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_8\">\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 1.25 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(28.599062 52.906172)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-49\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-46\"/>\n",
       "       <use x=\"83.398438\" xlink:href=\"#ArialMT-50\"/>\n",
       "       <use x=\"139.013672\" xlink:href=\"#ArialMT-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_9\">\n",
       "     <g id=\"text_15\">\n",
       "      <!-- 1.50 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(28.599062 25.726172)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-49\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-46\"/>\n",
       "       <use x=\"83.398438\" xlink:href=\"#ArialMT-53\"/>\n",
       "       <use x=\"139.013672\" xlink:href=\"#ArialMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_16\">\n",
       "     <!-- $x_2$ -->\n",
       "     <g style=\"fill:#262626;\" transform=\"translate(15.789375 136.929375)rotate(-90)scale(0.12 -0.12)\">\n",
       "      <defs>\n",
       "       <path d=\"M 19.1875 8.296875 \n",
       "L 53.609375 8.296875 \n",
       "L 53.609375 0 \n",
       "L 7.328125 0 \n",
       "L 7.328125 8.296875 \n",
       "Q 12.9375 14.109375 22.625 23.890625 \n",
       "Q 32.328125 33.6875 34.8125 36.53125 \n",
       "Q 39.546875 41.84375 41.421875 45.53125 \n",
       "Q 43.3125 49.21875 43.3125 52.78125 \n",
       "Q 43.3125 58.59375 39.234375 62.25 \n",
       "Q 35.15625 65.921875 28.609375 65.921875 \n",
       "Q 23.96875 65.921875 18.8125 64.3125 \n",
       "Q 13.671875 62.703125 7.8125 59.421875 \n",
       "L 7.8125 69.390625 \n",
       "Q 13.765625 71.78125 18.9375 73 \n",
       "Q 24.125 74.21875 28.421875 74.21875 \n",
       "Q 39.75 74.21875 46.484375 68.546875 \n",
       "Q 53.21875 62.890625 53.21875 53.421875 \n",
       "Q 53.21875 48.921875 51.53125 44.890625 \n",
       "Q 49.859375 40.875 45.40625 35.40625 \n",
       "Q 44.1875 33.984375 37.640625 27.21875 \n",
       "Q 31.109375 20.453125 19.1875 8.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-50\"/>\n",
       "      </defs>\n",
       "      <use transform=\"translate(0 0.3125)\" xlink:href=\"#DejaVuSans-Oblique-120\"/>\n",
       "      <use transform=\"translate(59.179688 -16.09375)scale(0.7)\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"PathCollection_1\">\n",
       "    <defs>\n",
       "     <path d=\"M 0 3 \n",
       "C 0.795609 3 1.55874 2.683901 2.12132 2.12132 \n",
       "C 2.683901 1.55874 3 0.795609 3 0 \n",
       "C 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \n",
       "C 1.55874 -2.683901 0.795609 -3 0 -3 \n",
       "C -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \n",
       "C -2.683901 -1.55874 -3 -0.795609 -3 0 \n",
       "C -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \n",
       "C -1.55874 2.683901 -0.795609 3 0 3 \n",
       "z\n",
       "\" id=\"m3a71524397\" style=\"stroke:#333333;\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#p3f2878dc3e)\">\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"113.113131\" xlink:href=\"#m3a71524397\" y=\"182.49841\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"219.514464\" xlink:href=\"#m3a71524397\" y=\"79.177554\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"240.616481\" xlink:href=\"#m3a71524397\" y=\"80.465647\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"122.990671\" xlink:href=\"#m3a71524397\" y=\"191.228627\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"117.043338\" xlink:href=\"#m3a71524397\" y=\"191.727538\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"93.260188\" xlink:href=\"#m3a71524397\" y=\"179.533069\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"228.00165\" xlink:href=\"#m3a71524397\" y=\"76.358712\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"219.482368\" xlink:href=\"#m3a71524397\" y=\"70.746403\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"111.284669\" xlink:href=\"#m3a71524397\" y=\"191.339768\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"223.810868\" xlink:href=\"#m3a71524397\" y=\"72.425246\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"118.781318\" xlink:href=\"#m3a71524397\" y=\"187.999568\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"237.932388\" xlink:href=\"#m3a71524397\" y=\"55.593479\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"224.217696\" xlink:href=\"#m3a71524397\" y=\"79.527791\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"219.602569\" xlink:href=\"#m3a71524397\" y=\"75.719413\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"111.508243\" xlink:href=\"#m3a71524397\" y=\"197.700217\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"107.563758\" xlink:href=\"#m3a71524397\" y=\"175.970833\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"234.571592\" xlink:href=\"#m3a71524397\" y=\"101.757689\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"237.352655\" xlink:href=\"#m3a71524397\" y=\"96.196594\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"214.848877\" xlink:href=\"#m3a71524397\" y=\"76.809314\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"101.913196\" xlink:href=\"#m3a71524397\" y=\"195.003449\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"236.692399\" xlink:href=\"#m3a71524397\" y=\"55.926769\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"229.777307\" xlink:href=\"#m3a71524397\" y=\"77.453246\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"127.308474\" xlink:href=\"#m3a71524397\" y=\"168.724494\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"216.849553\" xlink:href=\"#m3a71524397\" y=\"55.699404\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"115.832488\" xlink:href=\"#m3a71524397\" y=\"183.641939\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"216.182823\" xlink:href=\"#m3a71524397\" y=\"70.797118\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"105.721388\" xlink:href=\"#m3a71524397\" y=\"171.603514\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"234.148045\" xlink:href=\"#m3a71524397\" y=\"68.646256\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"230.753461\" xlink:href=\"#m3a71524397\" y=\"78.679537\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"225.880597\" xlink:href=\"#m3a71524397\" y=\"64.645059\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"110.00079\" xlink:href=\"#m3a71524397\" y=\"175.447519\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"119.536148\" xlink:href=\"#m3a71524397\" y=\"195.403149\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"106.096908\" xlink:href=\"#m3a71524397\" y=\"163.831905\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"114.236986\" xlink:href=\"#m3a71524397\" y=\"188.794276\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"125.568748\" xlink:href=\"#m3a71524397\" y=\"188.438894\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"110.82048\" xlink:href=\"#m3a71524397\" y=\"184.370206\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"126.164417\" xlink:href=\"#m3a71524397\" y=\"197.373813\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"205.300445\" xlink:href=\"#m3a71524397\" y=\"61.436522\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"236.250176\" xlink:href=\"#m3a71524397\" y=\"81.114938\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"224.331035\" xlink:href=\"#m3a71524397\" y=\"80.449362\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"110.77974\" xlink:href=\"#m3a71524397\" y=\"192.017061\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"212.177342\" xlink:href=\"#m3a71524397\" y=\"100.402151\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"230.495769\" xlink:href=\"#m3a71524397\" y=\"74.952984\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"114.364648\" xlink:href=\"#m3a71524397\" y=\"197.307124\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"124.319684\" xlink:href=\"#m3a71524397\" y=\"201.679001\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"131.115223\" xlink:href=\"#m3a71524397\" y=\"169.662193\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"217.455836\" xlink:href=\"#m3a71524397\" y=\"86.835655\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"207.796541\" xlink:href=\"#m3a71524397\" y=\"65.168595\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"108.495859\" xlink:href=\"#m3a71524397\" y=\"192.334435\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"218.401396\" xlink:href=\"#m3a71524397\" y=\"84.171598\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"114.940106\" xlink:href=\"#m3a71524397\" y=\"188.569421\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"227.539986\" xlink:href=\"#m3a71524397\" y=\"56.702062\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"112.215934\" xlink:href=\"#m3a71524397\" y=\"178.902658\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"216.06741\" xlink:href=\"#m3a71524397\" y=\"90.543693\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"225.083505\" xlink:href=\"#m3a71524397\" y=\"67.592741\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"93.261819\" xlink:href=\"#m3a71524397\" y=\"180.358952\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"207.699862\" xlink:href=\"#m3a71524397\" y=\"67.404154\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"231.495083\" xlink:href=\"#m3a71524397\" y=\"81.910495\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"102.634019\" xlink:href=\"#m3a71524397\" y=\"185.25332\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"111.779471\" xlink:href=\"#m3a71524397\" y=\"211.285422\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"111.352236\" xlink:href=\"#m3a71524397\" y=\"187.654911\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"97.134681\" xlink:href=\"#m3a71524397\" y=\"187.76147\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"242.640862\" xlink:href=\"#m3a71524397\" y=\"82.018961\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"216.060768\" xlink:href=\"#m3a71524397\" y=\"88.325443\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"236.3733\" xlink:href=\"#m3a71524397\" y=\"61.483413\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"97.576934\" xlink:href=\"#m3a71524397\" y=\"176.194034\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"224.875736\" xlink:href=\"#m3a71524397\" y=\"95.15416\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"232.96919\" xlink:href=\"#m3a71524397\" y=\"100.850264\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"130.417091\" xlink:href=\"#m3a71524397\" y=\"202.171878\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"122.83182\" xlink:href=\"#m3a71524397\" y=\"193.324472\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"112.053929\" xlink:href=\"#m3a71524397\" y=\"179.898067\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"112.715436\" xlink:href=\"#m3a71524397\" y=\"178.07685\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"225.355298\" xlink:href=\"#m3a71524397\" y=\"72.659467\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"215.52742\" xlink:href=\"#m3a71524397\" y=\"99.662933\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"112.019832\" xlink:href=\"#m3a71524397\" y=\"184.228202\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"121.484079\" xlink:href=\"#m3a71524397\" y=\"177.398639\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"122.719929\" xlink:href=\"#m3a71524397\" y=\"183.122569\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"225.134309\" xlink:href=\"#m3a71524397\" y=\"59.837762\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"224.421006\" xlink:href=\"#m3a71524397\" y=\"58.391533\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"113.648342\" xlink:href=\"#m3a71524397\" y=\"194.141866\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"233.603266\" xlink:href=\"#m3a71524397\" y=\"59.925283\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"219.750979\" xlink:href=\"#m3a71524397\" y=\"87.23468\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"232.167043\" xlink:href=\"#m3a71524397\" y=\"56.674185\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"106.934512\" xlink:href=\"#m3a71524397\" y=\"182.205173\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"221.249005\" xlink:href=\"#m3a71524397\" y=\"68.032968\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"114.856615\" xlink:href=\"#m3a71524397\" y=\"197.612993\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"122.118068\" xlink:href=\"#m3a71524397\" y=\"191.150753\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"106.384068\" xlink:href=\"#m3a71524397\" y=\"180.837501\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"204.43312\" xlink:href=\"#m3a71524397\" y=\"72.637357\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"214.114299\" xlink:href=\"#m3a71524397\" y=\"67.911438\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"196.458267\" xlink:href=\"#m3a71524397\" y=\"65.431977\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"105.79991\" xlink:href=\"#m3a71524397\" y=\"181.088171\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"129.084183\" xlink:href=\"#m3a71524397\" y=\"193.249332\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"109.558555\" xlink:href=\"#m3a71524397\" y=\"195.488332\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"214.681732\" xlink:href=\"#m3a71524397\" y=\"101.672422\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"117.640167\" xlink:href=\"#m3a71524397\" y=\"184.056276\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"112.010728\" xlink:href=\"#m3a71524397\" y=\"179.208321\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"107.786485\" xlink:href=\"#m3a71524397\" y=\"187.931485\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"115.351335\" xlink:href=\"#m3a71524397\" y=\"194.218882\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"203.461917\" xlink:href=\"#m3a71524397\" y=\"75.808827\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"210.652327\" xlink:href=\"#m3a71524397\" y=\"62.893054\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"94.164979\" xlink:href=\"#m3a71524397\" y=\"199.133154\"/>\n",
       "     <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"222.539021\" xlink:href=\"#m3a71524397\" y=\"93.606743\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"PathCollection_2\">\n",
       "    <defs>\n",
       "     <path d=\"M 0 3 \n",
       "C 0.795609 3 1.55874 2.683901 2.12132 2.12132 \n",
       "C 2.683901 1.55874 3 0.795609 3 0 \n",
       "C 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \n",
       "C 1.55874 -2.683901 0.795609 -3 0 -3 \n",
       "C -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \n",
       "C -2.683901 -1.55874 -3 -0.795609 -3 0 \n",
       "C -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \n",
       "C -1.55874 2.683901 -0.795609 3 0 3 \n",
       "z\n",
       "\" id=\"m6b8dd32c32\" style=\"stroke:#333333;\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#p3f2878dc3e)\">\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"218.589083\" xlink:href=\"#m6b8dd32c32\" y=\"172.722578\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"228.751683\" xlink:href=\"#m6b8dd32c32\" y=\"172.935574\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"219.482672\" xlink:href=\"#m6b8dd32c32\" y=\"186.914606\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"107.967069\" xlink:href=\"#m6b8dd32c32\" y=\"65.983224\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"234.116201\" xlink:href=\"#m6b8dd32c32\" y=\"189.015519\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"116.317983\" xlink:href=\"#m6b8dd32c32\" y=\"80.286877\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"209.955211\" xlink:href=\"#m6b8dd32c32\" y=\"196.695087\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"139.988184\" xlink:href=\"#m6b8dd32c32\" y=\"77.172245\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"231.64685\" xlink:href=\"#m6b8dd32c32\" y=\"201.300291\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"205.985229\" xlink:href=\"#m6b8dd32c32\" y=\"176.380585\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"217.828649\" xlink:href=\"#m6b8dd32c32\" y=\"166.503753\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"89.143285\" xlink:href=\"#m6b8dd32c32\" y=\"65.332493\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"129.004352\" xlink:href=\"#m6b8dd32c32\" y=\"66.093504\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"113.243105\" xlink:href=\"#m6b8dd32c32\" y=\"90.480582\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"113.486786\" xlink:href=\"#m6b8dd32c32\" y=\"63.382855\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"96.963843\" xlink:href=\"#m6b8dd32c32\" y=\"60.97202\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"220.975831\" xlink:href=\"#m6b8dd32c32\" y=\"189.139562\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"207.149686\" xlink:href=\"#m6b8dd32c32\" y=\"172.606934\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"214.723634\" xlink:href=\"#m6b8dd32c32\" y=\"174.234168\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"122.187621\" xlink:href=\"#m6b8dd32c32\" y=\"76.904463\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"204.001479\" xlink:href=\"#m6b8dd32c32\" y=\"181.570638\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"239.135026\" xlink:href=\"#m6b8dd32c32\" y=\"188.18285\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"232.424437\" xlink:href=\"#m6b8dd32c32\" y=\"186.265279\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"212.630899\" xlink:href=\"#m6b8dd32c32\" y=\"189.421959\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"237.203079\" xlink:href=\"#m6b8dd32c32\" y=\"169.211816\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"102.836419\" xlink:href=\"#m6b8dd32c32\" y=\"85.502441\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"234.929546\" xlink:href=\"#m6b8dd32c32\" y=\"171.522637\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"124.484581\" xlink:href=\"#m6b8dd32c32\" y=\"73.646974\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"219.568309\" xlink:href=\"#m6b8dd32c32\" y=\"170.95476\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"91.311946\" xlink:href=\"#m6b8dd32c32\" y=\"75.104414\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"112.262667\" xlink:href=\"#m6b8dd32c32\" y=\"82.308517\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"212.722854\" xlink:href=\"#m6b8dd32c32\" y=\"194.586315\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"206.10131\" xlink:href=\"#m6b8dd32c32\" y=\"174.471235\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"116.165303\" xlink:href=\"#m6b8dd32c32\" y=\"78.009178\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"228.974875\" xlink:href=\"#m6b8dd32c32\" y=\"175.042947\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"116.617165\" xlink:href=\"#m6b8dd32c32\" y=\"84.209657\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"114.190338\" xlink:href=\"#m6b8dd32c32\" y=\"86.375929\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"242.3893\" xlink:href=\"#m6b8dd32c32\" y=\"195.125801\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"219.105796\" xlink:href=\"#m6b8dd32c32\" y=\"172.06177\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"103.801552\" xlink:href=\"#m6b8dd32c32\" y=\"74.200592\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"127.529858\" xlink:href=\"#m6b8dd32c32\" y=\"75.819376\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"130.222425\" xlink:href=\"#m6b8dd32c32\" y=\"61.958089\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"229.134884\" xlink:href=\"#m6b8dd32c32\" y=\"192.73988\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"104.197708\" xlink:href=\"#m6b8dd32c32\" y=\"77.476277\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"217.204818\" xlink:href=\"#m6b8dd32c32\" y=\"176.141722\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"115.898981\" xlink:href=\"#m6b8dd32c32\" y=\"88.124485\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"122.098013\" xlink:href=\"#m6b8dd32c32\" y=\"69.712783\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"121.241299\" xlink:href=\"#m6b8dd32c32\" y=\"72.428564\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"210.298572\" xlink:href=\"#m6b8dd32c32\" y=\"176.850192\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"104.192758\" xlink:href=\"#m6b8dd32c32\" y=\"91.277882\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"120.308518\" xlink:href=\"#m6b8dd32c32\" y=\"68.163842\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"203.806749\" xlink:href=\"#m6b8dd32c32\" y=\"173.739296\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"224.784028\" xlink:href=\"#m6b8dd32c32\" y=\"196.098083\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"118.293649\" xlink:href=\"#m6b8dd32c32\" y=\"68.565279\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"123.236597\" xlink:href=\"#m6b8dd32c32\" y=\"83.624636\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"209.214082\" xlink:href=\"#m6b8dd32c32\" y=\"183.904627\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"202.548388\" xlink:href=\"#m6b8dd32c32\" y=\"186.028703\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"121.027864\" xlink:href=\"#m6b8dd32c32\" y=\"79.354762\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"86.458875\" xlink:href=\"#m6b8dd32c32\" y=\"85.001475\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"109.60376\" xlink:href=\"#m6b8dd32c32\" y=\"91.247218\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"123.437367\" xlink:href=\"#m6b8dd32c32\" y=\"71.278714\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"106.227745\" xlink:href=\"#m6b8dd32c32\" y=\"80.026767\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"111.328294\" xlink:href=\"#m6b8dd32c32\" y=\"74.155451\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"123.931262\" xlink:href=\"#m6b8dd32c32\" y=\"83.994695\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"239.314437\" xlink:href=\"#m6b8dd32c32\" y=\"189.581028\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"100.141138\" xlink:href=\"#m6b8dd32c32\" y=\"61.615829\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"239.886783\" xlink:href=\"#m6b8dd32c32\" y=\"175.951217\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"229.493759\" xlink:href=\"#m6b8dd32c32\" y=\"165.595948\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"205.732229\" xlink:href=\"#m6b8dd32c32\" y=\"196.655183\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"208.799691\" xlink:href=\"#m6b8dd32c32\" y=\"209.221196\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"114.630111\" xlink:href=\"#m6b8dd32c32\" y=\"62.796784\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"210.918677\" xlink:href=\"#m6b8dd32c32\" y=\"171.183771\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"200.487523\" xlink:href=\"#m6b8dd32c32\" y=\"160.20823\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"103.844151\" xlink:href=\"#m6b8dd32c32\" y=\"67.343693\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"122.525962\" xlink:href=\"#m6b8dd32c32\" y=\"77.367636\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"231.24623\" xlink:href=\"#m6b8dd32c32\" y=\"175.385053\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"109.752428\" xlink:href=\"#m6b8dd32c32\" y=\"70.714482\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"119.120655\" xlink:href=\"#m6b8dd32c32\" y=\"78.731359\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"117.866078\" xlink:href=\"#m6b8dd32c32\" y=\"81.281882\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"218.314711\" xlink:href=\"#m6b8dd32c32\" y=\"169.775104\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"224.55223\" xlink:href=\"#m6b8dd32c32\" y=\"162.512298\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"231.493178\" xlink:href=\"#m6b8dd32c32\" y=\"176.082906\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"143.288048\" xlink:href=\"#m6b8dd32c32\" y=\"76.940435\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"205.146132\" xlink:href=\"#m6b8dd32c32\" y=\"198.450031\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"245.504457\" xlink:href=\"#m6b8dd32c32\" y=\"197.700438\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"215.424288\" xlink:href=\"#m6b8dd32c32\" y=\"195.311378\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"106.954843\" xlink:href=\"#m6b8dd32c32\" y=\"85.208582\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"105.187827\" xlink:href=\"#m6b8dd32c32\" y=\"76.937881\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"233.349721\" xlink:href=\"#m6b8dd32c32\" y=\"197.574985\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"105.531984\" xlink:href=\"#m6b8dd32c32\" y=\"82.792323\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"94.487374\" xlink:href=\"#m6b8dd32c32\" y=\"78.896216\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"128.801858\" xlink:href=\"#m6b8dd32c32\" y=\"68.522121\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"107.871643\" xlink:href=\"#m6b8dd32c32\" y=\"70.865367\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"239.354938\" xlink:href=\"#m6b8dd32c32\" y=\"195.618315\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"201.703232\" xlink:href=\"#m6b8dd32c32\" y=\"181.419653\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"114.545241\" xlink:href=\"#m6b8dd32c32\" y=\"65.332078\"/>\n",
       "     <use style=\"fill:#dd8452;stroke:#333333;\" x=\"237.198711\" xlink:href=\"#m6b8dd32c32\" y=\"193.710222\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 59.506094 239.229375 \n",
       "L 59.506094 21.789375 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 276.946094 239.229375 \n",
       "L 276.946094 21.789375 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 59.506094 239.229375 \n",
       "L 276.946094 239.229375 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 59.506094 21.789375 \n",
       "L 276.946094 21.789375 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n",
       "   </g>\n",
       "   <g id=\"text_17\">\n",
       "    <!-- Dataset samples -->\n",
       "    <g style=\"fill:#262626;\" transform=\"translate(123.542031 15.789375)scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path d=\"M 7.71875 0 \n",
       "L 7.71875 71.578125 \n",
       "L 32.375 71.578125 \n",
       "Q 40.71875 71.578125 45.125 70.5625 \n",
       "Q 51.265625 69.140625 55.609375 65.4375 \n",
       "Q 61.28125 60.640625 64.078125 53.1875 \n",
       "Q 66.890625 45.75 66.890625 36.1875 \n",
       "Q 66.890625 28.03125 64.984375 21.734375 \n",
       "Q 63.09375 15.4375 60.109375 11.296875 \n",
       "Q 57.125 7.171875 53.578125 4.796875 \n",
       "Q 50.046875 2.4375 45.046875 1.21875 \n",
       "Q 40.046875 0 33.546875 0 \n",
       "z\n",
       "M 17.1875 8.453125 \n",
       "L 32.46875 8.453125 \n",
       "Q 39.546875 8.453125 43.578125 9.765625 \n",
       "Q 47.609375 11.078125 50 13.484375 \n",
       "Q 53.375 16.84375 55.25 22.53125 \n",
       "Q 57.125 28.21875 57.125 36.328125 \n",
       "Q 57.125 47.5625 53.4375 53.59375 \n",
       "Q 49.75 59.625 44.484375 61.671875 \n",
       "Q 40.671875 63.140625 32.234375 63.140625 \n",
       "L 17.1875 63.140625 \n",
       "z\n",
       "\" id=\"ArialMT-68\"/>\n",
       "      <path d=\"M 40.4375 6.390625 \n",
       "Q 35.546875 2.25 31.03125 0.53125 \n",
       "Q 26.515625 -1.171875 21.34375 -1.171875 \n",
       "Q 12.796875 -1.171875 8.203125 3 \n",
       "Q 3.609375 7.171875 3.609375 13.671875 \n",
       "Q 3.609375 17.484375 5.34375 20.625 \n",
       "Q 7.078125 23.78125 9.890625 25.6875 \n",
       "Q 12.703125 27.59375 16.21875 28.5625 \n",
       "Q 18.796875 29.25 24.03125 29.890625 \n",
       "Q 34.671875 31.15625 39.703125 32.90625 \n",
       "Q 39.75 34.71875 39.75 35.203125 \n",
       "Q 39.75 40.578125 37.25 42.78125 \n",
       "Q 33.890625 45.75 27.25 45.75 \n",
       "Q 21.046875 45.75 18.09375 43.578125 \n",
       "Q 15.140625 41.40625 13.71875 35.890625 \n",
       "L 5.125 37.0625 \n",
       "Q 6.296875 42.578125 8.984375 45.96875 \n",
       "Q 11.671875 49.359375 16.75 51.1875 \n",
       "Q 21.828125 53.03125 28.515625 53.03125 \n",
       "Q 35.15625 53.03125 39.296875 51.46875 \n",
       "Q 43.453125 49.90625 45.40625 47.53125 \n",
       "Q 47.359375 45.171875 48.140625 41.546875 \n",
       "Q 48.578125 39.3125 48.578125 33.453125 \n",
       "L 48.578125 21.734375 \n",
       "Q 48.578125 9.46875 49.140625 6.21875 \n",
       "Q 49.703125 2.984375 51.375 0 \n",
       "L 42.1875 0 \n",
       "Q 40.828125 2.734375 40.4375 6.390625 \n",
       "z\n",
       "M 39.703125 26.03125 \n",
       "Q 34.90625 24.078125 25.34375 22.703125 \n",
       "Q 19.921875 21.921875 17.671875 20.9375 \n",
       "Q 15.4375 19.96875 14.203125 18.09375 \n",
       "Q 12.984375 16.21875 12.984375 13.921875 \n",
       "Q 12.984375 10.40625 15.640625 8.0625 \n",
       "Q 18.3125 5.71875 23.4375 5.71875 \n",
       "Q 28.515625 5.71875 32.46875 7.9375 \n",
       "Q 36.421875 10.15625 38.28125 14.015625 \n",
       "Q 39.703125 17 39.703125 22.796875 \n",
       "z\n",
       "\" id=\"ArialMT-97\"/>\n",
       "      <path d=\"M 25.78125 7.859375 \n",
       "L 27.046875 0.09375 \n",
       "Q 23.34375 -0.6875 20.40625 -0.6875 \n",
       "Q 15.625 -0.6875 12.984375 0.828125 \n",
       "Q 10.359375 2.34375 9.28125 4.8125 \n",
       "Q 8.203125 7.28125 8.203125 15.1875 \n",
       "L 8.203125 45.015625 \n",
       "L 1.765625 45.015625 \n",
       "L 1.765625 51.859375 \n",
       "L 8.203125 51.859375 \n",
       "L 8.203125 64.703125 \n",
       "L 16.9375 69.96875 \n",
       "L 16.9375 51.859375 \n",
       "L 25.78125 51.859375 \n",
       "L 25.78125 45.015625 \n",
       "L 16.9375 45.015625 \n",
       "L 16.9375 14.703125 \n",
       "Q 16.9375 10.9375 17.40625 9.859375 \n",
       "Q 17.875 8.796875 18.921875 8.15625 \n",
       "Q 19.96875 7.515625 21.921875 7.515625 \n",
       "Q 23.390625 7.515625 25.78125 7.859375 \n",
       "z\n",
       "\" id=\"ArialMT-116\"/>\n",
       "      <path d=\"M 3.078125 15.484375 \n",
       "L 11.765625 16.84375 \n",
       "Q 12.5 11.625 15.84375 8.84375 \n",
       "Q 19.1875 6.0625 25.203125 6.0625 \n",
       "Q 31.25 6.0625 34.171875 8.515625 \n",
       "Q 37.109375 10.984375 37.109375 14.3125 \n",
       "Q 37.109375 17.28125 34.515625 19 \n",
       "Q 32.71875 20.171875 25.53125 21.96875 \n",
       "Q 15.875 24.421875 12.140625 26.203125 \n",
       "Q 8.40625 27.984375 6.46875 31.125 \n",
       "Q 4.546875 34.28125 4.546875 38.09375 \n",
       "Q 4.546875 41.546875 6.125 44.5 \n",
       "Q 7.71875 47.46875 10.453125 49.421875 \n",
       "Q 12.5 50.921875 16.03125 51.96875 \n",
       "Q 19.578125 53.03125 23.640625 53.03125 \n",
       "Q 29.734375 53.03125 34.34375 51.265625 \n",
       "Q 38.96875 49.515625 41.15625 46.5 \n",
       "Q 43.359375 43.5 44.1875 38.484375 \n",
       "L 35.59375 37.3125 \n",
       "Q 35.015625 41.3125 32.203125 43.546875 \n",
       "Q 29.390625 45.796875 24.265625 45.796875 \n",
       "Q 18.21875 45.796875 15.625 43.796875 \n",
       "Q 13.03125 41.796875 13.03125 39.109375 \n",
       "Q 13.03125 37.40625 14.109375 36.03125 \n",
       "Q 15.1875 34.625 17.484375 33.6875 \n",
       "Q 18.796875 33.203125 25.25 31.453125 \n",
       "Q 34.578125 28.953125 38.25 27.359375 \n",
       "Q 41.9375 25.78125 44.03125 22.75 \n",
       "Q 46.140625 19.734375 46.140625 15.234375 \n",
       "Q 46.140625 10.84375 43.578125 6.953125 \n",
       "Q 41.015625 3.078125 36.171875 0.953125 \n",
       "Q 31.34375 -1.171875 25.25 -1.171875 \n",
       "Q 15.140625 -1.171875 9.84375 3.03125 \n",
       "Q 4.546875 7.234375 3.078125 15.484375 \n",
       "z\n",
       "\" id=\"ArialMT-115\"/>\n",
       "      <path d=\"M 42.09375 16.703125 \n",
       "L 51.171875 15.578125 \n",
       "Q 49.03125 7.625 43.21875 3.21875 \n",
       "Q 37.40625 -1.171875 28.375 -1.171875 \n",
       "Q 17 -1.171875 10.328125 5.828125 \n",
       "Q 3.65625 12.84375 3.65625 25.484375 \n",
       "Q 3.65625 38.578125 10.390625 45.796875 \n",
       "Q 17.140625 53.03125 27.875 53.03125 \n",
       "Q 38.28125 53.03125 44.875 45.953125 \n",
       "Q 51.46875 38.875 51.46875 26.03125 \n",
       "Q 51.46875 25.25 51.421875 23.6875 \n",
       "L 12.75 23.6875 \n",
       "Q 13.234375 15.140625 17.578125 10.59375 \n",
       "Q 21.921875 6.0625 28.421875 6.0625 \n",
       "Q 33.25 6.0625 36.671875 8.59375 \n",
       "Q 40.09375 11.140625 42.09375 16.703125 \n",
       "z\n",
       "M 13.234375 30.90625 \n",
       "L 42.1875 30.90625 \n",
       "Q 41.609375 37.453125 38.875 40.71875 \n",
       "Q 34.671875 45.796875 27.984375 45.796875 \n",
       "Q 21.921875 45.796875 17.796875 41.75 \n",
       "Q 13.671875 37.703125 13.234375 30.90625 \n",
       "z\n",
       "\" id=\"ArialMT-101\"/>\n",
       "      <path id=\"ArialMT-32\"/>\n",
       "      <path d=\"M 6.59375 0 \n",
       "L 6.59375 51.859375 \n",
       "L 14.453125 51.859375 \n",
       "L 14.453125 44.578125 \n",
       "Q 16.890625 48.390625 20.9375 50.703125 \n",
       "Q 25 53.03125 30.171875 53.03125 \n",
       "Q 35.9375 53.03125 39.625 50.640625 \n",
       "Q 43.3125 48.25 44.828125 43.953125 \n",
       "Q 50.984375 53.03125 60.84375 53.03125 \n",
       "Q 68.5625 53.03125 72.703125 48.75 \n",
       "Q 76.859375 44.484375 76.859375 35.59375 \n",
       "L 76.859375 0 \n",
       "L 68.109375 0 \n",
       "L 68.109375 32.671875 \n",
       "Q 68.109375 37.9375 67.25 40.25 \n",
       "Q 66.40625 42.578125 64.15625 43.984375 \n",
       "Q 61.921875 45.40625 58.890625 45.40625 \n",
       "Q 53.421875 45.40625 49.796875 41.765625 \n",
       "Q 46.1875 38.140625 46.1875 30.125 \n",
       "L 46.1875 0 \n",
       "L 37.40625 0 \n",
       "L 37.40625 33.6875 \n",
       "Q 37.40625 39.546875 35.25 42.46875 \n",
       "Q 33.109375 45.40625 28.21875 45.40625 \n",
       "Q 24.515625 45.40625 21.359375 43.453125 \n",
       "Q 18.21875 41.5 16.796875 37.734375 \n",
       "Q 15.375 33.984375 15.375 26.90625 \n",
       "L 15.375 0 \n",
       "z\n",
       "\" id=\"ArialMT-109\"/>\n",
       "      <path d=\"M 6.59375 -19.875 \n",
       "L 6.59375 51.859375 \n",
       "L 14.59375 51.859375 \n",
       "L 14.59375 45.125 \n",
       "Q 17.4375 49.078125 21 51.046875 \n",
       "Q 24.5625 53.03125 29.640625 53.03125 \n",
       "Q 36.28125 53.03125 41.359375 49.609375 \n",
       "Q 46.4375 46.1875 49.015625 39.953125 \n",
       "Q 51.609375 33.734375 51.609375 26.3125 \n",
       "Q 51.609375 18.359375 48.75 11.984375 \n",
       "Q 45.90625 5.609375 40.453125 2.21875 \n",
       "Q 35.015625 -1.171875 29 -1.171875 \n",
       "Q 24.609375 -1.171875 21.109375 0.6875 \n",
       "Q 17.625 2.546875 15.375 5.375 \n",
       "L 15.375 -19.875 \n",
       "z\n",
       "M 14.546875 25.640625 \n",
       "Q 14.546875 15.625 18.59375 10.84375 \n",
       "Q 22.65625 6.0625 28.421875 6.0625 \n",
       "Q 34.28125 6.0625 38.453125 11.015625 \n",
       "Q 42.625 15.96875 42.625 26.375 \n",
       "Q 42.625 36.28125 38.546875 41.203125 \n",
       "Q 34.46875 46.140625 28.8125 46.140625 \n",
       "Q 23.1875 46.140625 18.859375 40.890625 \n",
       "Q 14.546875 35.640625 14.546875 25.640625 \n",
       "z\n",
       "\" id=\"ArialMT-112\"/>\n",
       "      <path d=\"M 6.390625 0 \n",
       "L 6.390625 71.578125 \n",
       "L 15.1875 71.578125 \n",
       "L 15.1875 0 \n",
       "z\n",
       "\" id=\"ArialMT-108\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#ArialMT-68\"/>\n",
       "     <use x=\"72.216797\" xlink:href=\"#ArialMT-97\"/>\n",
       "     <use x=\"127.832031\" xlink:href=\"#ArialMT-116\"/>\n",
       "     <use x=\"155.615234\" xlink:href=\"#ArialMT-97\"/>\n",
       "     <use x=\"211.230469\" xlink:href=\"#ArialMT-115\"/>\n",
       "     <use x=\"261.230469\" xlink:href=\"#ArialMT-101\"/>\n",
       "     <use x=\"316.845703\" xlink:href=\"#ArialMT-116\"/>\n",
       "     <use x=\"344.628906\" xlink:href=\"#ArialMT-32\"/>\n",
       "     <use x=\"372.412109\" xlink:href=\"#ArialMT-115\"/>\n",
       "     <use x=\"422.412109\" xlink:href=\"#ArialMT-97\"/>\n",
       "     <use x=\"478.027344\" xlink:href=\"#ArialMT-109\"/>\n",
       "     <use x=\"561.328125\" xlink:href=\"#ArialMT-112\"/>\n",
       "     <use x=\"616.943359\" xlink:href=\"#ArialMT-108\"/>\n",
       "     <use x=\"639.160156\" xlink:href=\"#ArialMT-101\"/>\n",
       "     <use x=\"694.775391\" xlink:href=\"#ArialMT-115\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 197.367969 147.719219 \n",
       "L 269.246094 147.719219 \n",
       "Q 271.446094 147.719219 271.446094 145.519219 \n",
       "L 271.446094 115.499531 \n",
       "Q 271.446094 113.299531 269.246094 113.299531 \n",
       "L 197.367969 113.299531 \n",
       "Q 195.167969 113.299531 195.167969 115.499531 \n",
       "L 195.167969 145.519219 \n",
       "Q 195.167969 147.719219 197.367969 147.719219 \n",
       "z\n",
       "\" style=\"fill:#eaeaf2;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n",
       "    </g>\n",
       "    <g id=\"PathCollection_3\">\n",
       "     <g>\n",
       "      <use style=\"fill:#4c72b0;stroke:#333333;\" x=\"210.567969\" xlink:href=\"#m3a71524397\" y=\"122.685625\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_18\">\n",
       "     <!-- Class 0 -->\n",
       "     <g style=\"fill:#262626;\" transform=\"translate(230.367969 125.573125)scale(0.11 -0.11)\">\n",
       "      <defs>\n",
       "       <path d=\"M 58.796875 25.09375 \n",
       "L 68.265625 22.703125 \n",
       "Q 65.28125 11.03125 57.546875 4.90625 \n",
       "Q 49.8125 -1.21875 38.625 -1.21875 \n",
       "Q 27.046875 -1.21875 19.796875 3.484375 \n",
       "Q 12.546875 8.203125 8.765625 17.140625 \n",
       "Q 4.984375 26.078125 4.984375 36.328125 \n",
       "Q 4.984375 47.515625 9.25 55.828125 \n",
       "Q 13.53125 64.15625 21.40625 68.46875 \n",
       "Q 29.296875 72.796875 38.765625 72.796875 \n",
       "Q 49.515625 72.796875 56.828125 67.328125 \n",
       "Q 64.15625 61.859375 67.046875 51.953125 \n",
       "L 57.71875 49.75 \n",
       "Q 55.21875 57.5625 50.484375 61.125 \n",
       "Q 45.75 64.703125 38.578125 64.703125 \n",
       "Q 30.328125 64.703125 24.78125 60.734375 \n",
       "Q 19.234375 56.78125 16.984375 50.109375 \n",
       "Q 14.75 43.453125 14.75 36.375 \n",
       "Q 14.75 27.25 17.40625 20.4375 \n",
       "Q 20.0625 13.625 25.671875 10.25 \n",
       "Q 31.296875 6.890625 37.84375 6.890625 \n",
       "Q 45.796875 6.890625 51.3125 11.46875 \n",
       "Q 56.84375 16.0625 58.796875 25.09375 \n",
       "z\n",
       "\" id=\"ArialMT-67\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#ArialMT-67\"/>\n",
       "      <use x=\"72.216797\" xlink:href=\"#ArialMT-108\"/>\n",
       "      <use x=\"94.433594\" xlink:href=\"#ArialMT-97\"/>\n",
       "      <use x=\"150.048828\" xlink:href=\"#ArialMT-115\"/>\n",
       "      <use x=\"200.048828\" xlink:href=\"#ArialMT-115\"/>\n",
       "      <use x=\"250.048828\" xlink:href=\"#ArialMT-32\"/>\n",
       "      <use x=\"277.832031\" xlink:href=\"#ArialMT-48\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"PathCollection_4\">\n",
       "     <g>\n",
       "      <use style=\"fill:#dd8452;stroke:#333333;\" x=\"210.567969\" xlink:href=\"#m6b8dd32c32\" y=\"138.245469\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_19\">\n",
       "     <!-- Class 1 -->\n",
       "     <g style=\"fill:#262626;\" transform=\"translate(230.367969 141.132969)scale(0.11 -0.11)\">\n",
       "      <use xlink:href=\"#ArialMT-67\"/>\n",
       "      <use x=\"72.216797\" xlink:href=\"#ArialMT-108\"/>\n",
       "      <use x=\"94.433594\" xlink:href=\"#ArialMT-97\"/>\n",
       "      <use x=\"150.048828\" xlink:href=\"#ArialMT-115\"/>\n",
       "      <use x=\"200.048828\" xlink:href=\"#ArialMT-115\"/>\n",
       "      <use x=\"250.048828\" xlink:href=\"#ArialMT-32\"/>\n",
       "      <use x=\"277.832031\" xlink:href=\"#ArialMT-49\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p3f2878dc3e\">\n",
       "   <rect height=\"217.44\" width=\"217.44\" x=\"59.506094\" y=\"21.789375\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@torch.no_grad() # Decorator, same effect as \"with torch.no_grad(): ...\" over the whole function.\n",
    "def visualize_classification(model, data, label):\n",
    "    if isinstance(data, torch.Tensor):\n",
    "        data = data.cpu().numpy()\n",
    "    if isinstance(label, torch.Tensor):\n",
    "        label = label.cpu().numpy()\n",
    "    data_0 = data[label == 0]\n",
    "    data_1 = data[label == 1]\n",
    "    \n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.scatter(data_0[:,0], data_0[:,1], edgecolor=\"#333\", label=\"Class 0\")\n",
    "    plt.scatter(data_1[:,0], data_1[:,1], edgecolor=\"#333\", label=\"Class 1\")\n",
    "    plt.title(\"Dataset samples\")\n",
    "    plt.ylabel(r\"$x_2$\")\n",
    "    plt.xlabel(r\"$x_1$\")\n",
    "    plt.legend()\n",
    "    \n",
    "    # Let's make use of a lot of operations we have learned above\n",
    "    model.to(device)\n",
    "    c0 = torch.Tensor(to_rgba(\"C0\")).to(device)\n",
    "    c1 = torch.Tensor(to_rgba(\"C1\")).to(device)\n",
    "    x1 = torch.arange(-0.5, 1.5, step=0.01, device=device)\n",
    "    x2 = torch.arange(-0.5, 1.5, step=0.01, device=device)\n",
    "    xx1, xx2 = torch.meshgrid(x1, x2) # Meshgrid function as in numpy\n",
    "    model_inputs = torch.stack([xx1, xx2], dim=-1)\n",
    "    preds = model(model_inputs)\n",
    "    preds = torch.sigmoid(preds)\n",
    "    output_image = (1 - preds) * c0[None,None] + preds * c1[None,None] # Specifying \"None\" in a dimension creates a new one\n",
    "    output_image = output_image.cpu().numpy() # Convert to numpy array. This only works for tensors on CPU, hence first push to CPU\n",
    "    plt.imshow(output_image, origin='lower', extent=(-0.5, 1.5, -0.5, 1.5))\n",
    "    plt.grid(False)\n",
    "\n",
    "visualize_classification(model, dataset.data, dataset.label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision boundaries might not look exactly as in the figure in the preamble of this section which can be caused by running it on CPU or a different GPU architecture. Nevertheless, the result on the accuracy metric should be the approximately the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional features we didn't get to discuss yet\n",
    "\n",
    "Finally, you are all set to start with your own PyTorch project! In summary, we have looked at how we can build neural networks in PyTorch, and train and test them on data. However, there is still much more to PyTorch we haven't discussed yet. In the comming series of Jupyter notebooks, we will discover more and more functionalities of PyTorch, so that you also get familiar to PyTorch concepts beyond the basics. If you are already interested in learning more of PyTorch, we recommend the official [tutorial website](https://pytorch.org/tutorials/) that contains many tutorials on various topics. Especially logging with Tensorboard ([tutorial here](https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html)) is a good practice that we will explore from Tutorial 5 on. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
