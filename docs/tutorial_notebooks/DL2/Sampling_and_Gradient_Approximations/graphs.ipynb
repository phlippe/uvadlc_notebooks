{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0c2d0ee",
   "metadata": {},
   "source": [
    "# Graph Sampling for Neural Relational Inference\n",
    "  \n",
    "**Recordings:** TBA \n",
    "[![YouTube - Part N](https://img.shields.io/static/v1.svg?logo=youtube&label=YouTube&message=Part%20N&color=red)](TBA)    \n",
    "**Authors:**\n",
    "Adeel Pervez and David Knigge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c382dc7a-e8e6-4999-8fdc-4e642bcf6795",
   "metadata": {},
   "source": [
    "\n",
    "In this tutorials we show an example of a variational autoencoder model with graph structured latent spaces.\n",
    "This model is called Neural Relational Inference and is described in this [paper]().\n",
    "This tutorial uses code from the associated code base available [here](https://github.com/ethanfetaya/NRI)\n",
    "\n",
    "The problem dealt by this model is one of predicting particle trajectories.\n",
    "Suppose that we have $N$ interacting particles (say, charges) with some interaction structure (say, attractive/repulsive forces) that are moving about in space.\n",
    "For each particle we are observe its trajectory (say, position and velocity) as it moves about over some period of time T.\n",
    "Each new state in the tracjectory of a particle will depend on the current state (position and velocity) and on the interaction with other particles.\n",
    "Our data consists of a set of $N$ particle trajectories but the actual interactions are unknown.\n",
    "The task of our model is to learn the dynamics of the particles to predict future trajectories given example trajectories only.\n",
    "\n",
    "Notice that the task of predicting particle dynamics would become easier if we knew the form of the interactions between particles. which we think of as a graph of interactions.\n",
    "Each particle in the system would occupy a node in the graph and the strenght of the interaction could be represented by the weight of the graph.\n",
    "The interaction graph could be fed to a neural network alongwith the currently known trajectory which could then predict the next steps of the particles.\n",
    "\n",
    "However, since in this problem we are not given the interaction graph, the approach taken by Neural Relational Inference is to use the encoder of a variational autoencoder to sample a graph using the given trajectory as input.\n",
    "For this the method uses a graph neural network as encoder.\n",
    "\n",
    "## Graph Network Encoder\n",
    "Since graph neural networks already require a graph over which to pass messages, the encoder starts with a fully connected graph with each node representing a particle.\n",
    "The entire trajectory information for a particle is used as the input feature for each node.\n",
    "Node features are transformed and passed over edges and concatenated to form edge features.\n",
    "This process can be repeated to get a deeper network with edge features as the output.\n",
    "\n",
    "The edge features are then transformed into edge weights (as (unnormalized) log probabilities).\n",
    "Finally from these edge weights we can sample an interaction graph by sample edges according to their weights. \n",
    "This interaction graph then serves as a latent variable $z$ to be used in the decoder where $z_{ij}$ indicates whether edge $(i,j)$ is present in the graph.\n",
    "Since we need to backpropagate into the encoder we relax the edge sampling operation using the Gumbel-Softmax relaxation.\n",
    "\n",
    "## Graph Network Decoder\n",
    "In the decoder we use another graph network which uses the graph sampled by the encoder and the input trajectory to predict the next step in the trajectory for some predefined number of steps.\n",
    "The models uses a gaussian likelihood loss for the trajectory which is fed into the VAE loss for optimization.\n",
    "\n",
    "The model structure can be seen in the following figure from the paper linked above.\n",
    "\n",
    "![nri](img/nri.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaa553a-aac7-446e-abed-fae7fed066e0",
   "metadata": {},
   "source": [
    "#Neural Relational Inference\n",
    "\n",
    "Now we build a model to learn the dynamics of a 5 particle system connected by springs.\n",
    "The trajectory data for this system has been generated synthetically using the dynamical equations of motion and a ground truth interaction graph.\n",
    "The code to load the data is given in the `load_data` function in `utils.py`.\n",
    "\n",
    "As the first step we begin with downloading loading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c639a2c1-703f-435c-8291-68fdb6c4de03",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O 'nri_springs.zip' https://surfdrive.surf.nl/files/index.php/s/6YWMO1eiVXI4EkB/download\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22524751-0149-465e-8e61-9eaa4c3051e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -u nri_springs.zip -d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4e685d-7daf-4982-89dd-57d3a21d2a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import argparse\n",
    "import pickle\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#import math\n",
    "\n",
    "#from torch.autograd import Variable\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import networkx\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220df0c8-88c0-4658-86b4-40dab913212b",
   "metadata": {},
   "source": [
    "### Loading and Examining Data\n",
    "\n",
    "We specify the batch size and the data file suffix to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a73a9f5-5e93-4195-a929-eafdf8cdbcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader, test_loader, _, _, _, _ = load_data(128, \"_springs5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc632bb1-ccc5-49d1-964f-3167f42f71f7",
   "metadata": {},
   "source": [
    "Let's now examine this data. We get an iterator from the data loader and retrieve the first minibatch.\n",
    "The dataset is in the form of tuples of trajectory information and the ground truth interaction graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dfe74b-f252-47e8-88b7-36b7bb7479d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_sample,rel_sample) = next(iter(train_loader))\n",
    "print(x_sample.shape)\n",
    "print(rel_sample.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a1dc31-84db-45ef-b6a5-d62df9ea83d7",
   "metadata": {},
   "source": [
    "Let's look at the interaction graph first.\n",
    "This dataset consists of trajectories of systems of 5 particles. \n",
    "The interaction graph then specifies for each particle whether or not it interacts with every other particle.\n",
    "For 5 particles this gives us 20 interaction pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c426b3-695f-4614-8207-8203ed738a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=0\n",
    "print(rel_sample[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78430dc-49b7-47d9-abdf-d236b5f3f66b",
   "metadata": {},
   "source": [
    "This interaction is in the form of a list of interactions pairs. We can convert one such list to an interaction graph adjancency matrix as follows. \n",
    "Here we specify that a particle does not interact with itself by setting the diagonal to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0024f5-88f5-43ff-ac3c-f15d596209ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_adj(rel):\n",
    "    b = torch.zeros((5*5))\n",
    "    for i in range(4):\n",
    "        b[i*5+i+1:(i+1)*5+(i+1)] = rel[i*5:(i+1)*5]\n",
    "    return b.reshape((5,5))\n",
    "b=list_to_adj(rel_sample[idx])\n",
    "print(b.reshape((5,5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875ed2c5-afa3-4269-897e-06fca2690030",
   "metadata": {},
   "source": [
    "We can draw the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be504da-6c73-4c38-8c28-dadf27637b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_graph(b):\n",
    "    g = b.reshape((5,5)).cpu().numpy()\n",
    "    graph = networkx.from_numpy_array(g)\n",
    "    networkx.draw(graph, with_labels=True)\n",
    "    plt.show()\n",
    "show_graph(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deaeca4-4231-4692-a591-1f68c10ee5f3",
   "metadata": {},
   "source": [
    "Let's now examine the trajectory data for the first data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7c65ea-79fe-4ec8-8d1d-7d88b619404a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sample[idx].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c006d5-a5cd-443f-afba-186b71887c6e",
   "metadata": {},
   "source": [
    "The shape of the data above specifies that each entry consists of 5 particles with trajectories given for 49 time steps.\n",
    "Furthermore, each state in the trajectory is specified by a 4 dimensional vector.\n",
    "In this case the state is a 2d position and 2d velocity pair specifying the position and velocity of each particle at each time step.\n",
    "We examine the position and velocity of the first particle in the first trajectory for a couple of time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba25cfc-42a6-4b3d-b0b1-43710d9c3b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sample[idx,0,0:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718c3f7e-ad1f-44d2-bad7-68c20e23aafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims=4\n",
    "num_atoms=5\n",
    "timesteps=49\n",
    "lr=0.0005\n",
    "temp=0.5\n",
    "output_var=5e-5\n",
    "\n",
    "_EPS = 1e-10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6656d05c-c319-4eac-b6c8-423350867781",
   "metadata": {},
   "source": [
    "Recall that we mentioned above that the encoder of the model works on the fully connected graph in order to predict the interaction graph.\n",
    "To pass messages over the fully connected graph, it is useful to define some relational masks specifying which vertices receive messages from which other ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7433889d-7c24-48c4-81a4-2edf202e354f",
   "metadata": {},
   "outputs": [],
   "source": [
    "off_diag = np.ones([num_atoms, num_atoms]) - np.eye(num_atoms)\n",
    "\n",
    "rel_rec = np.array(encode_onehot(np.where(off_diag)[0]), dtype=np.float32)\n",
    "rel_send = np.array(encode_onehot(np.where(off_diag)[1]), dtype=np.float32)\n",
    "rel_rec = torch.FloatTensor(rel_rec)\n",
    "rel_send = torch.FloatTensor(rel_send)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cde3af-eb71-49a8-b244-9693f875416d",
   "metadata": {},
   "source": [
    "We can convert edge features into node features and node features into edge features by passing messages over the fully connected graph using these masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603dcfd2-c5f8-4b9b-a154-b85f56c2826f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rel_rec.t(), rel_rec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad03fa73-14bc-4625-88c1-c7f7d1944172",
   "metadata": {},
   "source": [
    "For example to convert edge features for the 20 interactions into node features we can multiply the above matrix with the edge feature vector as \n",
    "```\n",
    "torch.matmul(rel_rec.t(), x)\n",
    "```\n",
    "which collects the messages from all neighboring nodes for each vertex and adds the messages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1f328c-bf0c-40be-9a8d-9fc1fdbe6638",
   "metadata": {},
   "source": [
    "Next we define a simple MLP class to be used for the nonlinear feature transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf9717f-99fd-4284-a2d9-4801cf6e878d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"Two-layer fully-connected ELU net with batch norm.\"\"\"\n",
    "\n",
    "    def __init__(self, n_in, n_hid, n_out, do_prob=0.):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_in, n_hid)\n",
    "        self.fc2 = nn.Linear(n_hid, n_out)\n",
    "        self.bn = nn.BatchNorm1d(n_out)\n",
    "        self.dropout_prob = do_prob\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal(m.weight.data)\n",
    "                m.bias.data.fill_(0.1)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def batch_norm(self, inputs):\n",
    "        x = inputs.view(inputs.size(0) * inputs.size(1), -1)\n",
    "        x = self.bn(x)\n",
    "        return x.view(inputs.size(0), inputs.size(1), -1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Input shape: [num_sims, num_things, num_features]\n",
    "        x = F.elu(self.fc1(inputs))\n",
    "        x = F.dropout(x, self.dropout_prob, training=self.training)\n",
    "        x = F.elu(self.fc2(x))\n",
    "        return self.batch_norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44406999-5158-4484-a56f-6dfd423dd6fd",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "\n",
    "Next we specify the VAE encoder as a graph neural network.\n",
    "For each particle we construct a single feature vector by using the entire trajectory information.\n",
    "We include three graph neural network layers that convert the node features into edge features into node features and finally into edge features. \n",
    "The final edge features are then used to parameterize the edge probabilities for the graph sampling operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a127c4-0690-4358-b097-ac7f5c0c2255",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MLPEncoder(nn.Module):\n",
    "    def __init__(self, n_in, n_hid, n_out=2, do_prob=0.,):\n",
    "        super(MLPEncoder, self).__init__()\n",
    "\n",
    "        self.mlp1 = MLP(n_in, n_hid, n_hid, do_prob)\n",
    "        self.mlp2 = MLP(n_hid * 2, n_hid, n_hid, do_prob)\n",
    "        self.mlp3 = MLP(n_hid, n_hid, n_hid, do_prob)\n",
    "        self.mlp4 = MLP(n_hid * 3, n_hid, n_hid, do_prob)\n",
    "        \n",
    "        self.fc_out = nn.Linear(n_hid, n_out)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal(m.weight.data)\n",
    "                m.bias.data.fill_(0.1)\n",
    "\n",
    "    def edge2node(self, x, rel_rec, rel_send):\n",
    "        # NOTE: Assumes that we have the same graph across all samples.\n",
    "        incoming = torch.matmul(rel_rec.t(), x)\n",
    "        return incoming / incoming.size(1)\n",
    "\n",
    "    def node2edge(self, x, rel_rec, rel_send):\n",
    "        # NOTE: Assumes that we have the same graph across all samples.\n",
    "        receivers = torch.matmul(rel_rec, x)\n",
    "        senders = torch.matmul(rel_send, x)\n",
    "        edges = torch.cat([senders, receivers], dim=2)\n",
    "        return edges\n",
    "\n",
    "    def forward(self, inputs, rel_rec, rel_send):\n",
    "        # Input shape: [num_sims, num_atoms, num_timesteps, num_dims]\n",
    "        x = inputs.view(inputs.size(0), inputs.size(1), -1)\n",
    "        # New shape: [num_sims, num_atoms, num_timesteps*num_dims]\n",
    "\n",
    "        x = self.mlp1(x)  # 2-layer ELU net per node\n",
    "\n",
    "        x = self.node2edge(x, rel_rec, rel_send)\n",
    "        x = self.mlp2(x)\n",
    "        x_skip = x\n",
    "\n",
    "        x = self.edge2node(x, rel_rec, rel_send)\n",
    "        x = self.mlp3(x)\n",
    "        x = self.node2edge(x, rel_rec, rel_send)\n",
    "        x = torch.cat((x, x_skip), dim=2)  # Skip connection\n",
    "        x = self.mlp4(x)\n",
    "\n",
    "        return self.fc_out(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b92015-2ce8-45c6-bf59-c7a99120171d",
   "metadata": {},
   "source": [
    "### Decoder \n",
    "\n",
    "In the decoder we take the initial state and attempt to predict the remaining trajectory.\n",
    "To predict a single time step the function `single_step_forward` takes as input the current state and the proposed interaction graph.\n",
    "From the states of the nodes as node features we produce edge features by passing messages over all neighbors and then zero out the messages corresponding to edges not present in the proposed graph.\n",
    "The edge messages are then sent to the corresponding nodes after which we apply an MLP to compute the next prediction as a difference with the current state.\n",
    "The process is then repeated for all timesteps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448792ed-f196-464d-81db-e3edab31a71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPDecoder(nn.Module):\n",
    "    \"\"\"MLP decoder module.\"\"\"\n",
    "\n",
    "    def __init__(self, n_in_node, edge_types, msg_hid, msg_out, n_hid,\n",
    "                 do_prob=0.):\n",
    "        super(MLPDecoder, self).__init__()\n",
    "\n",
    "        self.msg_fc1 = (nn.Linear(2 * n_in_node, msg_hid))\n",
    "        self.msg_fc2 = (nn.Linear(msg_hid, msg_out))\n",
    "        self.msg_out_shape = msg_out\n",
    "\n",
    "        self.out_fc1 = nn.Linear(n_in_node + msg_out, n_hid)\n",
    "        self.out_fc2 = nn.Linear(n_hid, n_hid)\n",
    "        self.out_fc3 = nn.Linear(n_hid, n_in_node)\n",
    "\n",
    "        print('Using learned interaction net decoder.')\n",
    "\n",
    "        self.dropout_prob = do_prob\n",
    "\n",
    "    def single_step_forward(self, single_timestep_inputs, rel_rec, rel_send,\n",
    "                            single_timestep_rel_type):\n",
    "\n",
    "        # single_timestep_inputs has shape\n",
    "        # [batch_size, num_timesteps, num_atoms, num_dims]\n",
    "\n",
    "        # single_timestep_rel_type has shape:\n",
    "        # [batch_size, num_timesteps, num_atoms*(num_atoms-1), num_edge_types]\n",
    "\n",
    "        # Node2edge\n",
    "        receivers = torch.matmul(rel_rec, single_timestep_inputs)\n",
    "        senders = torch.matmul(rel_send, single_timestep_inputs)\n",
    "        pre_msg = torch.cat([senders, receivers], dim=-1)\n",
    "\n",
    "        msg = F.relu(self.msg_fc1(pre_msg))\n",
    "        msg = F.dropout(msg, p=self.dropout_prob)\n",
    "        msg = F.relu(self.msg_fc2(msg))\n",
    "        msg = msg * single_timestep_rel_type[:, :, :, 1:2]\n",
    "\n",
    "        # Aggregate all msgs to receiver\n",
    "        agg_msgs = msg.transpose(-2, -1).matmul(rel_rec).transpose(-2, -1)\n",
    "        agg_msgs = agg_msgs.contiguous()\n",
    "\n",
    "        # Skip connection\n",
    "        aug_inputs = torch.cat([single_timestep_inputs, agg_msgs], dim=-1)\n",
    "\n",
    "        # Output MLP\n",
    "        pred = F.dropout(F.relu(self.out_fc1(aug_inputs)), p=self.dropout_prob)\n",
    "        pred = F.dropout(F.relu(self.out_fc2(pred)), p=self.dropout_prob)\n",
    "        pred = self.out_fc3(pred)\n",
    "\n",
    "        # Predict position/velocity difference\n",
    "        return single_timestep_inputs + pred\n",
    "\n",
    "    def forward(self, inputs, rel_type, rel_rec, rel_send, pred_steps=1):\n",
    "        # NOTE: Assumes that we have the same graph across all samples.\n",
    "\n",
    "        inputs = inputs.transpose(1, 2).contiguous()\n",
    "\n",
    "        sizes = [rel_type.size(0), inputs.size(1), rel_type.size(1),\n",
    "                 rel_type.size(2)]\n",
    "        rel_type = rel_type.unsqueeze(1).expand(sizes)\n",
    "\n",
    "        time_steps = inputs.size(1)\n",
    "        assert (pred_steps <= time_steps)\n",
    "        preds = []\n",
    "\n",
    "        # initial step\n",
    "        last_pred = inputs[:, 0:1, :, :]\n",
    "        # NOTE: Assumes rel_type is constant (i.e. same across all time steps).\n",
    "        curr_rel_type = rel_type[:, 0:1, :, :]\n",
    "\n",
    "        # Run n prediction steps\n",
    "        for step in range(0, pred_steps):\n",
    "            last_pred = self.single_step_forward(last_pred, rel_rec, rel_send,\n",
    "                                                 curr_rel_type)\n",
    "            preds.append(last_pred)\n",
    "\n",
    "        sizes = [preds[0].size(0), preds[0].size(1) * pred_steps,\n",
    "                 preds[0].size(2), preds[0].size(3)]\n",
    "\n",
    "        #output = Variable(torch.zeros(sizes))\n",
    "        output = torch.zeros(sizes)\n",
    "        if inputs.is_cuda:\n",
    "            output = output.cuda()\n",
    "\n",
    "        # Re-assemble correct timeline\n",
    "        for i in range(len(preds)):\n",
    "            output[:, i:i+1, :, :] = preds[i]\n",
    "\n",
    "        pred_all = output[:, :(inputs.size(1) - 1), :, :]\n",
    "\n",
    "        return pred_all.transpose(1, 2).contiguous()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddcd409-80ac-452a-89e9-f91e1caba245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate off-diagonal interaction graph\n",
    "off_diag = np.ones([num_atoms, num_atoms]) - np.eye(num_atoms)\n",
    "\n",
    "rel_rec = np.array(encode_onehot(np.where(off_diag)[0]), dtype=np.float32)\n",
    "rel_send = np.array(encode_onehot(np.where(off_diag)[1]), dtype=np.float32)\n",
    "rel_rec = torch.FloatTensor(rel_rec)\n",
    "rel_send = torch.FloatTensor(rel_send)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4634d87c-9724-440b-a12e-4b672883189a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#edge weights have dim 2\n",
    "encoder = MLPEncoder(timesteps * dims, 256, 2)\n",
    "decoder = MLPDecoder(n_in_node=dims,\n",
    "                         edge_types=2,\n",
    "                         msg_hid=256,\n",
    "                         msg_out=256,\n",
    "                         n_hid=256, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedba580-7db9-4123-89ee-b6794114a543",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.cuda()\n",
    "decoder.cuda()\n",
    "rel_rec = rel_rec.cuda()\n",
    "rel_send = rel_send.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d039d23a-9a0e-4f8f-a2f3-90ced16b8d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()),\n",
    "                       lr=lr)\n",
    "train_loader, valid_loader, test_loader, loc_max, loc_min, vel_max, vel_min = load_data(\n",
    "    128, \"_springs5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a73cc88-963d-418c-8311-dc084a59946c",
   "metadata": {},
   "source": [
    "We can now train the model.\n",
    "This runs the encoder to get the latent graph parameters and samples the edges using the `gumbel_softmax` function to get a latent graph which is then passed to the decoder.\n",
    "We use the uniform categorical prior to compute the KL divergence for the VAE loss and a Gaussian likelihood loss with a fixed various for the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e242e8-6bf6-4b24-ab19-25e42f5683b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, best_val_loss):\n",
    "    t = time.time()\n",
    "    nll_train = []\n",
    "    acc_train = []\n",
    "    kl_train = []\n",
    "    mse_train = []\n",
    "\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    #scheduler.step()\n",
    "    for batch_idx, (data, relations) in enumerate(train_loader):\n",
    "\n",
    "        #if args.cuda:\n",
    "        data, relations = data.cuda(), relations.cuda()\n",
    "        #data, relations = Variable(data), Variable(relations)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = encoder(data, rel_rec, rel_send)\n",
    "        edges = gumbel_softmax(logits, tau=temp, hard=False)\n",
    "        prob = my_softmax(logits, -1)\n",
    "\n",
    "        output = decoder(data, edges, rel_rec, rel_send, timesteps)\n",
    "\n",
    "        target = data[:, :, 1:, :]\n",
    "\n",
    "        loss_nll = nll_gaussian(output, target, output_var)\n",
    "\n",
    "        loss_kl = kl_categorical_uniform(prob, num_atoms, 2)\n",
    "\n",
    "        loss = loss_nll + loss_kl\n",
    "\n",
    "        acc = edge_accuracy(logits, relations)\n",
    "        acc_train.append(acc)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        mse_train.append(F.mse_loss(output, target).item())\n",
    "        nll_train.append(loss_nll.item())\n",
    "        kl_train.append(loss_kl.item())\n",
    "\n",
    "    nll_val = []\n",
    "    acc_val = []\n",
    "    kl_val = []\n",
    "    mse_val = []\n",
    "\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    for batch_idx, (data, relations) in enumerate(valid_loader):\n",
    "        #if args.cuda:\n",
    "        data, relations = data.cuda(), relations.cuda()\n",
    "\n",
    "        logits = encoder(data, rel_rec, rel_send)\n",
    "        edges = gumbel_softmax(logits, tau=temp, hard=True)\n",
    "        prob = my_softmax(logits, -1)\n",
    "\n",
    "        # validation output uses teacher forcing\n",
    "        output = decoder(data, edges, rel_rec, rel_send, timesteps)\n",
    "\n",
    "        target = data[:, :, 1:, :]\n",
    "        loss_nll = nll_gaussian(output, target, output_var)\n",
    "\n",
    "        loss_kl = kl_categorical_uniform(prob, num_atoms, 2)\n",
    "\n",
    "        acc = edge_accuracy(logits, relations)\n",
    "        acc_val.append(acc)\n",
    "\n",
    "        mse_val.append(F.mse_loss(output, target).item())\n",
    "        nll_val.append(loss_nll.item())\n",
    "        kl_val.append(loss_kl.item())\n",
    "\n",
    "    print('Epoch: {:04d}'.format(epoch),\n",
    "          'nll_train: {:.10f}'.format(np.mean(nll_train)),\n",
    "          'kl_train: {:.10f}'.format(np.mean(kl_train)),\n",
    "          'mse_train: {:.10f}'.format(np.mean(mse_train)),\n",
    "          'acc_train: {:.10f}'.format(np.mean(acc_train)),\n",
    "          'nll_val: {:.10f}'.format(np.mean(nll_val)),\n",
    "          'kl_val: {:.10f}'.format(np.mean(kl_val)),\n",
    "          'mse_val: {:.10f}'.format(np.mean(mse_val)),\n",
    "          'acc_val: {:.10f}'.format(np.mean(acc_val)),\n",
    "          'time: {:.4f}s'.format(time.time() - t))\n",
    "    return np.mean(nll_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c689471d-3244-45d3-8935-d73b83e76c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_total = time.time()\n",
    "best_val_loss = np.inf\n",
    "best_epoch = 0\n",
    "for epoch in range(10):\n",
    "    val_loss = train(epoch, best_val_loss)\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_epoch = epoch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0990669f-4925-4430-83a5-bb4cdcef4d8b",
   "metadata": {},
   "source": [
    "### Visualizing Discovered Graphs\n",
    "We can now visualize the actual and predicted interaction graphs for some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead91d0b-0338-41a0-bf53-ffc1432e53c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data,relations = next(iter(valid_loader))\n",
    "data=data.cuda()\n",
    "relations=relations.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fe574b-baa2-44a1-848a-f7bc4a43079e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = encoder(data, rel_rec, rel_send)\n",
    "_, rel = logits.max(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6e69a5-49e5-466b-8d6b-80feae023ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rel[0])\n",
    "print(relations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6ed6b6-9cec-4181-b78f-8903a07e7c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    g_act = list_to_adj(relations[i])\n",
    "    g_pred = list_to_adj(rel[i])\n",
    "\n",
    "    print(\"Original\")\n",
    "    show_graph(g_act)\n",
    "    print(\"Predicted\")\n",
    "    show_graph(g_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
