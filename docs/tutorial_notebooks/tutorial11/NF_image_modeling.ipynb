{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 11: Normalizing Flows for image modeling\n",
    "\n",
    "![Status](https://img.shields.io/static/v1.svg?label=Status&message=Finished&color=green)\n",
    "\n",
    "**Filled notebook:** \n",
    "[![View notebook on Github](https://img.shields.io/static/v1.svg?logo=github&label=Repo&message=View%20On%20Github&color=lightgrey)](https://github.com/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial11/NF_image_modeling.ipynb)\n",
    "[![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial11/NF_image_modeling.ipynb)  \n",
    "**Pre-trained models:** \n",
    "[![View files on Github](https://img.shields.io/static/v1.svg?logo=github&label=Repo&message=View%20On%20Github&color=lightgrey)](https://github.com/phlippe/saved_models/tree/main/tutorial11)\n",
    "[![GoogleDrive](https://img.shields.io/static/v1.svg?logo=google-drive&logoColor=yellow&label=GDrive&message=Download&color=yellow)](https://drive.google.com/drive/folders/1gttZ5DSrpKwn9g3RcizqA5qG7NFLMgvv?usp=sharing)   \n",
    "**Recordings:** \n",
    "[![YouTube - Part 1](https://img.shields.io/static/v1.svg?logo=youtube&label=YouTube&message=Part%201&color=red)](https://youtu.be/U1fwesIusbg)\n",
    "[![YouTube - Part 2](https://img.shields.io/static/v1.svg?logo=youtube&label=YouTube&message=Part%202&color=red)](https://youtu.be/qMoGcRhVrF8)\n",
    "[![YouTube - Part 3](https://img.shields.io/static/v1.svg?logo=youtube&label=YouTube&message=Part%203&color=red)](https://youtu.be/YoAWiaEt41Y)\n",
    "[![YouTube - Part 4](https://img.shields.io/static/v1.svg?logo=youtube&label=YouTube&message=Part%204&color=red)](https://youtu.be/nTyDvn-ADJ4)    \n",
    "**Author:** Phillip Lippe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will take a closer look at complex, deep normalizing flows. The most popular, current application of deep normalizing flows is to model datasets of images. As for other generative models, images are a good domain to start working on because (1) CNNs are widely studied and strong models exist, (2) images are high-dimensional and complex, and (3) images are discrete integers. In this tutorial, we will review current advances in normalizing flows for image modeling, and get hands-on experience on coding normalizing flows. Note that normalizing flows are commonly parameter heavy and therefore computationally expensive. We will use relatively simple and shallow flows to save computational cost and allow you to run the notebook on CPU, but keep in mind that a simple way to improve the scores of the flows we study here is to make them deeper. \n",
    "\n",
    "Throughout this notebook, we make use of [PyTorch Lightning](https://pytorch-lightning.readthedocs.io/en/latest/). The first cell imports our usual libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_941215/940811947.py:11: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('svg', 'pdf') # For export\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import numpy as np \n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "from matplotlib.colors import to_rgb\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "import seaborn as sns\n",
    "sns.reset_orig()\n",
    "\n",
    "## Progress bar\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "# Torchvision\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "# PyTorch Lightning\n",
    "try:\n",
    "    import pytorch_lightning as pl\n",
    "except ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n",
    "    !pip install --quiet pytorch-lightning>=1.4\n",
    "    import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "\n",
    "# Path to the folder where the datasets are/should be downloaded (e.g. MNIST)\n",
    "DATASET_PATH = \"../data\"\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = \"../saved_models/tutorial11\"\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Fetching the device that will be used throughout this notebook\n",
    "device = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda:0\")\n",
    "print(\"Using device\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we have a few pretrained models. We download them below to the specified path above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from urllib.error import HTTPError\n",
    "# Github URL where saved models are stored for this tutorial\n",
    "base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial11/\"\n",
    "# Files to download\n",
    "pretrained_files = [\"MNISTFlow_simple.ckpt\", \"MNISTFlow_vardeq.ckpt\", \"MNISTFlow_multiscale.ckpt\"]\n",
    "# Create checkpoint path if it doesn't exist yet\n",
    "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
    "\n",
    "# For each file, check whether it already exists. If not, try downloading it.\n",
    "for file_name in pretrained_files:\n",
    "    file_path = os.path.join(CHECKPOINT_PATH, file_name)\n",
    "    if not os.path.isfile(file_path):\n",
    "        file_url = base_url + file_name\n",
    "        print(f\"Downloading {file_url}...\")\n",
    "        try:\n",
    "            urllib.request.urlretrieve(file_url, file_path)\n",
    "        except HTTPError as e:\n",
    "            print(\"Something went wrong. Please try to download the file from the GDrive folder, or contact the author with the full output including the following error:\\n\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the MNIST dataset in this notebook. MNIST constitutes, despite its simplicity, a challenge for small generative models as it requires the global understanding of an image. At the same time, we can easily judge whether generated images come from the same distribution as the dataset (i.e. represent real digits), or not.\n",
    "\n",
    "To deal better with the discrete nature of the images, we transform them from a range of 0-1 to a range of 0-255 as integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "# Convert images from 0-1 to 0-255 (integers)\n",
    "def discretize(sample):\n",
    "    return (sample * 255).to(torch.int32)\n",
    "\n",
    "# Transformations applied on each image => make them a tensor and discretize\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                discretize])\n",
    "\n",
    "# Loading the training dataset. We need to split it into a training and validation part\n",
    "train_dataset = MNIST(root=DATASET_PATH, train=True, transform=transform, download=True)\n",
    "pl.seed_everything(42)\n",
    "train_set, val_set = torch.utils.data.random_split(train_dataset, [50000, 10000])\n",
    "\n",
    "# Loading the test set\n",
    "test_set = MNIST(root=DATASET_PATH, train=False, transform=transform, download=True)\n",
    "\n",
    "# We define a set of data loaders that we can use for various purposes later.\n",
    "# Note that for actually training a model, we will use different data loaders\n",
    "# with a lower batch size.\n",
    "train_loader = data.DataLoader(train_set, batch_size=256, shuffle=False, drop_last=False)\n",
    "val_loader = data.DataLoader(val_set, batch_size=64, shuffle=False, drop_last=False, num_workers=4)\n",
    "test_loader = data.DataLoader(test_set, batch_size=64, shuffle=False, drop_last=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we will define below a function to simplify the visualization of images/samples. Some training examples of the MNIST dataset is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/pdf": "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\n",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"335.299355pt\" height=\"177.48pt\" viewBox=\"0 0 335.299355 177.48\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2022-06-10T09:54:07.571143</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 177.48 \n",
       "L 335.299355 177.48 \n",
       "L 335.299355 0 \n",
       "L 0 0 \n",
       "L 0 177.48 \n",
       "z\n",
       "\" style=\"fill: none\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g clip-path=\"url(#p4e980ef5cf)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "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\" id=\"imageaa33bc04ab\" transform=\"scale(1 -1)translate(0 -164)\" x=\"7.2\" y=\"-6.28\" width=\"321\" height=\"164\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p4e980ef5cf\">\n",
       "   <rect x=\"7.2\" y=\"7.2\" width=\"320.899355\" height=\"163.08\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 432x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_imgs(imgs, title=None, row_size=4):\n",
    "    # Form a grid of pictures (we use max. 8 columns)\n",
    "    num_imgs = imgs.shape[0] if isinstance(imgs, torch.Tensor) else len(imgs)\n",
    "    is_int = imgs.dtype==torch.int32 if isinstance(imgs, torch.Tensor) else imgs[0].dtype==torch.int32\n",
    "    nrow = min(num_imgs, row_size)\n",
    "    ncol = int(math.ceil(num_imgs/nrow))\n",
    "    imgs = torchvision.utils.make_grid(imgs, nrow=nrow, pad_value=128 if is_int else 0.5)\n",
    "    np_imgs = imgs.cpu().numpy()\n",
    "    # Plot the grid\n",
    "    plt.figure(figsize=(1.5*nrow, 1.5*ncol))\n",
    "    plt.imshow(np.transpose(np_imgs, (1,2,0)), interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "show_imgs([train_set[i][0] for i in range(8)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Flows as generative model\n",
    "\n",
    "In the previous lectures, we have seen Energy-based models, Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs) as example of generative models. However, none of them explicitly learn the probability density function $p(x)$ of the real input data. While VAEs model a lower bound, energy-based models only implicitly learn the probability density. GANs on the other hand provide us a sampling mechanism for generating new data, without offering a likelihood estimate. The generative model we will look at here, called Normalizing Flows, actually models the true data distribution $p(x)$ and provides us with an exact likelihood estimate. Below, we can visually compare VAEs, GANs and Flows\n",
    "(figure credit - [Lilian Weng](https://lilianweng.github.io/lil-log/2018/10/13/flow-based-deep-generative-models.html)):\n",
    "\n",
    "<center width=\"100%\"><img src=\"comparison_GAN_VAE_NF.png\" width=\"600px\"></center>\n",
    "\n",
    "The major difference compared to VAEs is that flows use *invertible* functions $f$ to map the input data $x$ to a latent representation $z$. To realize this, $z$ must be of the same shape as $x$. This is in contrast to VAEs where $z$ is usually much lower dimensional than the original input data. However, an invertible mapping also means that for every data point $x$, we have a corresponding latent representation $z$ which allows us to perform lossless reconstruction ($z$ to $x$). In the visualization above, this means that $x=x'$ for flows, no matter what invertible function $f$ and input $x$ we choose. \n",
    "\n",
    "Nonetheless, how are normalizing flows modeling a probability density with an invertible function? The answer to this question is the rule for change of variables. Specifically, given a prior density $p_z(z)$ (e.g. Gaussian) and an invertible function $f$, we can determine $p_x(x)$ as follows:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "    \\int p_x(x) dx & = \\int p_z(z) dz = 1 \\hspace{1cm}\\text{(by definition of a probability distribution)}\\\\\n",
    "    \\Leftrightarrow p_x(x) & = p_z(z) \\left|\\frac{dz}{dx}\\right| = p_z(f(x)) \\left|\\frac{df(x)}{dx}\\right|\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Hence, in order to determine the probability of $x$, we only need to determine its probability in latent space, and get the derivate of $f$. Note that this is for a univariate distribution, and $f$ is required to be invertible and smooth. For a multivariate case, the derivative becomes a Jacobian of which we need to take the determinant. As we usually use the log-likelihood as objective, we write the multivariate term with logarithms below:\n",
    "\n",
    "$$\n",
    "\\log p_x(\\mathbf{x}) = \\log p_z(f(\\mathbf{x})) + \\log{} \\left|\\det \\frac{df(\\mathbf{x})}{d\\mathbf{x}}\\right|\n",
    "$$\n",
    "\n",
    "Although we now know how a normalizing flow obtains its likelihood, it might not be clear what a normalizing flow does intuitively. For this, we should look from the inverse perspective of the flow starting with the prior probability density $p_z(z)$. If we apply an invertible function on it, we effectively \"transform\" its probability density. For instance, if $f^{-1}(z)=z+1$, we shift the density by one while still remaining a valid probability distribution, and being invertible. We can also apply more complex transformations, like scaling: $f^{-1}(z)=2z+1$, but there you might see a difference. When you scale, you also change the volume of the probability density, as for example on uniform distributions (figure credit - [Eric Jang](https://blog.evjang.com/2018/01/nf1.html)):\n",
    "\n",
    "<center width=\"100%\"><img src=\"uniform_flow.png\" width=\"300px\"></center>\n",
    "\n",
    "You can see that the height of $p(y)$ should be lower than $p(x)$ after scaling. This change in volume represents $\\left|\\frac{df(x)}{dx}\\right|$ in our equation above, and ensures that even after scaling, we still have a valid probability distribution. We can go on with making our function $f$ more complex. However, the more complex $f$ becomes, the harder it will be to find the inverse $f^{-1}$ of it, and to calculate the log-determinant of the Jacobian $\\log{} \\left|\\det \\frac{df(\\mathbf{x})}{d\\mathbf{x}}\\right|$. An easier trick to stack multiple invertible functions $f_{1,...,K}$ after each other, as all together, they still represent a single, invertible function. Using multiple, learnable invertible functions, a normalizing flow attempts to transform $p_z(z)$ slowly into a more complex distribution which should finally be $p_x(x)$. We visualize the idea below\n",
    "(figure credit - [Lilian Weng](https://lilianweng.github.io/lil-log/2018/10/13/flow-based-deep-generative-models.html)):\n",
    "\n",
    "<center width=\"100%\"><img src=\"normalizing_flow_layout.png\" width=\"700px\"></center>\n",
    "\n",
    "Starting from $z_0$, which follows the prior Gaussian distribution, we sequentially apply the invertible functions $f_1,f_2,...,f_K$, until $z_K$ represents $x$. Note that in the figure above, the functions $f$ represent the inverted function from $f$ we had above (here: $f:Z\\to X$, above: $f:X\\to Z$). This is just a different notation and has no impact on the actual flow design because all $f$ need to be invertible anyways. When we estimate the log likelihood of a data point $x$ as in the equations above, we run the flows in the opposite direction than visualized above. Multiple flow layers have been proposed that use a neural network as learnable parameters, such as the planar and radial flow. However, we will focus here on flows that are commonly used in image modeling, and will discuss them in the rest of the notebook along with the details of how to train a normalizing flow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Flows on images\n",
    "\n",
    "To become familiar with normalizing flows, especially for the application of image modeling, it is best to discuss the different elements in a flow along with the implementation. As a general concept, we want to build a normalizing flow that maps an input image (here MNIST) to an equally sized latent space:\n",
    "\n",
    "<center width=\"100%\" style=\"padding: 10px\"><img src=\"image_to_gaussian.svg\" width=\"450px\"></center>\n",
    "\n",
    "As a first step, we will implement a template of a normalizing flow in PyTorch Lightning. During training and validation, a normalizing flow performs density estimation in the forward direction. For this, we apply a series of flow transformations on the input $x$ and estimate the probability of the input by determining the probability of the transformed point $z$ given a prior, and the change of volume caused by the transformations. During inference, we can do both density estimation and sampling new points by inverting the flow transformations. Therefore, we define a function `_get_likelihood` which performs density estimation, and `sample` to generate new examples. The functions `training_step`, `validation_step` and `test_step` all make use of `_get_likelihood`. \n",
    "\n",
    "The standard metric used in generative models, and in particular normalizing flows, is bits per dimensions (bpd). Bpd is motivated from an information theory perspective and describes how many bits we would need to encode a particular example in our modeled distribution. The less bits we need, the more likely the example in our distribution. When we test for the bits per dimension of our test dataset, we can judge whether our model generalizes to new samples of the dataset and didn't memorize the training dataset. In order to calculate the bits per dimension score, we can rely on the negative log-likelihood and change the log base (as bits are binary while NLL is usually exponential):\n",
    "\n",
    "$$\\text{bpd} = \\text{nll} \\cdot \\log_2\\left(\\exp(1)\\right) \\cdot \\left(\\prod d_i\\right)^{-1}$$\n",
    "\n",
    "where $d_1,...,d_K$ are the dimensions of the input. For images, this would be the height, width and channel number. We divide the log likelihood by these extra dimensions to have a metric which we can compare for different image resolutions. In the original image space, MNIST examples have a bits per dimension score of 8 (we need 8 bits to encode each pixel as there are 256 possible values). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFlow(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, flows, import_samples=8):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            flows - A list of flows (each a nn.Module) that should be applied on the images. \n",
    "            import_samples - Number of importance samples to use during testing (see explanation below). Can be changed at any time\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.flows = nn.ModuleList(flows)\n",
    "        self.import_samples = import_samples\n",
    "        # Create prior distribution for final latent space\n",
    "        self.prior = torch.distributions.normal.Normal(loc=0.0, scale=1.0)\n",
    "        # Example input for visualizing the graph\n",
    "        self.example_input_array = train_set[0][0].unsqueeze(dim=0)\n",
    "\n",
    "    def forward(self, imgs):\n",
    "        # The forward function is only used for visualizing the graph\n",
    "        return self._get_likelihood(imgs)\n",
    "\n",
    "    def encode(self, imgs):\n",
    "        # Given a batch of images, return the latent representation z and ldj of the transformations\n",
    "        z, ldj = imgs, torch.zeros(imgs.shape[0], device=self.device)\n",
    "        for flow in self.flows:\n",
    "            z, ldj = flow(z, ldj, reverse=False)\n",
    "        return z, ldj\n",
    "\n",
    "    def _get_likelihood(self, imgs, return_ll=False):\n",
    "        \"\"\"\n",
    "        Given a batch of images, return the likelihood of those. \n",
    "        If return_ll is True, this function returns the log likelihood of the input.\n",
    "        Otherwise, the ouptut metric is bits per dimension (scaled negative log likelihood)\n",
    "        \"\"\"\n",
    "        z, ldj = self.encode(imgs)\n",
    "        log_pz = self.prior.log_prob(z).sum(dim=[1,2,3])\n",
    "        log_px = ldj + log_pz\n",
    "        nll = -log_px\n",
    "        # Calculating bits per dimension\n",
    "        bpd = nll * np.log2(np.exp(1)) / np.prod(imgs.shape[1:])\n",
    "        return bpd.mean() if not return_ll else log_px\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, img_shape, z_init=None):\n",
    "        \"\"\"\n",
    "        Sample a batch of images from the flow.\n",
    "        \"\"\"\n",
    "        # Sample latent representation from prior\n",
    "        if z_init is None:\n",
    "            z = self.prior.sample(sample_shape=img_shape).to(device)\n",
    "        else:\n",
    "            z = z_init.to(device)\n",
    "        \n",
    "        # Transform z to x by inverting the flows\n",
    "        ldj = torch.zeros(img_shape[0], device=device)\n",
    "        for flow in reversed(self.flows):\n",
    "            z, ldj = flow(z, ldj, reverse=True)\n",
    "        return z\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
    "        # An scheduler is optional, but can help in flows to get the last bpd improvement\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.99)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Normalizing flows are trained by maximum likelihood => return bpd\n",
    "        loss = self._get_likelihood(batch[0])                             \n",
    "        self.log('train_bpd', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self._get_likelihood(batch[0])\n",
    "        self.log('val_bpd', loss)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # Perform importance sampling during testing => estimate likelihood M times for each image\n",
    "        samples = []\n",
    "        for _ in range(self.import_samples):\n",
    "            img_ll = self._get_likelihood(batch[0], return_ll=True)\n",
    "            samples.append(img_ll)\n",
    "        img_ll = torch.stack(samples, dim=-1)\n",
    "        \n",
    "        # To average the probabilities, we need to go from log-space to exp, and back to log.\n",
    "        # Logsumexp provides us a stable implementation for this\n",
    "        img_ll = torch.logsumexp(img_ll, dim=-1) - np.log(self.import_samples)\n",
    "        \n",
    "        # Calculate final bpd\n",
    "        bpd = -img_ll * np.log2(np.exp(1)) / np.prod(batch[0].shape[1:])\n",
    "        bpd = bpd.mean()\n",
    "        \n",
    "        self.log('test_bpd', bpd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `test_step` function differs from the training and validation step in that it makes use of importance sampling. We will discuss the motiviation and details behind this after understanding how flows model discrete images in continuous space. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dequantization\n",
    "\n",
    "Normalizing flows rely on the rule of change of variables, which is naturally defined in continuous space. Applying flows directly on discrete data leads to undesired density models where arbitrarly high likelihood are placed on a few, particular values. See the illustration below: \n",
    "\n",
    "<center><img src=\"dequantization_issue.svg\" width=\"40%\"/></center>\n",
    "\n",
    "The black points represent the discrete points, and the green volume the density modeled by a normalizing flow in continuous space. The flow would continue to increase the likelihood for $x=0,1,2,3$ while having no volume on any other point. Remember that in continuous space, we have the constraint that the overall volume of the probability density must be 1 ($\\int p(x)dx=1$). Otherwise, we don't model a probability distribution anymore. However, the discrete points $x=0,1,2,3$ represent delta peaks with no width in continuous space. This is why the flow can place an infinite high likelihood on these few points while still representing a distribution in continuous space. Nonetheless, the learned density does not tell us anything about the distribution among the discrete points, as in discrete space, the likelihoods of those four points would have to sum to 1, not to infinity. \n",
    "\n",
    "To prevent such degenerated solutions, a common solution is to add a small amount of noise to each discrete value, which is also referred to as dequantization. Considering $x$ as an integer (as it is the case for images), the dequantized representation $v$ can be formulated as $v=x+u$ where $u\\in[0,1)^D$.  Thus, the discrete value $1$ is modeled by a distribution over the interval $[1.0, 2.0)$, the value $2$ by an volume over $[2.0, 3.0)$, etc. Our objective of modeling $p(x)$ becomes:\n",
    "\n",
    "$$ p(x) = \\int p(x+u)du = \\int \\frac{q(u|x)}{q(u|x)}p(x+u)du = \\mathbb{E}_{u\\sim q(u|x)}\\left[\\frac{p(x+u)}{q(u|x)} \\right]$$\n",
    "\n",
    "with $q(u|x)$ being the noise distribution. For now, we assume it to be uniform, which can also be written as $p(x)=\\mathbb{E}_{u\\sim U(0,1)^D}\\left[p(x+u) \\right]$.\n",
    "\n",
    "In the following, we will implement Dequantization as a flow transformation itself. After adding noise to the discrete values, we additionally transform the volume into a Gaussian-like shape. This is done by scaling $x+u$ between $0$ and $1$, and applying the invert of the sigmoid function $\\sigma(z)^{-1} = \\log z - \\log 1-z$. If we would not do this, we would face two problems: \n",
    "\n",
    "1. The input is scaled between 0 and 256 while the prior distribution is a Gaussian with mean $0$ and standard deviation $1$. In the first iterations after initializing the parameters of the flow, we would have extremely low likelihoods for large values like $256$. This would cause the training to diverge instantaneously.\n",
    "2. As the output distribution is a Gaussian, it is beneficial for the flow to have a similarly shaped input distribution. This will reduce the modeling complexity that is required by the flow.\n",
    "\n",
    "Overall, we can implement dequantization as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dequantization(nn.Module):\n",
    "    \n",
    "    def __init__(self, alpha=1e-5, quants=256):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            alpha - small constant that is used to scale the original input. \n",
    "                    Prevents dealing with values very close to 0 and 1 when inverting the sigmoid\n",
    "            quants - Number of possible discrete values (usually 256 for 8-bit image)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.quants = quants \n",
    "        \n",
    "    def forward(self, z, ldj, reverse=False):\n",
    "        if not reverse:\n",
    "            z, ldj = self.dequant(z, ldj)\n",
    "            z, ldj = self.sigmoid(z, ldj, reverse=True)\n",
    "        else:\n",
    "            z, ldj = self.sigmoid(z, ldj, reverse=False)\n",
    "            z = z * self.quants\n",
    "            ldj += np.log(self.quants) * np.prod(z.shape[1:])\n",
    "            z = torch.floor(z).clamp(min=0, max=self.quants-1).to(torch.int32)\n",
    "        return z, ldj\n",
    "    \n",
    "    def sigmoid(self, z, ldj, reverse=False):\n",
    "        # Applies an invertible sigmoid transformation\n",
    "        if not reverse:\n",
    "            ldj += (-z-2*F.softplus(-z)).sum(dim=[1,2,3])\n",
    "            z = torch.sigmoid(z)\n",
    "        else:\n",
    "            z = z * (1 - self.alpha) + 0.5 * self.alpha  # Scale to prevent boundaries 0 and 1\n",
    "            ldj += np.log(1 - self.alpha) * np.prod(z.shape[1:])\n",
    "            ldj += (-torch.log(z) - torch.log(1-z)).sum(dim=[1,2,3])\n",
    "            z = torch.log(z) - torch.log(1-z)\n",
    "        return z, ldj\n",
    "    \n",
    "    def dequant(self, z, ldj):\n",
    "        # Transform discrete values to continuous volumes\n",
    "        z = z.to(torch.float32)\n",
    "        z = z + torch.rand_like(z).detach()\n",
    "        z = z / self.quants\n",
    "        ldj -= np.log(self.quants) * np.prod(z.shape[1:])\n",
    "        return z, ldj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good check whether a flow is correctly implemented or not, is to verify that it is invertible. Hence, we will dequantize a randomly chosen training image, and then quantize it again. We would expect that we would get the exact same image out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dequantization was not invertible.\n",
      "Original value: 0\n",
      "Reconstructed value: 1\n"
     ]
    }
   ],
   "source": [
    "## Testing invertibility of dequantization layer\n",
    "pl.seed_everything(42)\n",
    "orig_img = train_set[0][0].unsqueeze(dim=0)\n",
    "ldj = torch.zeros(1,)\n",
    "dequant_module = Dequantization()\n",
    "deq_img, ldj = dequant_module(orig_img, ldj, reverse=False)\n",
    "reconst_img, ldj = dequant_module(deq_img, ldj, reverse=True)\n",
    "\n",
    "d1, d2 = torch.where(orig_img.squeeze() != reconst_img.squeeze())\n",
    "if len(d1) != 0:\n",
    "    print(\"Dequantization was not invertible.\")\n",
    "    for i in range(d1.shape[0]):\n",
    "        print(\"Original value:\", orig_img[0,0,d1[i], d2[i]].item())\n",
    "        print(\"Reconstructed value:\", reconst_img[0,0,d1[i], d2[i]].item())\n",
    "else:\n",
    "    print(\"Successfully inverted dequantization\")\n",
    "\n",
    "# Layer is not strictly invertible due to float precision constraints\n",
    "# assert (orig_img == reconst_img).all().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast to our expectation, the test fails. However, this is no reason to doubt our implementation here as only one single value is not equal to the original. This is caused due to numerical inaccuracies in the sigmoid invert. While the input space to the inverted sigmoid is scaled between 0 and 1, the output space is between $-\\infty$ and $\\infty$. And as we use 32 bits to represent the numbers (in addition to applying logs over and over again), such inaccuries can occur and should not be worrisome. Nevertheless, it is good to be aware of them, and can be improved by using a double tensor (float64). \n",
    "\n",
    "Finally, we can take our dequantization and actually visualize the distribution it transforms the discrete values into:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/pdf": "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\n",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"393.732813pt\" height=\"222.954375pt\" viewBox=\"0 0 393.732813 222.954375\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2022-06-10T09:54:07.768599</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 222.954375 \n",
       "L 393.732813 222.954375 \n",
       "L 393.732813 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 43.78125 185.398125 \n",
       "L 378.58125 185.398125 \n",
       "L 378.58125 22.318125 \n",
       "L 43.78125 22.318125 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"text_1\">\n",
       "      <!-- -4.0 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(34.025781 199.996562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-2d\" d=\"M 313 2009 \n",
       "L 1997 2009 \n",
       "L 1997 1497 \n",
       "L 313 1497 \n",
       "L 313 2009 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \n",
       "L 1344 794 \n",
       "L 1344 0 \n",
       "L 684 0 \n",
       "L 684 794 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2d\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-34\" x=\"36.083984\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"131.494141\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"text_2\">\n",
       "      <!-- -1.9 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(120.344677 199.996562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-39\" d=\"M 703 97 \n",
       "L 703 672 \n",
       "Q 941 559 1184 500 \n",
       "Q 1428 441 1663 441 \n",
       "Q 2288 441 2617 861 \n",
       "Q 2947 1281 2994 2138 \n",
       "Q 2813 1869 2534 1725 \n",
       "Q 2256 1581 1919 1581 \n",
       "Q 1219 1581 811 2004 \n",
       "Q 403 2428 403 3163 \n",
       "Q 403 3881 828 4315 \n",
       "Q 1253 4750 1959 4750 \n",
       "Q 2769 4750 3195 4129 \n",
       "Q 3622 3509 3622 2328 \n",
       "Q 3622 1225 3098 567 \n",
       "Q 2575 -91 1691 -91 \n",
       "Q 1453 -91 1209 -44 \n",
       "Q 966 3 703 97 \n",
       "z\n",
       "M 1959 2075 \n",
       "Q 2384 2075 2632 2365 \n",
       "Q 2881 2656 2881 3163 \n",
       "Q 2881 3666 2632 3958 \n",
       "Q 2384 4250 1959 4250 \n",
       "Q 1534 4250 1286 3958 \n",
       "Q 1038 3666 1038 3163 \n",
       "Q 1038 2656 1286 2365 \n",
       "Q 1534 2075 1959 2075 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2d\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-31\" x=\"36.083984\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-39\" x=\"131.494141\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"text_3\">\n",
       "      <!-- -1.1 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(155.9617 199.996562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-2d\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-31\" x=\"36.083984\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-31\" x=\"131.494141\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"text_4\">\n",
       "      <!-- -0.5 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(180.265081 199.996562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2d\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"36.083984\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"131.494141\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 0.0 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(203.439199 199.996562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 0.5 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(225.228435 199.996562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_7\">\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 1.1 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(249.531811 199.996562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-31\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_8\">\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 1.9 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(285.148833 199.996562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-39\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_9\">\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 4.0 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(370.629688 199.996562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_10\">\n",
       "     <!-- z -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(208.557031 213.674688)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-7a\" d=\"M 353 3500 \n",
       "L 3084 3500 \n",
       "L 3084 2975 \n",
       "L 922 459 \n",
       "L 3084 459 \n",
       "L 3084 0 \n",
       "L 275 0 \n",
       "L 275 525 \n",
       "L 2438 3041 \n",
       "L 353 3041 \n",
       "L 353 3500 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-7a\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 0.0 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(20.878125 189.197344)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 0.5 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(20.878125 152.133707)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 1.0 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(20.878125 115.070071)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 1.5 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(20.878125 78.006435)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"text_15\">\n",
       "      <!-- 2.0 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(20.878125 40.942798)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_16\">\n",
       "     <!-- Probability -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(14.798438 130.287031)rotate(-90)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-50\" d=\"M 1259 4147 \n",
       "L 1259 2394 \n",
       "L 2053 2394 \n",
       "Q 2494 2394 2734 2622 \n",
       "Q 2975 2850 2975 3272 \n",
       "Q 2975 3691 2734 3919 \n",
       "Q 2494 4147 2053 4147 \n",
       "L 1259 4147 \n",
       "z\n",
       "M 628 4666 \n",
       "L 2053 4666 \n",
       "Q 2838 4666 3239 4311 \n",
       "Q 3641 3956 3641 3272 \n",
       "Q 3641 2581 3239 2228 \n",
       "Q 2838 1875 2053 1875 \n",
       "L 1259 1875 \n",
       "L 1259 0 \n",
       "L 628 0 \n",
       "L 628 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
       "Q 2534 3019 2420 3045 \n",
       "Q 2306 3072 2169 3072 \n",
       "Q 1681 3072 1420 2755 \n",
       "Q 1159 2438 1159 1844 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1341 3275 1631 3429 \n",
       "Q 1922 3584 2338 3584 \n",
       "Q 2397 3584 2469 3576 \n",
       "Q 2541 3569 2628 3553 \n",
       "L 2631 2963 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-62\" d=\"M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "M 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2969 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \n",
       "L 1178 3500 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 3500 \n",
       "z\n",
       "M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 4134 \n",
       "L 603 4134 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \n",
       "L 1172 3500 \n",
       "L 2356 3500 \n",
       "L 2356 3053 \n",
       "L 1172 3053 \n",
       "L 1172 1153 \n",
       "Q 1172 725 1289 603 \n",
       "Q 1406 481 1766 481 \n",
       "L 2356 481 \n",
       "L 2356 0 \n",
       "L 1766 0 \n",
       "Q 1100 0 847 248 \n",
       "Q 594 497 594 1153 \n",
       "L 594 3053 \n",
       "L 172 3053 \n",
       "L 172 3500 \n",
       "L 594 3500 \n",
       "L 594 4494 \n",
       "L 1172 4494 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-79\" d=\"M 2059 -325 \n",
       "Q 1816 -950 1584 -1140 \n",
       "Q 1353 -1331 966 -1331 \n",
       "L 506 -1331 \n",
       "L 506 -850 \n",
       "L 844 -850 \n",
       "Q 1081 -850 1212 -737 \n",
       "Q 1344 -625 1503 -206 \n",
       "L 1606 56 \n",
       "L 191 3500 \n",
       "L 800 3500 \n",
       "L 1894 763 \n",
       "L 2988 3500 \n",
       "L 3597 3500 \n",
       "L 2059 -325 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"58.552734\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"97.416016\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-62\" x=\"158.597656\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"222.074219\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-62\" x=\"283.353516\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"346.830078\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" x=\"374.613281\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"402.396484\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" x=\"430.179688\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-79\" x=\"469.388672\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"PolyCollection_1\">\n",
       "    <defs>\n",
       "     <path id=\"m249e78d1df\" d=\"M 43.78125 -37.55625 \n",
       "L 43.78125 -48.030558 \n",
       "L 44.200273 -48.131995 \n",
       "L 44.619297 -48.23439 \n",
       "L 45.03832 -48.337735 \n",
       "L 45.457344 -48.442033 \n",
       "L 45.876367 -48.5473 \n",
       "L 46.29539 -48.653555 \n",
       "L 46.714414 -48.760783 \n",
       "L 47.133437 -48.869009 \n",
       "L 47.55246 -48.978238 \n",
       "L 47.971484 -49.088476 \n",
       "L 48.390507 -49.199734 \n",
       "L 48.809531 -49.312015 \n",
       "L 49.228554 -49.42534 \n",
       "L 49.647577 -49.539705 \n",
       "L 50.066601 -49.65512 \n",
       "L 50.485634 -49.771597 \n",
       "L 50.904657 -49.889153 \n",
       "L 51.323681 -50.007779 \n",
       "L 51.742704 -50.127498 \n",
       "L 52.161728 -50.248309 \n",
       "L 52.580751 -50.370231 \n",
       "L 52.999774 -50.49327 \n",
       "L 53.418798 -50.617427 \n",
       "L 53.837821 -50.742725 \n",
       "L 54.256844 -50.869162 \n",
       "L 54.675868 -50.996747 \n",
       "L 55.094891 -51.125497 \n",
       "L 55.513915 -51.255415 \n",
       "L 55.932938 -51.386517 \n",
       "L 56.351961 -51.518807 \n",
       "L 56.770985 -51.652296 \n",
       "L 57.190008 -51.786992 \n",
       "L 57.609032 -51.922914 \n",
       "L 58.028055 -52.060053 \n",
       "L 58.447078 -52.198436 \n",
       "L 58.866102 -52.338063 \n",
       "L 59.285125 -52.478949 \n",
       "L 59.704148 -52.6211 \n",
       "L 60.123172 -52.764532 \n",
       "L 60.542205 -52.909253 \n",
       "L 60.961229 -53.055266 \n",
       "L 61.380252 -53.202586 \n",
       "L 61.799275 -53.351223 \n",
       "L 62.218299 -53.501181 \n",
       "L 62.637322 -53.652486 \n",
       "L 63.056345 -53.805134 \n",
       "L 63.475369 -53.959142 \n",
       "L 63.894392 -54.114517 \n",
       "L 64.313416 -54.271268 \n",
       "L 64.732439 -54.429413 \n",
       "L 65.151462 -54.58895 \n",
       "L 65.570486 -54.749904 \n",
       "L 65.989509 -54.912272 \n",
       "L 66.408532 -55.076073 \n",
       "L 66.827556 -55.241318 \n",
       "L 67.246579 -55.408013 \n",
       "L 67.665603 -55.576175 \n",
       "L 68.084626 -55.745799 \n",
       "L 68.503649 -55.916915 \n",
       "L 68.922673 -56.089526 \n",
       "L 69.341696 -56.263644 \n",
       "L 69.76072 -56.439281 \n",
       "L 70.179743 -56.616439 \n",
       "L 70.598776 -56.795145 \n",
       "L 71.0178 -56.97539 \n",
       "L 71.436823 -57.157205 \n",
       "L 71.855846 -57.340581 \n",
       "L 72.27487 -57.525547 \n",
       "L 72.693893 -57.712098 \n",
       "L 73.112917 -57.900257 \n",
       "L 73.53194 -58.090035 \n",
       "L 73.950963 -58.281446 \n",
       "L 74.369987 -58.474481 \n",
       "L 74.78901 -58.669172 \n",
       "L 75.208033 -58.865523 \n",
       "L 75.627057 -59.063548 \n",
       "L 76.04608 -59.263246 \n",
       "L 76.465104 -59.464642 \n",
       "L 76.884127 -59.667748 \n",
       "L 77.30315 -59.872577 \n",
       "L 77.722174 -60.079121 \n",
       "L 78.141197 -60.287403 \n",
       "L 78.56022 -60.497449 \n",
       "L 78.979244 -60.709246 \n",
       "L 79.398267 -60.922821 \n",
       "L 79.817291 -61.138175 \n",
       "L 80.236314 -61.35532 \n",
       "L 80.655347 -61.574288 \n",
       "L 81.074371 -61.795068 \n",
       "L 81.493394 -62.017668 \n",
       "L 81.912418 -62.242123 \n",
       "L 82.331441 -62.468424 \n",
       "L 82.750464 -62.696584 \n",
       "L 83.169488 -62.926615 \n",
       "L 83.588511 -63.158545 \n",
       "L 84.007534 -63.39236 \n",
       "L 84.426558 -63.628087 \n",
       "L 84.845581 -63.865738 \n",
       "L 85.264605 -64.105315 \n",
       "L 85.683628 -64.346832 \n",
       "L 86.102651 -64.5903 \n",
       "L 86.521675 -64.835734 \n",
       "L 86.940698 -65.083147 \n",
       "L 87.359721 -65.33254 \n",
       "L 87.778745 -65.583936 \n",
       "L 88.197768 -65.83734 \n",
       "L 88.616792 -66.092762 \n",
       "L 89.035815 -66.350216 \n",
       "L 89.454838 -66.609715 \n",
       "L 89.873862 -66.87126 \n",
       "L 90.292885 -67.134865 \n",
       "L 90.711908 -67.400539 \n",
       "L 91.130932 -67.668298 \n",
       "L 91.549955 -67.938155 \n",
       "L 91.968979 -68.210109 \n",
       "L 92.388002 -68.484189 \n",
       "L 92.807025 -68.760377 \n",
       "L 93.226049 -69.038714 \n",
       "L 93.645072 -69.319203 \n",
       "L 94.064106 -69.60183 \n",
       "L 94.483129 -69.886642 \n",
       "L 94.902152 -70.173611 \n",
       "L 95.321176 -70.462766 \n",
       "L 95.740199 -70.754122 \n",
       "L 96.159222 -71.047689 \n",
       "L 96.578246 -71.343465 \n",
       "L 96.997269 -71.641464 \n",
       "L 97.416293 -71.941698 \n",
       "L 97.835316 -72.244179 \n",
       "L 98.254339 -72.548903 \n",
       "L 98.673363 -72.855884 \n",
       "L 99.092386 -73.165134 \n",
       "L 99.511409 -73.476663 \n",
       "L 99.930433 -73.790486 \n",
       "L 100.349456 -74.1066 \n",
       "L 100.76848 -74.425014 \n",
       "L 101.187503 -74.745756 \n",
       "L 101.606526 -75.068789 \n",
       "L 102.02555 -75.394177 \n",
       "L 102.444573 -75.72188 \n",
       "L 102.863596 -76.051942 \n",
       "L 103.28262 -76.384338 \n",
       "L 103.701643 -76.719101 \n",
       "L 104.120677 -77.056233 \n",
       "L 104.5397 -77.395746 \n",
       "L 104.958723 -77.737623 \n",
       "L 105.377747 -78.081869 \n",
       "L 105.79677 -78.428522 \n",
       "L 106.215794 -78.777588 \n",
       "L 106.634817 -79.129017 \n",
       "L 107.05384 -79.48289 \n",
       "L 107.472864 -79.839167 \n",
       "L 107.891887 -80.19786 \n",
       "L 108.31091 -80.558979 \n",
       "L 108.729934 -80.922519 \n",
       "L 109.148957 -81.288507 \n",
       "L 109.567981 -81.656929 \n",
       "L 109.987004 -82.027777 \n",
       "L 110.406027 -82.401082 \n",
       "L 110.825051 -82.776852 \n",
       "L 111.244074 -83.155052 \n",
       "L 111.663097 -83.535736 \n",
       "L 112.082121 -83.918845 \n",
       "L 112.501144 -84.304437 \n",
       "L 112.920168 -84.69249 \n",
       "L 113.339191 -85.082995 \n",
       "L 113.758214 -85.475983 \n",
       "L 114.177248 -85.871446 \n",
       "L 114.596271 -86.269369 \n",
       "L 115.015294 -86.669754 \n",
       "L 115.434318 -87.072626 \n",
       "L 115.853341 -87.477973 \n",
       "L 116.272365 -87.885767 \n",
       "L 116.691388 -88.296049 \n",
       "L 117.110411 -88.708774 \n",
       "L 117.529435 -89.123995 \n",
       "L 117.948458 -89.541668 \n",
       "L 118.367482 -89.961825 \n",
       "L 118.786505 -90.384421 \n",
       "L 119.205528 -90.809486 \n",
       "L 119.624552 -91.236995 \n",
       "L 120.043575 -91.66696 \n",
       "L 120.462598 -92.099378 \n",
       "L 120.881622 -92.534256 \n",
       "L 121.300645 -92.971543 \n",
       "L 121.719669 -93.411299 \n",
       "L 122.138692 -93.853468 \n",
       "L 122.557715 -94.298058 \n",
       "L 122.976739 -94.745065 \n",
       "L 123.395762 -95.194471 \n",
       "L 123.814785 -95.646298 \n",
       "L 124.233819 -96.100507 \n",
       "L 124.652842 -96.557101 \n",
       "L 125.071866 -97.016091 \n",
       "L 125.490889 -97.477426 \n",
       "L 125.909912 -97.94113 \n",
       "L 126.328936 -98.407206 \n",
       "L 126.747959 -98.875593 \n",
       "L 127.166982 -99.346313 \n",
       "L 127.586006 -99.819344 \n",
       "L 128.005029 -100.294712 \n",
       "L 128.424053 -100.77232 \n",
       "L 128.843076 -101.252226 \n",
       "L 129.262099 -101.734429 \n",
       "L 129.681123 -102.218837 \n",
       "L 129.681123 -37.55625 \n",
       "L 129.681123 -37.55625 \n",
       "L 129.262099 -37.55625 \n",
       "L 128.843076 -37.55625 \n",
       "L 128.424053 -37.55625 \n",
       "L 128.005029 -37.55625 \n",
       "L 127.586006 -37.55625 \n",
       "L 127.166982 -37.55625 \n",
       "L 126.747959 -37.55625 \n",
       "L 126.328936 -37.55625 \n",
       "L 125.909912 -37.55625 \n",
       "L 125.490889 -37.55625 \n",
       "L 125.071866 -37.55625 \n",
       "L 124.652842 -37.55625 \n",
       "L 124.233819 -37.55625 \n",
       "L 123.814785 -37.55625 \n",
       "L 123.395762 -37.55625 \n",
       "L 122.976739 -37.55625 \n",
       "L 122.557715 -37.55625 \n",
       "L 122.138692 -37.55625 \n",
       "L 121.719669 -37.55625 \n",
       "L 121.300645 -37.55625 \n",
       "L 120.881622 -37.55625 \n",
       "L 120.462598 -37.55625 \n",
       "L 120.043575 -37.55625 \n",
       "L 119.624552 -37.55625 \n",
       "L 119.205528 -37.55625 \n",
       "L 118.786505 -37.55625 \n",
       "L 118.367482 -37.55625 \n",
       "L 117.948458 -37.55625 \n",
       "L 117.529435 -37.55625 \n",
       "L 117.110411 -37.55625 \n",
       "L 116.691388 -37.55625 \n",
       "L 116.272365 -37.55625 \n",
       "L 115.853341 -37.55625 \n",
       "L 115.434318 -37.55625 \n",
       "L 115.015294 -37.55625 \n",
       "L 114.596271 -37.55625 \n",
       "L 114.177248 -37.55625 \n",
       "L 113.758214 -37.55625 \n",
       "L 113.339191 -37.55625 \n",
       "L 112.920168 -37.55625 \n",
       "L 112.501144 -37.55625 \n",
       "L 112.082121 -37.55625 \n",
       "L 111.663097 -37.55625 \n",
       "L 111.244074 -37.55625 \n",
       "L 110.825051 -37.55625 \n",
       "L 110.406027 -37.55625 \n",
       "L 109.987004 -37.55625 \n",
       "L 109.567981 -37.55625 \n",
       "L 109.148957 -37.55625 \n",
       "L 108.729934 -37.55625 \n",
       "L 108.31091 -37.55625 \n",
       "L 107.891887 -37.55625 \n",
       "L 107.472864 -37.55625 \n",
       "L 107.05384 -37.55625 \n",
       "L 106.634817 -37.55625 \n",
       "L 106.215794 -37.55625 \n",
       "L 105.79677 -37.55625 \n",
       "L 105.377747 -37.55625 \n",
       "L 104.958723 -37.55625 \n",
       "L 104.5397 -37.55625 \n",
       "L 104.120677 -37.55625 \n",
       "L 103.701643 -37.55625 \n",
       "L 103.28262 -37.55625 \n",
       "L 102.863596 -37.55625 \n",
       "L 102.444573 -37.55625 \n",
       "L 102.02555 -37.55625 \n",
       "L 101.606526 -37.55625 \n",
       "L 101.187503 -37.55625 \n",
       "L 100.76848 -37.55625 \n",
       "L 100.349456 -37.55625 \n",
       "L 99.930433 -37.55625 \n",
       "L 99.511409 -37.55625 \n",
       "L 99.092386 -37.55625 \n",
       "L 98.673363 -37.55625 \n",
       "L 98.254339 -37.55625 \n",
       "L 97.835316 -37.55625 \n",
       "L 97.416293 -37.55625 \n",
       "L 96.997269 -37.55625 \n",
       "L 96.578246 -37.55625 \n",
       "L 96.159222 -37.55625 \n",
       "L 95.740199 -37.55625 \n",
       "L 95.321176 -37.55625 \n",
       "L 94.902152 -37.55625 \n",
       "L 94.483129 -37.55625 \n",
       "L 94.064106 -37.55625 \n",
       "L 93.645072 -37.55625 \n",
       "L 93.226049 -37.55625 \n",
       "L 92.807025 -37.55625 \n",
       "L 92.388002 -37.55625 \n",
       "L 91.968979 -37.55625 \n",
       "L 91.549955 -37.55625 \n",
       "L 91.130932 -37.55625 \n",
       "L 90.711908 -37.55625 \n",
       "L 90.292885 -37.55625 \n",
       "L 89.873862 -37.55625 \n",
       "L 89.454838 -37.55625 \n",
       "L 89.035815 -37.55625 \n",
       "L 88.616792 -37.55625 \n",
       "L 88.197768 -37.55625 \n",
       "L 87.778745 -37.55625 \n",
       "L 87.359721 -37.55625 \n",
       "L 86.940698 -37.55625 \n",
       "L 86.521675 -37.55625 \n",
       "L 86.102651 -37.55625 \n",
       "L 85.683628 -37.55625 \n",
       "L 85.264605 -37.55625 \n",
       "L 84.845581 -37.55625 \n",
       "L 84.426558 -37.55625 \n",
       "L 84.007534 -37.55625 \n",
       "L 83.588511 -37.55625 \n",
       "L 83.169488 -37.55625 \n",
       "L 82.750464 -37.55625 \n",
       "L 82.331441 -37.55625 \n",
       "L 81.912418 -37.55625 \n",
       "L 81.493394 -37.55625 \n",
       "L 81.074371 -37.55625 \n",
       "L 80.655347 -37.55625 \n",
       "L 80.236314 -37.55625 \n",
       "L 79.817291 -37.55625 \n",
       "L 79.398267 -37.55625 \n",
       "L 78.979244 -37.55625 \n",
       "L 78.56022 -37.55625 \n",
       "L 78.141197 -37.55625 \n",
       "L 77.722174 -37.55625 \n",
       "L 77.30315 -37.55625 \n",
       "L 76.884127 -37.55625 \n",
       "L 76.465104 -37.55625 \n",
       "L 76.04608 -37.55625 \n",
       "L 75.627057 -37.55625 \n",
       "L 75.208033 -37.55625 \n",
       "L 74.78901 -37.55625 \n",
       "L 74.369987 -37.55625 \n",
       "L 73.950963 -37.55625 \n",
       "L 73.53194 -37.55625 \n",
       "L 73.112917 -37.55625 \n",
       "L 72.693893 -37.55625 \n",
       "L 72.27487 -37.55625 \n",
       "L 71.855846 -37.55625 \n",
       "L 71.436823 -37.55625 \n",
       "L 71.0178 -37.55625 \n",
       "L 70.598776 -37.55625 \n",
       "L 70.179743 -37.55625 \n",
       "L 69.76072 -37.55625 \n",
       "L 69.341696 -37.55625 \n",
       "L 68.922673 -37.55625 \n",
       "L 68.503649 -37.55625 \n",
       "L 68.084626 -37.55625 \n",
       "L 67.665603 -37.55625 \n",
       "L 67.246579 -37.55625 \n",
       "L 66.827556 -37.55625 \n",
       "L 66.408532 -37.55625 \n",
       "L 65.989509 -37.55625 \n",
       "L 65.570486 -37.55625 \n",
       "L 65.151462 -37.55625 \n",
       "L 64.732439 -37.55625 \n",
       "L 64.313416 -37.55625 \n",
       "L 63.894392 -37.55625 \n",
       "L 63.475369 -37.55625 \n",
       "L 63.056345 -37.55625 \n",
       "L 62.637322 -37.55625 \n",
       "L 62.218299 -37.55625 \n",
       "L 61.799275 -37.55625 \n",
       "L 61.380252 -37.55625 \n",
       "L 60.961229 -37.55625 \n",
       "L 60.542205 -37.55625 \n",
       "L 60.123172 -37.55625 \n",
       "L 59.704148 -37.55625 \n",
       "L 59.285125 -37.55625 \n",
       "L 58.866102 -37.55625 \n",
       "L 58.447078 -37.55625 \n",
       "L 58.028055 -37.55625 \n",
       "L 57.609032 -37.55625 \n",
       "L 57.190008 -37.55625 \n",
       "L 56.770985 -37.55625 \n",
       "L 56.351961 -37.55625 \n",
       "L 55.932938 -37.55625 \n",
       "L 55.513915 -37.55625 \n",
       "L 55.094891 -37.55625 \n",
       "L 54.675868 -37.55625 \n",
       "L 54.256844 -37.55625 \n",
       "L 53.837821 -37.55625 \n",
       "L 53.418798 -37.55625 \n",
       "L 52.999774 -37.55625 \n",
       "L 52.580751 -37.55625 \n",
       "L 52.161728 -37.55625 \n",
       "L 51.742704 -37.55625 \n",
       "L 51.323681 -37.55625 \n",
       "L 50.904657 -37.55625 \n",
       "L 50.485634 -37.55625 \n",
       "L 50.066601 -37.55625 \n",
       "L 49.647577 -37.55625 \n",
       "L 49.228554 -37.55625 \n",
       "L 48.809531 -37.55625 \n",
       "L 48.390507 -37.55625 \n",
       "L 47.971484 -37.55625 \n",
       "L 47.55246 -37.55625 \n",
       "L 47.133437 -37.55625 \n",
       "L 46.714414 -37.55625 \n",
       "L 46.29539 -37.55625 \n",
       "L 45.876367 -37.55625 \n",
       "L 45.457344 -37.55625 \n",
       "L 45.03832 -37.55625 \n",
       "L 44.619297 -37.55625 \n",
       "L 44.200273 -37.55625 \n",
       "L 43.78125 -37.55625 \n",
       "z\n",
       "\" style=\"stroke: #1f77b4; stroke-opacity: 0.5\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#p1a3a22fac7)\">\n",
       "     <use xlink:href=\"#m249e78d1df\" x=\"0\" y=\"222.954375\" style=\"fill: #1f77b4; fill-opacity: 0.5; stroke: #1f77b4; stroke-opacity: 0.5\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"PolyCollection_2\">\n",
       "    <defs>\n",
       "     <path id=\"ma1af4b06ba\" d=\"M 130.100146 -37.55625 \n",
       "L 130.100146 -102.705503 \n",
       "L 130.519174 -103.194405 \n",
       "L 130.938198 -103.685493 \n",
       "L 131.357221 -104.178764 \n",
       "L 131.776245 -104.674209 \n",
       "L 132.195268 -105.171793 \n",
       "L 132.614291 -105.671537 \n",
       "L 133.033315 -106.173371 \n",
       "L 133.452338 -106.677356 \n",
       "L 133.871367 -107.183379 \n",
       "L 134.290385 -107.691469 \n",
       "L 134.709408 -108.201587 \n",
       "L 135.128432 -108.713711 \n",
       "L 135.547455 -109.227846 \n",
       "L 135.966478 -109.743969 \n",
       "L 136.385502 -110.262009 \n",
       "L 136.804525 -110.781985 \n",
       "L 137.223554 -111.303851 \n",
       "L 137.642577 -111.827596 \n",
       "L 138.0616 -112.353182 \n",
       "L 138.480624 -112.880572 \n",
       "L 138.899647 -113.409782 \n",
       "L 139.31867 -113.940741 \n",
       "L 139.737694 -114.473433 \n",
       "L 140.156717 -115.00783 \n",
       "L 140.575746 -115.543897 \n",
       "L 140.994769 -116.081652 \n",
       "L 141.413792 -116.620962 \n",
       "L 141.832816 -117.161889 \n",
       "L 142.251839 -117.704345 \n",
       "L 142.670862 -118.24833 \n",
       "L 143.089886 -118.793799 \n",
       "L 143.508909 -119.340709 \n",
       "L 143.927938 -119.889042 \n",
       "L 144.346956 -120.438726 \n",
       "L 144.765979 -120.989753 \n",
       "L 145.185003 -121.542071 \n",
       "L 145.604026 -122.095679 \n",
       "L 146.02305 -122.650489 \n",
       "L 146.442073 -123.206483 \n",
       "L 146.861096 -123.763625 \n",
       "L 147.280125 -124.321899 \n",
       "L 147.699148 -124.881197 \n",
       "L 148.118171 -125.441521 \n",
       "L 148.537195 -126.002808 \n",
       "L 148.956218 -126.565023 \n",
       "L 149.375242 -127.128148 \n",
       "L 149.794265 -127.692103 \n",
       "L 150.213288 -128.256837 \n",
       "L 150.632317 -128.822339 \n",
       "L 151.051335 -129.388521 \n",
       "L 151.470358 -129.95534 \n",
       "L 151.889382 -130.522795 \n",
       "L 152.308405 -131.090771 \n",
       "L 152.727429 -131.659278 \n",
       "L 153.146452 -132.228217 \n",
       "L 153.565475 -132.797545 \n",
       "L 153.984504 -133.367254 \n",
       "L 154.403527 -133.937236 \n",
       "L 154.82255 -134.507465 \n",
       "L 155.241574 -135.077881 \n",
       "L 155.660597 -135.648402 \n",
       "L 156.079621 -136.219012 \n",
       "L 156.498644 -136.789657 \n",
       "L 156.917667 -137.36024 \n",
       "L 157.336696 -137.930726 \n",
       "L 157.755719 -138.501061 \n",
       "L 158.174743 -139.071185 \n",
       "L 158.593766 -139.641034 \n",
       "L 159.012789 -140.210522 \n",
       "L 159.431813 -140.779638 \n",
       "L 159.850836 -141.348295 \n",
       "L 160.269859 -141.916421 \n",
       "L 160.688888 -142.483973 \n",
       "L 161.107906 -143.050889 \n",
       "L 161.52693 -143.617089 \n",
       "L 161.945953 -144.182494 \n",
       "L 162.364976 -144.747068 \n",
       "L 162.784 -145.310732 \n",
       "L 163.203023 -145.873442 \n",
       "L 163.622046 -146.435109 \n",
       "L 164.041075 -146.995654 \n",
       "L 164.460098 -147.555041 \n",
       "L 164.879122 -148.113173 \n",
       "L 165.298145 -148.670006 \n",
       "L 165.298145 -37.55625 \n",
       "L 165.298145 -37.55625 \n",
       "L 164.879122 -37.55625 \n",
       "L 164.460098 -37.55625 \n",
       "L 164.041075 -37.55625 \n",
       "L 163.622046 -37.55625 \n",
       "L 163.203023 -37.55625 \n",
       "L 162.784 -37.55625 \n",
       "L 162.364976 -37.55625 \n",
       "L 161.945953 -37.55625 \n",
       "L 161.52693 -37.55625 \n",
       "L 161.107906 -37.55625 \n",
       "L 160.688888 -37.55625 \n",
       "L 160.269859 -37.55625 \n",
       "L 159.850836 -37.55625 \n",
       "L 159.431813 -37.55625 \n",
       "L 159.012789 -37.55625 \n",
       "L 158.593766 -37.55625 \n",
       "L 158.174743 -37.55625 \n",
       "L 157.755719 -37.55625 \n",
       "L 157.336696 -37.55625 \n",
       "L 156.917667 -37.55625 \n",
       "L 156.498644 -37.55625 \n",
       "L 156.079621 -37.55625 \n",
       "L 155.660597 -37.55625 \n",
       "L 155.241574 -37.55625 \n",
       "L 154.82255 -37.55625 \n",
       "L 154.403527 -37.55625 \n",
       "L 153.984504 -37.55625 \n",
       "L 153.565475 -37.55625 \n",
       "L 153.146452 -37.55625 \n",
       "L 152.727429 -37.55625 \n",
       "L 152.308405 -37.55625 \n",
       "L 151.889382 -37.55625 \n",
       "L 151.470358 -37.55625 \n",
       "L 151.051335 -37.55625 \n",
       "L 150.632317 -37.55625 \n",
       "L 150.213288 -37.55625 \n",
       "L 149.794265 -37.55625 \n",
       "L 149.375242 -37.55625 \n",
       "L 148.956218 -37.55625 \n",
       "L 148.537195 -37.55625 \n",
       "L 148.118171 -37.55625 \n",
       "L 147.699148 -37.55625 \n",
       "L 147.280125 -37.55625 \n",
       "L 146.861096 -37.55625 \n",
       "L 146.442073 -37.55625 \n",
       "L 146.02305 -37.55625 \n",
       "L 145.604026 -37.55625 \n",
       "L 145.185003 -37.55625 \n",
       "L 144.765979 -37.55625 \n",
       "L 144.346956 -37.55625 \n",
       "L 143.927938 -37.55625 \n",
       "L 143.508909 -37.55625 \n",
       "L 143.089886 -37.55625 \n",
       "L 142.670862 -37.55625 \n",
       "L 142.251839 -37.55625 \n",
       "L 141.832816 -37.55625 \n",
       "L 141.413792 -37.55625 \n",
       "L 140.994769 -37.55625 \n",
       "L 140.575746 -37.55625 \n",
       "L 140.156717 -37.55625 \n",
       "L 139.737694 -37.55625 \n",
       "L 139.31867 -37.55625 \n",
       "L 138.899647 -37.55625 \n",
       "L 138.480624 -37.55625 \n",
       "L 138.0616 -37.55625 \n",
       "L 137.642577 -37.55625 \n",
       "L 137.223554 -37.55625 \n",
       "L 136.804525 -37.55625 \n",
       "L 136.385502 -37.55625 \n",
       "L 135.966478 -37.55625 \n",
       "L 135.547455 -37.55625 \n",
       "L 135.128432 -37.55625 \n",
       "L 134.709408 -37.55625 \n",
       "L 134.290385 -37.55625 \n",
       "L 133.871367 -37.55625 \n",
       "L 133.452338 -37.55625 \n",
       "L 133.033315 -37.55625 \n",
       "L 132.614291 -37.55625 \n",
       "L 132.195268 -37.55625 \n",
       "L 131.776245 -37.55625 \n",
       "L 131.357221 -37.55625 \n",
       "L 130.938198 -37.55625 \n",
       "L 130.519174 -37.55625 \n",
       "L 130.100146 -37.55625 \n",
       "z\n",
       "\" style=\"stroke: #ff7f0e; stroke-opacity: 0.5\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#p1a3a22fac7)\">\n",
       "     <use xlink:href=\"#ma1af4b06ba\" x=\"0\" y=\"222.954375\" style=\"fill: #ff7f0e; fill-opacity: 0.5; stroke: #ff7f0e; stroke-opacity: 0.5\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"PolyCollection_3\">\n",
       "    <defs>\n",
       "     <path id=\"mfac49e5087\" d=\"M 165.717168 -37.55625 \n",
       "L 165.717168 -149.225434 \n",
       "L 166.136192 -149.77944 \n",
       "L 166.555215 -150.331917 \n",
       "L 166.974238 -150.882785 \n",
       "L 167.393267 -151.432019 \n",
       "L 167.81229 -151.979512 \n",
       "L 168.231314 -152.525193 \n",
       "L 168.650337 -153.068993 \n",
       "L 169.06936 -153.610874 \n",
       "L 169.488386 -154.150715 \n",
       "L 169.90741 -154.688461 \n",
       "L 170.326433 -155.224024 \n",
       "L 170.745456 -155.757361 \n",
       "L 171.16448 -156.288391 \n",
       "L 171.583503 -156.817 \n",
       "L 172.002527 -157.343161 \n",
       "L 172.42155 -157.866795 \n",
       "L 172.840576 -158.387804 \n",
       "L 173.259599 -158.90611 \n",
       "L 173.678623 -159.421676 \n",
       "L 174.097646 -159.934379 \n",
       "L 174.516669 -160.444201 \n",
       "L 174.935693 -160.951001 \n",
       "L 175.354716 -161.454744 \n",
       "L 175.773739 -161.955358 \n",
       "L 176.192765 -162.452738 \n",
       "L 176.611789 -162.946805 \n",
       "L 177.030812 -163.43754 \n",
       "L 177.449835 -163.924829 \n",
       "L 177.868859 -164.408601 \n",
       "L 178.287882 -164.888749 \n",
       "L 178.706906 -165.365231 \n",
       "L 179.125929 -165.837966 \n",
       "L 179.544955 -166.306918 \n",
       "L 179.963978 -166.771947 \n",
       "L 180.383002 -167.233 \n",
       "L 180.802025 -167.690023 \n",
       "L 181.221048 -168.142893 \n",
       "L 181.640072 -168.591592 \n",
       "L 182.059095 -169.036032 \n",
       "L 182.478119 -169.476098 \n",
       "L 182.897144 -169.911772 \n",
       "L 183.316168 -170.342956 \n",
       "L 183.735191 -170.769581 \n",
       "L 184.154215 -171.19155 \n",
       "L 184.57324 -171.608826 \n",
       "L 184.992264 -172.021312 \n",
       "L 185.411287 -172.428974 \n",
       "L 185.830311 -172.831722 \n",
       "L 186.249336 -173.229442 \n",
       "L 186.66836 -173.622152 \n",
       "L 187.087383 -174.009719 \n",
       "L 187.506407 -174.392099 \n",
       "L 187.92543 -174.769195 \n",
       "L 188.344453 -175.141006 \n",
       "L 188.763477 -175.50741 \n",
       "L 189.1825 -175.868316 \n",
       "L 189.601526 -176.223744 \n",
       "L 189.601526 -37.55625 \n",
       "L 189.601526 -37.55625 \n",
       "L 189.1825 -37.55625 \n",
       "L 188.763477 -37.55625 \n",
       "L 188.344453 -37.55625 \n",
       "L 187.92543 -37.55625 \n",
       "L 187.506407 -37.55625 \n",
       "L 187.087383 -37.55625 \n",
       "L 186.66836 -37.55625 \n",
       "L 186.249336 -37.55625 \n",
       "L 185.830311 -37.55625 \n",
       "L 185.411287 -37.55625 \n",
       "L 184.992264 -37.55625 \n",
       "L 184.57324 -37.55625 \n",
       "L 184.154215 -37.55625 \n",
       "L 183.735191 -37.55625 \n",
       "L 183.316168 -37.55625 \n",
       "L 182.897144 -37.55625 \n",
       "L 182.478119 -37.55625 \n",
       "L 182.059095 -37.55625 \n",
       "L 181.640072 -37.55625 \n",
       "L 181.221048 -37.55625 \n",
       "L 180.802025 -37.55625 \n",
       "L 180.383002 -37.55625 \n",
       "L 179.963978 -37.55625 \n",
       "L 179.544955 -37.55625 \n",
       "L 179.125929 -37.55625 \n",
       "L 178.706906 -37.55625 \n",
       "L 178.287882 -37.55625 \n",
       "L 177.868859 -37.55625 \n",
       "L 177.449835 -37.55625 \n",
       "L 177.030812 -37.55625 \n",
       "L 176.611789 -37.55625 \n",
       "L 176.192765 -37.55625 \n",
       "L 175.773739 -37.55625 \n",
       "L 175.354716 -37.55625 \n",
       "L 174.935693 -37.55625 \n",
       "L 174.516669 -37.55625 \n",
       "L 174.097646 -37.55625 \n",
       "L 173.678623 -37.55625 \n",
       "L 173.259599 -37.55625 \n",
       "L 172.840576 -37.55625 \n",
       "L 172.42155 -37.55625 \n",
       "L 172.002527 -37.55625 \n",
       "L 171.583503 -37.55625 \n",
       "L 171.16448 -37.55625 \n",
       "L 170.745456 -37.55625 \n",
       "L 170.326433 -37.55625 \n",
       "L 169.90741 -37.55625 \n",
       "L 169.488386 -37.55625 \n",
       "L 169.06936 -37.55625 \n",
       "L 168.650337 -37.55625 \n",
       "L 168.231314 -37.55625 \n",
       "L 167.81229 -37.55625 \n",
       "L 167.393267 -37.55625 \n",
       "L 166.974238 -37.55625 \n",
       "L 166.555215 -37.55625 \n",
       "L 166.136192 -37.55625 \n",
       "L 165.717168 -37.55625 \n",
       "z\n",
       "\" style=\"stroke: #2ca02c; stroke-opacity: 0.5\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#p1a3a22fac7)\">\n",
       "     <use xlink:href=\"#mfac49e5087\" x=\"0\" y=\"222.954375\" style=\"fill: #2ca02c; fill-opacity: 0.5; stroke: #2ca02c; stroke-opacity: 0.5\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"PolyCollection_4\">\n",
       "    <defs>\n",
       "     <path id=\"m2d2f5394f1\" d=\"M 190.020549 -37.55625 \n",
       "L 190.020549 -176.573561 \n",
       "L 190.439573 -176.917723 \n",
       "L 190.858596 -177.256176 \n",
       "L 191.277621 -177.588867 \n",
       "L 191.696644 -177.915709 \n",
       "L 192.115669 -178.236629 \n",
       "L 192.534692 -178.55163 \n",
       "L 192.953716 -178.86063 \n",
       "L 193.37274 -179.163524 \n",
       "L 193.791764 -179.460277 \n",
       "L 194.210787 -179.750879 \n",
       "L 194.62981 -180.035243 \n",
       "L 195.048834 -180.313297 \n",
       "L 195.467858 -180.585025 \n",
       "L 195.886882 -180.850354 \n",
       "L 196.305905 -181.109224 \n",
       "L 196.72493 -181.361608 \n",
       "L 197.143953 -181.60747 \n",
       "L 197.562976 -181.846723 \n",
       "L 197.982001 -182.07933 \n",
       "L 198.401024 -182.305266 \n",
       "L 198.820049 -182.524477 \n",
       "L 199.239072 -182.736919 \n",
       "L 199.658096 -182.942566 \n",
       "L 200.07712 -183.141355 \n",
       "L 200.496144 -183.333252 \n",
       "L 200.915167 -183.518239 \n",
       "L 201.334191 -183.696262 \n",
       "L 201.753215 -183.867296 \n",
       "L 202.172239 -184.031287 \n",
       "L 202.591263 -184.188226 \n",
       "L 203.010287 -184.338087 \n",
       "L 203.42931 -184.480799 \n",
       "L 203.848334 -184.616388 \n",
       "L 204.267357 -184.744794 \n",
       "L 204.686381 -184.865997 \n",
       "L 205.105405 -184.979973 \n",
       "L 205.524429 -185.086711 \n",
       "L 205.943453 -185.186176 \n",
       "L 206.362476 -185.278351 \n",
       "L 206.7815 -185.363245 \n",
       "L 207.200524 -185.440769 \n",
       "L 207.619548 -185.510985 \n",
       "L 208.038572 -185.57384 \n",
       "L 208.457595 -185.629335 \n",
       "L 208.876619 -185.677424 \n",
       "L 209.295643 -185.718161 \n",
       "L 209.714667 -185.751493 \n",
       "L 210.13369 -185.777446 \n",
       "L 210.552714 -185.795968 \n",
       "L 210.971738 -185.807084 \n",
       "L 210.971738 -37.55625 \n",
       "L 210.971738 -37.55625 \n",
       "L 210.552714 -37.55625 \n",
       "L 210.13369 -37.55625 \n",
       "L 209.714667 -37.55625 \n",
       "L 209.295643 -37.55625 \n",
       "L 208.876619 -37.55625 \n",
       "L 208.457595 -37.55625 \n",
       "L 208.038572 -37.55625 \n",
       "L 207.619548 -37.55625 \n",
       "L 207.200524 -37.55625 \n",
       "L 206.7815 -37.55625 \n",
       "L 206.362476 -37.55625 \n",
       "L 205.943453 -37.55625 \n",
       "L 205.524429 -37.55625 \n",
       "L 205.105405 -37.55625 \n",
       "L 204.686381 -37.55625 \n",
       "L 204.267357 -37.55625 \n",
       "L 203.848334 -37.55625 \n",
       "L 203.42931 -37.55625 \n",
       "L 203.010287 -37.55625 \n",
       "L 202.591263 -37.55625 \n",
       "L 202.172239 -37.55625 \n",
       "L 201.753215 -37.55625 \n",
       "L 201.334191 -37.55625 \n",
       "L 200.915167 -37.55625 \n",
       "L 200.496144 -37.55625 \n",
       "L 200.07712 -37.55625 \n",
       "L 199.658096 -37.55625 \n",
       "L 199.239072 -37.55625 \n",
       "L 198.820049 -37.55625 \n",
       "L 198.401024 -37.55625 \n",
       "L 197.982001 -37.55625 \n",
       "L 197.562976 -37.55625 \n",
       "L 197.143953 -37.55625 \n",
       "L 196.72493 -37.55625 \n",
       "L 196.305905 -37.55625 \n",
       "L 195.886882 -37.55625 \n",
       "L 195.467858 -37.55625 \n",
       "L 195.048834 -37.55625 \n",
       "L 194.62981 -37.55625 \n",
       "L 194.210787 -37.55625 \n",
       "L 193.791764 -37.55625 \n",
       "L 193.37274 -37.55625 \n",
       "L 192.953716 -37.55625 \n",
       "L 192.534692 -37.55625 \n",
       "L 192.115669 -37.55625 \n",
       "L 191.696644 -37.55625 \n",
       "L 191.277621 -37.55625 \n",
       "L 190.858596 -37.55625 \n",
       "L 190.439573 -37.55625 \n",
       "L 190.020549 -37.55625 \n",
       "z\n",
       "\" style=\"stroke: #d62728; stroke-opacity: 0.5\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#p1a3a22fac7)\">\n",
       "     <use xlink:href=\"#m2d2f5394f1\" x=\"0\" y=\"222.954375\" style=\"fill: #d62728; fill-opacity: 0.5; stroke: #d62728; stroke-opacity: 0.5\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"PolyCollection_5\">\n",
       "    <defs>\n",
       "     <path id=\"mcb045e629b\" d=\"M 211.390762 -37.55625 \n",
       "L 211.390762 -185.810795 \n",
       "L 211.809785 -185.807084 \n",
       "L 212.228809 -185.795968 \n",
       "L 212.647833 -185.777446 \n",
       "L 213.066857 -185.75151 \n",
       "L 213.485881 -185.718178 \n",
       "L 213.904904 -185.677459 \n",
       "L 214.323928 -185.629335 \n",
       "L 214.742952 -185.57384 \n",
       "L 215.161976 -185.510985 \n",
       "L 215.581 -185.440769 \n",
       "L 216.000023 -185.363227 \n",
       "L 216.419047 -185.278351 \n",
       "L 216.838071 -185.186176 \n",
       "L 217.257095 -185.086711 \n",
       "L 217.676118 -184.979973 \n",
       "L 218.095142 -184.866015 \n",
       "L 218.514166 -184.744794 \n",
       "L 218.933189 -184.616388 \n",
       "L 219.352213 -184.480799 \n",
       "L 219.771237 -184.338069 \n",
       "L 220.190261 -184.188226 \n",
       "L 220.609285 -184.031287 \n",
       "L 221.028308 -183.867278 \n",
       "L 221.447332 -183.696262 \n",
       "L 221.866356 -183.518239 \n",
       "L 222.28538 -183.333252 \n",
       "L 222.704403 -183.141355 \n",
       "L 223.123428 -182.942566 \n",
       "L 223.542451 -182.736919 \n",
       "L 223.961474 -182.524477 \n",
       "L 224.380499 -182.305266 \n",
       "L 224.799522 -182.07933 \n",
       "L 225.218546 -181.846723 \n",
       "L 225.63757 -181.607453 \n",
       "L 226.056594 -181.361626 \n",
       "L 226.475617 -181.109224 \n",
       "L 226.894642 -180.850354 \n",
       "L 227.313665 -180.585025 \n",
       "L 227.732688 -180.313297 \n",
       "L 228.151713 -180.035243 \n",
       "L 228.570736 -179.750888 \n",
       "L 228.989761 -179.460295 \n",
       "L 229.408784 -179.163524 \n",
       "L 229.827808 -178.860613 \n",
       "L 230.246833 -178.55163 \n",
       "L 230.665856 -178.236647 \n",
       "L 231.084879 -177.9157 \n",
       "L 231.503903 -177.588867 \n",
       "L 231.922926 -177.256176 \n",
       "L 232.341951 -176.917723 \n",
       "L 232.760974 -176.573561 \n",
       "L 232.760974 -37.55625 \n",
       "L 232.760974 -37.55625 \n",
       "L 232.341951 -37.55625 \n",
       "L 231.922926 -37.55625 \n",
       "L 231.503903 -37.55625 \n",
       "L 231.084879 -37.55625 \n",
       "L 230.665856 -37.55625 \n",
       "L 230.246833 -37.55625 \n",
       "L 229.827808 -37.55625 \n",
       "L 229.408784 -37.55625 \n",
       "L 228.989761 -37.55625 \n",
       "L 228.570736 -37.55625 \n",
       "L 228.151713 -37.55625 \n",
       "L 227.732688 -37.55625 \n",
       "L 227.313665 -37.55625 \n",
       "L 226.894642 -37.55625 \n",
       "L 226.475617 -37.55625 \n",
       "L 226.056594 -37.55625 \n",
       "L 225.63757 -37.55625 \n",
       "L 225.218546 -37.55625 \n",
       "L 224.799522 -37.55625 \n",
       "L 224.380499 -37.55625 \n",
       "L 223.961474 -37.55625 \n",
       "L 223.542451 -37.55625 \n",
       "L 223.123428 -37.55625 \n",
       "L 222.704403 -37.55625 \n",
       "L 222.28538 -37.55625 \n",
       "L 221.866356 -37.55625 \n",
       "L 221.447332 -37.55625 \n",
       "L 221.028308 -37.55625 \n",
       "L 220.609285 -37.55625 \n",
       "L 220.190261 -37.55625 \n",
       "L 219.771237 -37.55625 \n",
       "L 219.352213 -37.55625 \n",
       "L 218.933189 -37.55625 \n",
       "L 218.514166 -37.55625 \n",
       "L 218.095142 -37.55625 \n",
       "L 217.676118 -37.55625 \n",
       "L 217.257095 -37.55625 \n",
       "L 216.838071 -37.55625 \n",
       "L 216.419047 -37.55625 \n",
       "L 216.000023 -37.55625 \n",
       "L 215.581 -37.55625 \n",
       "L 215.161976 -37.55625 \n",
       "L 214.742952 -37.55625 \n",
       "L 214.323928 -37.55625 \n",
       "L 213.904904 -37.55625 \n",
       "L 213.485881 -37.55625 \n",
       "L 213.066857 -37.55625 \n",
       "L 212.647833 -37.55625 \n",
       "L 212.228809 -37.55625 \n",
       "L 211.809785 -37.55625 \n",
       "L 211.390762 -37.55625 \n",
       "z\n",
       "\" style=\"stroke: #9467bd; stroke-opacity: 0.5\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#p1a3a22fac7)\">\n",
       "     <use xlink:href=\"#mcb045e629b\" x=\"0\" y=\"222.954375\" style=\"fill: #9467bd; fill-opacity: 0.5; stroke: #9467bd; stroke-opacity: 0.5\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"PolyCollection_6\">\n",
       "    <defs>\n",
       "     <path id=\"m1e32963076\" d=\"M 233.179997 -37.55625 \n",
       "L 233.179997 -176.223736 \n",
       "L 233.599021 -175.868316 \n",
       "L 234.018044 -175.507392 \n",
       "L 234.43707 -175.141006 \n",
       "L 234.856093 -174.769213 \n",
       "L 235.275117 -174.392099 \n",
       "L 235.69414 -174.009719 \n",
       "L 236.113164 -173.622152 \n",
       "L 236.532189 -173.229478 \n",
       "L 236.951213 -172.831704 \n",
       "L 237.370236 -172.428974 \n",
       "L 237.78926 -172.021321 \n",
       "L 238.208283 -171.608817 \n",
       "L 238.627306 -171.19155 \n",
       "L 239.04633 -170.769564 \n",
       "L 239.465353 -170.342939 \n",
       "L 239.884379 -169.911772 \n",
       "L 240.303402 -169.476098 \n",
       "L 240.722426 -169.036014 \n",
       "L 241.141449 -168.591592 \n",
       "L 241.560475 -168.142893 \n",
       "L 241.979498 -167.690006 \n",
       "L 242.398522 -167.233 \n",
       "L 242.817545 -166.771947 \n",
       "L 243.236571 -166.306918 \n",
       "L 243.655594 -165.837992 \n",
       "L 244.074618 -165.365231 \n",
       "L 244.493641 -164.888749 \n",
       "L 244.912665 -164.408601 \n",
       "L 245.331688 -163.924829 \n",
       "L 245.750711 -163.437558 \n",
       "L 246.169735 -162.946831 \n",
       "L 246.588761 -162.452738 \n",
       "L 247.007784 -161.955349 \n",
       "L 247.426807 -161.454735 \n",
       "L 247.845831 -160.951001 \n",
       "L 248.264854 -160.444192 \n",
       "L 248.683877 -159.934397 \n",
       "L 249.102901 -159.421658 \n",
       "L 249.521924 -158.90611 \n",
       "L 249.94095 -158.387796 \n",
       "L 250.359973 -157.866777 \n",
       "L 250.778997 -157.343161 \n",
       "L 251.19802 -156.817 \n",
       "L 251.617044 -156.288364 \n",
       "L 252.036067 -155.757361 \n",
       "L 252.45509 -155.224024 \n",
       "L 252.874114 -154.688443 \n",
       "L 253.29314 -154.150706 \n",
       "L 253.712163 -153.610865 \n",
       "L 254.131186 -153.069001 \n",
       "L 254.55021 -152.525193 \n",
       "L 254.969233 -151.979512 \n",
       "L 255.388257 -151.432019 \n",
       "L 255.80728 -150.882803 \n",
       "L 256.226303 -150.331917 \n",
       "L 256.645327 -149.77944 \n",
       "L 257.06435 -149.225443 \n",
       "L 257.06435 -37.55625 \n",
       "L 257.06435 -37.55625 \n",
       "L 256.645327 -37.55625 \n",
       "L 256.226303 -37.55625 \n",
       "L 255.80728 -37.55625 \n",
       "L 255.388257 -37.55625 \n",
       "L 254.969233 -37.55625 \n",
       "L 254.55021 -37.55625 \n",
       "L 254.131186 -37.55625 \n",
       "L 253.712163 -37.55625 \n",
       "L 253.29314 -37.55625 \n",
       "L 252.874114 -37.55625 \n",
       "L 252.45509 -37.55625 \n",
       "L 252.036067 -37.55625 \n",
       "L 251.617044 -37.55625 \n",
       "L 251.19802 -37.55625 \n",
       "L 250.778997 -37.55625 \n",
       "L 250.359973 -37.55625 \n",
       "L 249.94095 -37.55625 \n",
       "L 249.521924 -37.55625 \n",
       "L 249.102901 -37.55625 \n",
       "L 248.683877 -37.55625 \n",
       "L 248.264854 -37.55625 \n",
       "L 247.845831 -37.55625 \n",
       "L 247.426807 -37.55625 \n",
       "L 247.007784 -37.55625 \n",
       "L 246.588761 -37.55625 \n",
       "L 246.169735 -37.55625 \n",
       "L 245.750711 -37.55625 \n",
       "L 245.331688 -37.55625 \n",
       "L 244.912665 -37.55625 \n",
       "L 244.493641 -37.55625 \n",
       "L 244.074618 -37.55625 \n",
       "L 243.655594 -37.55625 \n",
       "L 243.236571 -37.55625 \n",
       "L 242.817545 -37.55625 \n",
       "L 242.398522 -37.55625 \n",
       "L 241.979498 -37.55625 \n",
       "L 241.560475 -37.55625 \n",
       "L 241.141449 -37.55625 \n",
       "L 240.722426 -37.55625 \n",
       "L 240.303402 -37.55625 \n",
       "L 239.884379 -37.55625 \n",
       "L 239.465353 -37.55625 \n",
       "L 239.04633 -37.55625 \n",
       "L 238.627306 -37.55625 \n",
       "L 238.208283 -37.55625 \n",
       "L 237.78926 -37.55625 \n",
       "L 237.370236 -37.55625 \n",
       "L 236.951213 -37.55625 \n",
       "L 236.532189 -37.55625 \n",
       "L 236.113164 -37.55625 \n",
       "L 235.69414 -37.55625 \n",
       "L 235.275117 -37.55625 \n",
       "L 234.856093 -37.55625 \n",
       "L 234.43707 -37.55625 \n",
       "L 234.018044 -37.55625 \n",
       "L 233.599021 -37.55625 \n",
       "L 233.179997 -37.55625 \n",
       "z\n",
       "\" style=\"stroke: #8c564b; stroke-opacity: 0.5\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#p1a3a22fac7)\">\n",
       "     <use xlink:href=\"#m1e32963076\" x=\"0\" y=\"222.954375\" style=\"fill: #8c564b; fill-opacity: 0.5; stroke: #8c564b; stroke-opacity: 0.5\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"PolyCollection_7\">\n",
       "    <defs>\n",
       "     <path id=\"ma5c757af47\" d=\"M 257.483373 -37.55625 \n",
       "L 257.483373 -148.670006 \n",
       "L 257.902402 -148.113164 \n",
       "L 258.321425 -147.555032 \n",
       "L 258.740449 -146.995645 \n",
       "L 259.159472 -146.435109 \n",
       "L 259.578495 -145.873442 \n",
       "L 259.997519 -145.31075 \n",
       "L 260.416542 -144.747068 \n",
       "L 260.835565 -144.182503 \n",
       "L 261.254594 -143.617081 \n",
       "L 261.673617 -143.050889 \n",
       "L 262.092641 -142.483991 \n",
       "L 262.511664 -141.916439 \n",
       "L 262.930687 -141.348304 \n",
       "L 263.349711 -140.779647 \n",
       "L 263.768734 -140.210548 \n",
       "L 264.187757 -139.641026 \n",
       "L 264.606786 -139.071185 \n",
       "L 265.025804 -138.501061 \n",
       "L 265.444828 -137.930734 \n",
       "L 265.863851 -137.36024 \n",
       "L 266.282874 -136.789657 \n",
       "L 266.701898 -136.21902 \n",
       "L 267.120921 -135.648411 \n",
       "L 267.539945 -135.077881 \n",
       "L 267.958973 -134.507465 \n",
       "L 268.377996 -133.937245 \n",
       "L 268.79702 -133.367254 \n",
       "L 269.216043 -132.797572 \n",
       "L 269.635066 -132.228226 \n",
       "L 270.05409 -131.659278 \n",
       "L 270.473113 -131.090789 \n",
       "L 270.892137 -130.522795 \n",
       "L 271.311165 -129.955349 \n",
       "L 271.730188 -129.388512 \n",
       "L 272.149212 -128.82233 \n",
       "L 272.568235 -128.256837 \n",
       "L 272.987258 -127.692086 \n",
       "L 273.406282 -127.128148 \n",
       "L 273.825305 -126.565023 \n",
       "L 274.244329 -126.002808 \n",
       "L 274.663357 -125.441504 \n",
       "L 275.082375 -124.881197 \n",
       "L 275.501399 -124.32189 \n",
       "L 275.920422 -123.763634 \n",
       "L 276.339445 -123.206509 \n",
       "L 276.758469 -122.650498 \n",
       "L 277.177492 -122.095679 \n",
       "L 277.596516 -121.542089 \n",
       "L 278.015544 -120.989745 \n",
       "L 278.434567 -120.438717 \n",
       "L 278.853591 -119.889024 \n",
       "L 279.272614 -119.340709 \n",
       "L 279.691638 -118.793791 \n",
       "L 280.110661 -118.248339 \n",
       "L 280.529684 -117.704345 \n",
       "L 280.948708 -117.161889 \n",
       "L 281.367736 -116.620962 \n",
       "L 281.786754 -116.081634 \n",
       "L 282.205778 -115.543915 \n",
       "L 282.624801 -115.00783 \n",
       "L 283.043825 -114.473433 \n",
       "L 283.462848 -113.940741 \n",
       "L 283.881871 -113.409782 \n",
       "L 284.300895 -112.88059 \n",
       "L 284.719923 -112.353165 \n",
       "L 285.138946 -111.827596 \n",
       "L 285.55797 -111.303851 \n",
       "L 285.976993 -110.781985 \n",
       "L 286.396017 -110.262009 \n",
       "L 286.81504 -109.743969 \n",
       "L 287.234063 -109.227864 \n",
       "L 287.653087 -108.713729 \n",
       "L 288.072115 -108.201587 \n",
       "L 288.491138 -107.691469 \n",
       "L 288.910162 -107.183379 \n",
       "L 289.329185 -106.677356 \n",
       "L 289.748209 -106.173388 \n",
       "L 290.167232 -105.671537 \n",
       "L 290.586255 -105.17181 \n",
       "L 291.005279 -104.674209 \n",
       "L 291.424307 -104.178747 \n",
       "L 291.843326 -103.685475 \n",
       "L 292.262349 -103.194387 \n",
       "L 292.681372 -102.705516 \n",
       "L 292.681372 -37.55625 \n",
       "L 292.681372 -37.55625 \n",
       "L 292.262349 -37.55625 \n",
       "L 291.843326 -37.55625 \n",
       "L 291.424307 -37.55625 \n",
       "L 291.005279 -37.55625 \n",
       "L 290.586255 -37.55625 \n",
       "L 290.167232 -37.55625 \n",
       "L 289.748209 -37.55625 \n",
       "L 289.329185 -37.55625 \n",
       "L 288.910162 -37.55625 \n",
       "L 288.491138 -37.55625 \n",
       "L 288.072115 -37.55625 \n",
       "L 287.653087 -37.55625 \n",
       "L 287.234063 -37.55625 \n",
       "L 286.81504 -37.55625 \n",
       "L 286.396017 -37.55625 \n",
       "L 285.976993 -37.55625 \n",
       "L 285.55797 -37.55625 \n",
       "L 285.138946 -37.55625 \n",
       "L 284.719923 -37.55625 \n",
       "L 284.300895 -37.55625 \n",
       "L 283.881871 -37.55625 \n",
       "L 283.462848 -37.55625 \n",
       "L 283.043825 -37.55625 \n",
       "L 282.624801 -37.55625 \n",
       "L 282.205778 -37.55625 \n",
       "L 281.786754 -37.55625 \n",
       "L 281.367736 -37.55625 \n",
       "L 280.948708 -37.55625 \n",
       "L 280.529684 -37.55625 \n",
       "L 280.110661 -37.55625 \n",
       "L 279.691638 -37.55625 \n",
       "L 279.272614 -37.55625 \n",
       "L 278.853591 -37.55625 \n",
       "L 278.434567 -37.55625 \n",
       "L 278.015544 -37.55625 \n",
       "L 277.596516 -37.55625 \n",
       "L 277.177492 -37.55625 \n",
       "L 276.758469 -37.55625 \n",
       "L 276.339445 -37.55625 \n",
       "L 275.920422 -37.55625 \n",
       "L 275.501399 -37.55625 \n",
       "L 275.082375 -37.55625 \n",
       "L 274.663357 -37.55625 \n",
       "L 274.244329 -37.55625 \n",
       "L 273.825305 -37.55625 \n",
       "L 273.406282 -37.55625 \n",
       "L 272.987258 -37.55625 \n",
       "L 272.568235 -37.55625 \n",
       "L 272.149212 -37.55625 \n",
       "L 271.730188 -37.55625 \n",
       "L 271.311165 -37.55625 \n",
       "L 270.892137 -37.55625 \n",
       "L 270.473113 -37.55625 \n",
       "L 270.05409 -37.55625 \n",
       "L 269.635066 -37.55625 \n",
       "L 269.216043 -37.55625 \n",
       "L 268.79702 -37.55625 \n",
       "L 268.377996 -37.55625 \n",
       "L 267.958973 -37.55625 \n",
       "L 267.539945 -37.55625 \n",
       "L 267.120921 -37.55625 \n",
       "L 266.701898 -37.55625 \n",
       "L 266.282874 -37.55625 \n",
       "L 265.863851 -37.55625 \n",
       "L 265.444828 -37.55625 \n",
       "L 265.025804 -37.55625 \n",
       "L 264.606786 -37.55625 \n",
       "L 264.187757 -37.55625 \n",
       "L 263.768734 -37.55625 \n",
       "L 263.349711 -37.55625 \n",
       "L 262.930687 -37.55625 \n",
       "L 262.511664 -37.55625 \n",
       "L 262.092641 -37.55625 \n",
       "L 261.673617 -37.55625 \n",
       "L 261.254594 -37.55625 \n",
       "L 260.835565 -37.55625 \n",
       "L 260.416542 -37.55625 \n",
       "L 259.997519 -37.55625 \n",
       "L 259.578495 -37.55625 \n",
       "L 259.159472 -37.55625 \n",
       "L 258.740449 -37.55625 \n",
       "L 258.321425 -37.55625 \n",
       "L 257.902402 -37.55625 \n",
       "L 257.483373 -37.55625 \n",
       "z\n",
       "\" style=\"stroke: #e377c2; stroke-opacity: 0.5\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#p1a3a22fac7)\">\n",
       "     <use xlink:href=\"#ma5c757af47\" x=\"0\" y=\"222.954375\" style=\"fill: #e377c2; fill-opacity: 0.5; stroke: #e377c2; stroke-opacity: 0.5\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"PolyCollection_8\">\n",
       "    <defs>\n",
       "     <path id=\"mdfabb3110b\" d=\"M 293.100396 -37.55625 \n",
       "L 293.100396 -102.218851 \n",
       "L 293.519419 -101.734429 \n",
       "L 293.938442 -101.252244 \n",
       "L 294.357466 -100.772334 \n",
       "L 294.776494 -100.294695 \n",
       "L 295.195518 -99.819362 \n",
       "L 295.614541 -99.346313 \n",
       "L 296.033564 -98.875593 \n",
       "L 296.452588 -98.407206 \n",
       "L 296.871611 -97.941147 \n",
       "L 297.290634 -97.477439 \n",
       "L 297.709658 -97.016091 \n",
       "L 298.128681 -96.557115 \n",
       "L 298.547705 -96.10052 \n",
       "L 298.966728 -95.646298 \n",
       "L 299.385751 -95.194484 \n",
       "L 299.804775 -94.745065 \n",
       "L 300.223798 -94.298058 \n",
       "L 300.642821 -93.853468 \n",
       "L 301.061845 -93.411299 \n",
       "L 301.480868 -92.971556 \n",
       "L 301.899902 -92.534243 \n",
       "L 302.318925 -92.099391 \n",
       "L 302.737948 -91.666973 \n",
       "L 303.156972 -91.236995 \n",
       "L 303.575995 -90.809473 \n",
       "L 303.995018 -90.384407 \n",
       "L 304.414042 -89.961812 \n",
       "L 304.833065 -89.541668 \n",
       "L 305.252089 -89.123995 \n",
       "L 305.671112 -88.708774 \n",
       "L 306.090135 -88.29604 \n",
       "L 306.509159 -87.885767 \n",
       "L 306.928182 -87.477959 \n",
       "L 307.347206 -87.072626 \n",
       "L 307.766229 -86.669767 \n",
       "L 308.185252 -86.269369 \n",
       "L 308.604276 -85.871446 \n",
       "L 309.023299 -85.475992 \n",
       "L 309.442322 -85.083017 \n",
       "L 309.861346 -84.692503 \n",
       "L 310.280369 -84.304445 \n",
       "L 310.699393 -83.918858 \n",
       "L 311.118416 -83.535736 \n",
       "L 311.537439 -83.155061 \n",
       "L 311.956473 -82.776852 \n",
       "L 312.375496 -82.401091 \n",
       "L 312.794519 -82.027777 \n",
       "L 313.213543 -81.65692 \n",
       "L 313.632566 -81.288507 \n",
       "L 314.05159 -80.922519 \n",
       "L 314.470613 -80.55897 \n",
       "L 314.889636 -80.19786 \n",
       "L 315.30866 -79.839167 \n",
       "L 315.727683 -79.48289 \n",
       "L 316.146706 -79.12903 \n",
       "L 316.56573 -78.777579 \n",
       "L 316.984753 -78.428531 \n",
       "L 317.403777 -78.081877 \n",
       "L 317.8228 -77.737623 \n",
       "L 318.241823 -77.395737 \n",
       "L 318.660847 -77.056246 \n",
       "L 319.07987 -76.719114 \n",
       "L 319.498894 -76.38436 \n",
       "L 319.917917 -76.051951 \n",
       "L 320.33694 -75.721897 \n",
       "L 320.755964 -75.394185 \n",
       "L 321.174987 -75.068806 \n",
       "L 321.59401 -74.745756 \n",
       "L 322.013044 -74.425023 \n",
       "L 322.432067 -74.1066 \n",
       "L 322.851091 -73.790486 \n",
       "L 323.270114 -73.476672 \n",
       "L 323.689137 -73.165134 \n",
       "L 324.108161 -72.855884 \n",
       "L 324.527184 -72.548894 \n",
       "L 324.946207 -72.24417 \n",
       "L 325.365231 -71.941698 \n",
       "L 325.784254 -71.641464 \n",
       "L 326.203278 -71.343465 \n",
       "L 326.622301 -71.047689 \n",
       "L 327.041324 -70.754128 \n",
       "L 327.460348 -70.462775 \n",
       "L 327.879371 -70.173611 \n",
       "L 328.298394 -69.886634 \n",
       "L 328.717418 -69.601839 \n",
       "L 329.136441 -69.319203 \n",
       "L 329.555465 -69.038723 \n",
       "L 329.974488 -68.76039 \n",
       "L 330.393511 -68.484189 \n",
       "L 330.812535 -68.210118 \n",
       "L 331.231558 -67.938155 \n",
       "L 331.650582 -67.668305 \n",
       "L 332.069615 -67.400539 \n",
       "L 332.488638 -67.134856 \n",
       "L 332.907662 -66.871254 \n",
       "L 333.326685 -66.609709 \n",
       "L 333.745708 -66.350216 \n",
       "L 334.164732 -66.092768 \n",
       "L 334.583755 -65.837347 \n",
       "L 335.002779 -65.583943 \n",
       "L 335.421802 -65.332546 \n",
       "L 335.840825 -65.083154 \n",
       "L 336.259849 -64.83574 \n",
       "L 336.678872 -64.5903 \n",
       "L 337.097895 -64.346832 \n",
       "L 337.516919 -64.105309 \n",
       "L 337.935942 -63.865731 \n",
       "L 338.354966 -63.628087 \n",
       "L 338.773989 -63.39236 \n",
       "L 339.193012 -63.158538 \n",
       "L 339.612036 -62.926615 \n",
       "L 340.031059 -62.696577 \n",
       "L 340.450082 -62.468417 \n",
       "L 340.869106 -62.242117 \n",
       "L 341.288129 -62.017672 \n",
       "L 341.707153 -61.795061 \n",
       "L 342.126176 -61.574288 \n",
       "L 342.545199 -61.355331 \n",
       "L 342.964223 -61.138179 \n",
       "L 343.383246 -60.922821 \n",
       "L 343.80227 -60.709252 \n",
       "L 344.221293 -60.497449 \n",
       "L 344.640316 -60.287414 \n",
       "L 345.05934 -60.079126 \n",
       "L 345.478373 -59.872571 \n",
       "L 345.897396 -59.667753 \n",
       "L 346.31642 -59.464646 \n",
       "L 346.735443 -59.26325 \n",
       "L 347.154467 -59.063548 \n",
       "L 347.57349 -58.865523 \n",
       "L 347.992513 -58.669172 \n",
       "L 348.411537 -58.474481 \n",
       "L 348.83056 -58.28144 \n",
       "L 349.249583 -58.090035 \n",
       "L 349.668607 -57.900262 \n",
       "L 350.08763 -57.712098 \n",
       "L 350.506654 -57.525543 \n",
       "L 350.925677 -57.340581 \n",
       "L 351.3447 -57.1572 \n",
       "L 351.763724 -56.97539 \n",
       "L 352.182747 -56.795145 \n",
       "L 352.60177 -56.616443 \n",
       "L 353.020794 -56.439286 \n",
       "L 353.439817 -56.263648 \n",
       "L 353.858841 -56.089535 \n",
       "L 354.277864 -55.916924 \n",
       "L 354.696887 -55.745808 \n",
       "L 355.115911 -55.576175 \n",
       "L 355.534944 -55.408013 \n",
       "L 355.953968 -55.241318 \n",
       "L 356.372991 -55.076073 \n",
       "L 356.792014 -54.912272 \n",
       "L 357.211038 -54.749904 \n",
       "L 357.630061 -54.588953 \n",
       "L 358.049084 -54.42941 \n",
       "L 358.468108 -54.271268 \n",
       "L 358.887131 -54.114517 \n",
       "L 359.306155 -53.959142 \n",
       "L 359.725178 -53.805134 \n",
       "L 360.144201 -53.652486 \n",
       "L 360.563225 -53.501185 \n",
       "L 360.982248 -53.351219 \n",
       "L 361.401271 -53.202586 \n",
       "L 361.820295 -53.055263 \n",
       "L 362.239318 -52.909253 \n",
       "L 362.658342 -52.764535 \n",
       "L 363.077365 -52.621108 \n",
       "L 363.496388 -52.478952 \n",
       "L 363.915412 -52.338066 \n",
       "L 364.334435 -52.198439 \n",
       "L 364.753458 -52.060059 \n",
       "L 365.172482 -51.922914 \n",
       "L 365.591515 -51.786995 \n",
       "L 366.010539 -51.652296 \n",
       "L 366.429562 -51.518807 \n",
       "L 366.848585 -51.386517 \n",
       "L 367.267609 -51.255417 \n",
       "L 367.686632 -51.125497 \n",
       "L 368.105656 -50.996747 \n",
       "L 368.524679 -50.869159 \n",
       "L 368.943702 -50.742722 \n",
       "L 369.362726 -50.617427 \n",
       "L 369.781749 -50.493266 \n",
       "L 370.200772 -50.370231 \n",
       "L 370.619796 -50.248312 \n",
       "L 371.038819 -50.127496 \n",
       "L 371.457843 -50.007779 \n",
       "L 371.876866 -49.889149 \n",
       "L 372.295889 -49.771601 \n",
       "L 372.714913 -49.65512 \n",
       "L 373.133936 -49.539705 \n",
       "L 373.552959 -49.42534 \n",
       "L 373.971983 -49.312022 \n",
       "L 374.391006 -49.199737 \n",
       "L 374.81003 -49.088478 \n",
       "L 375.229053 -48.97824 \n",
       "L 375.648086 -48.869009 \n",
       "L 376.06711 -48.760785 \n",
       "L 376.486133 -48.653552 \n",
       "L 376.905156 -48.547304 \n",
       "L 377.32418 -48.442033 \n",
       "L 377.743203 -48.337729 \n",
       "L 378.162227 -48.23439 \n",
       "L 378.58125 -48.132001 \n",
       "L 378.58125 -37.55625 \n",
       "L 378.58125 -37.55625 \n",
       "L 378.162227 -37.55625 \n",
       "L 377.743203 -37.55625 \n",
       "L 377.32418 -37.55625 \n",
       "L 376.905156 -37.55625 \n",
       "L 376.486133 -37.55625 \n",
       "L 376.06711 -37.55625 \n",
       "L 375.648086 -37.55625 \n",
       "L 375.229053 -37.55625 \n",
       "L 374.81003 -37.55625 \n",
       "L 374.391006 -37.55625 \n",
       "L 373.971983 -37.55625 \n",
       "L 373.552959 -37.55625 \n",
       "L 373.133936 -37.55625 \n",
       "L 372.714913 -37.55625 \n",
       "L 372.295889 -37.55625 \n",
       "L 371.876866 -37.55625 \n",
       "L 371.457843 -37.55625 \n",
       "L 371.038819 -37.55625 \n",
       "L 370.619796 -37.55625 \n",
       "L 370.200772 -37.55625 \n",
       "L 369.781749 -37.55625 \n",
       "L 369.362726 -37.55625 \n",
       "L 368.943702 -37.55625 \n",
       "L 368.524679 -37.55625 \n",
       "L 368.105656 -37.55625 \n",
       "L 367.686632 -37.55625 \n",
       "L 367.267609 -37.55625 \n",
       "L 366.848585 -37.55625 \n",
       "L 366.429562 -37.55625 \n",
       "L 366.010539 -37.55625 \n",
       "L 365.591515 -37.55625 \n",
       "L 365.172482 -37.55625 \n",
       "L 364.753458 -37.55625 \n",
       "L 364.334435 -37.55625 \n",
       "L 363.915412 -37.55625 \n",
       "L 363.496388 -37.55625 \n",
       "L 363.077365 -37.55625 \n",
       "L 362.658342 -37.55625 \n",
       "L 362.239318 -37.55625 \n",
       "L 361.820295 -37.55625 \n",
       "L 361.401271 -37.55625 \n",
       "L 360.982248 -37.55625 \n",
       "L 360.563225 -37.55625 \n",
       "L 360.144201 -37.55625 \n",
       "L 359.725178 -37.55625 \n",
       "L 359.306155 -37.55625 \n",
       "L 358.887131 -37.55625 \n",
       "L 358.468108 -37.55625 \n",
       "L 358.049084 -37.55625 \n",
       "L 357.630061 -37.55625 \n",
       "L 357.211038 -37.55625 \n",
       "L 356.792014 -37.55625 \n",
       "L 356.372991 -37.55625 \n",
       "L 355.953968 -37.55625 \n",
       "L 355.534944 -37.55625 \n",
       "L 355.115911 -37.55625 \n",
       "L 354.696887 -37.55625 \n",
       "L 354.277864 -37.55625 \n",
       "L 353.858841 -37.55625 \n",
       "L 353.439817 -37.55625 \n",
       "L 353.020794 -37.55625 \n",
       "L 352.60177 -37.55625 \n",
       "L 352.182747 -37.55625 \n",
       "L 351.763724 -37.55625 \n",
       "L 351.3447 -37.55625 \n",
       "L 350.925677 -37.55625 \n",
       "L 350.506654 -37.55625 \n",
       "L 350.08763 -37.55625 \n",
       "L 349.668607 -37.55625 \n",
       "L 349.249583 -37.55625 \n",
       "L 348.83056 -37.55625 \n",
       "L 348.411537 -37.55625 \n",
       "L 347.992513 -37.55625 \n",
       "L 347.57349 -37.55625 \n",
       "L 347.154467 -37.55625 \n",
       "L 346.735443 -37.55625 \n",
       "L 346.31642 -37.55625 \n",
       "L 345.897396 -37.55625 \n",
       "L 345.478373 -37.55625 \n",
       "L 345.05934 -37.55625 \n",
       "L 344.640316 -37.55625 \n",
       "L 344.221293 -37.55625 \n",
       "L 343.80227 -37.55625 \n",
       "L 343.383246 -37.55625 \n",
       "L 342.964223 -37.55625 \n",
       "L 342.545199 -37.55625 \n",
       "L 342.126176 -37.55625 \n",
       "L 341.707153 -37.55625 \n",
       "L 341.288129 -37.55625 \n",
       "L 340.869106 -37.55625 \n",
       "L 340.450082 -37.55625 \n",
       "L 340.031059 -37.55625 \n",
       "L 339.612036 -37.55625 \n",
       "L 339.193012 -37.55625 \n",
       "L 338.773989 -37.55625 \n",
       "L 338.354966 -37.55625 \n",
       "L 337.935942 -37.55625 \n",
       "L 337.516919 -37.55625 \n",
       "L 337.097895 -37.55625 \n",
       "L 336.678872 -37.55625 \n",
       "L 336.259849 -37.55625 \n",
       "L 335.840825 -37.55625 \n",
       "L 335.421802 -37.55625 \n",
       "L 335.002779 -37.55625 \n",
       "L 334.583755 -37.55625 \n",
       "L 334.164732 -37.55625 \n",
       "L 333.745708 -37.55625 \n",
       "L 333.326685 -37.55625 \n",
       "L 332.907662 -37.55625 \n",
       "L 332.488638 -37.55625 \n",
       "L 332.069615 -37.55625 \n",
       "L 331.650582 -37.55625 \n",
       "L 331.231558 -37.55625 \n",
       "L 330.812535 -37.55625 \n",
       "L 330.393511 -37.55625 \n",
       "L 329.974488 -37.55625 \n",
       "L 329.555465 -37.55625 \n",
       "L 329.136441 -37.55625 \n",
       "L 328.717418 -37.55625 \n",
       "L 328.298394 -37.55625 \n",
       "L 327.879371 -37.55625 \n",
       "L 327.460348 -37.55625 \n",
       "L 327.041324 -37.55625 \n",
       "L 326.622301 -37.55625 \n",
       "L 326.203278 -37.55625 \n",
       "L 325.784254 -37.55625 \n",
       "L 325.365231 -37.55625 \n",
       "L 324.946207 -37.55625 \n",
       "L 324.527184 -37.55625 \n",
       "L 324.108161 -37.55625 \n",
       "L 323.689137 -37.55625 \n",
       "L 323.270114 -37.55625 \n",
       "L 322.851091 -37.55625 \n",
       "L 322.432067 -37.55625 \n",
       "L 322.013044 -37.55625 \n",
       "L 321.59401 -37.55625 \n",
       "L 321.174987 -37.55625 \n",
       "L 320.755964 -37.55625 \n",
       "L 320.33694 -37.55625 \n",
       "L 319.917917 -37.55625 \n",
       "L 319.498894 -37.55625 \n",
       "L 319.07987 -37.55625 \n",
       "L 318.660847 -37.55625 \n",
       "L 318.241823 -37.55625 \n",
       "L 317.8228 -37.55625 \n",
       "L 317.403777 -37.55625 \n",
       "L 316.984753 -37.55625 \n",
       "L 316.56573 -37.55625 \n",
       "L 316.146706 -37.55625 \n",
       "L 315.727683 -37.55625 \n",
       "L 315.30866 -37.55625 \n",
       "L 314.889636 -37.55625 \n",
       "L 314.470613 -37.55625 \n",
       "L 314.05159 -37.55625 \n",
       "L 313.632566 -37.55625 \n",
       "L 313.213543 -37.55625 \n",
       "L 312.794519 -37.55625 \n",
       "L 312.375496 -37.55625 \n",
       "L 311.956473 -37.55625 \n",
       "L 311.537439 -37.55625 \n",
       "L 311.118416 -37.55625 \n",
       "L 310.699393 -37.55625 \n",
       "L 310.280369 -37.55625 \n",
       "L 309.861346 -37.55625 \n",
       "L 309.442322 -37.55625 \n",
       "L 309.023299 -37.55625 \n",
       "L 308.604276 -37.55625 \n",
       "L 308.185252 -37.55625 \n",
       "L 307.766229 -37.55625 \n",
       "L 307.347206 -37.55625 \n",
       "L 306.928182 -37.55625 \n",
       "L 306.509159 -37.55625 \n",
       "L 306.090135 -37.55625 \n",
       "L 305.671112 -37.55625 \n",
       "L 305.252089 -37.55625 \n",
       "L 304.833065 -37.55625 \n",
       "L 304.414042 -37.55625 \n",
       "L 303.995018 -37.55625 \n",
       "L 303.575995 -37.55625 \n",
       "L 303.156972 -37.55625 \n",
       "L 302.737948 -37.55625 \n",
       "L 302.318925 -37.55625 \n",
       "L 301.899902 -37.55625 \n",
       "L 301.480868 -37.55625 \n",
       "L 301.061845 -37.55625 \n",
       "L 300.642821 -37.55625 \n",
       "L 300.223798 -37.55625 \n",
       "L 299.804775 -37.55625 \n",
       "L 299.385751 -37.55625 \n",
       "L 298.966728 -37.55625 \n",
       "L 298.547705 -37.55625 \n",
       "L 298.128681 -37.55625 \n",
       "L 297.709658 -37.55625 \n",
       "L 297.290634 -37.55625 \n",
       "L 296.871611 -37.55625 \n",
       "L 296.452588 -37.55625 \n",
       "L 296.033564 -37.55625 \n",
       "L 295.614541 -37.55625 \n",
       "L 295.195518 -37.55625 \n",
       "L 294.776494 -37.55625 \n",
       "L 294.357466 -37.55625 \n",
       "L 293.938442 -37.55625 \n",
       "L 293.519419 -37.55625 \n",
       "L 293.100396 -37.55625 \n",
       "z\n",
       "\" style=\"stroke: #7f7f7f; stroke-opacity: 0.5\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#p1a3a22fac7)\">\n",
       "     <use xlink:href=\"#mdfabb3110b\" x=\"0\" y=\"222.954375\" style=\"fill: #7f7f7f; fill-opacity: 0.5; stroke: #7f7f7f; stroke-opacity: 0.5\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_1\">\n",
       "    <path d=\"M 43.78125 185.398125 \n",
       "L 43.78125 174.923817 \n",
       "\" clip-path=\"url(#p1a3a22fac7)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 2; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_2\">\n",
       "    <path d=\"M 129.681123 185.398125 \n",
       "L 129.681123 120.735538 \n",
       "\" clip-path=\"url(#p1a3a22fac7)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 2; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_3\">\n",
       "    <path d=\"M 130.100146 185.398125 \n",
       "L 130.100146 120.248872 \n",
       "\" clip-path=\"url(#p1a3a22fac7)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 2; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_4\">\n",
       "    <path d=\"M 165.298145 185.398125 \n",
       "L 165.298145 74.284369 \n",
       "\" clip-path=\"url(#p1a3a22fac7)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 2; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_5\">\n",
       "    <path d=\"M 165.717168 185.398125 \n",
       "L 165.717168 73.728941 \n",
       "\" clip-path=\"url(#p1a3a22fac7)\" style=\"fill: none; stroke: #2ca02c; stroke-width: 2; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_6\">\n",
       "    <path d=\"M 189.601526 185.398125 \n",
       "L 189.601526 46.730631 \n",
       "\" clip-path=\"url(#p1a3a22fac7)\" style=\"fill: none; stroke: #2ca02c; stroke-width: 2; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_7\">\n",
       "    <path d=\"M 190.020549 185.398125 \n",
       "L 190.020549 46.380814 \n",
       "\" clip-path=\"url(#p1a3a22fac7)\" style=\"fill: none; stroke: #d62728; stroke-width: 2; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_8\">\n",
       "    <path d=\"M 210.971738 185.398125 \n",
       "L 210.971738 37.147291 \n",
       "\" clip-path=\"url(#p1a3a22fac7)\" style=\"fill: none; stroke: #d62728; stroke-width: 2; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_9\">\n",
       "    <path d=\"M 211.390762 185.398125 \n",
       "L 211.390762 37.14358 \n",
       "\" clip-path=\"url(#p1a3a22fac7)\" style=\"fill: none; stroke: #9467bd; stroke-width: 2; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_10\">\n",
       "    <path d=\"M 232.760974 185.398125 \n",
       "L 232.760974 46.380814 \n",
       "\" clip-path=\"url(#p1a3a22fac7)\" style=\"fill: none; stroke: #9467bd; stroke-width: 2; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_11\">\n",
       "    <path d=\"M 233.179997 185.398125 \n",
       "L 233.179997 46.730639 \n",
       "\" clip-path=\"url(#p1a3a22fac7)\" style=\"fill: none; stroke: #8c564b; stroke-width: 2; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_12\">\n",
       "    <path d=\"M 257.06435 185.398125 \n",
       "L 257.06435 73.728932 \n",
       "\" clip-path=\"url(#p1a3a22fac7)\" style=\"fill: none; stroke: #8c564b; stroke-width: 2; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_13\">\n",
       "    <path d=\"M 257.483373 185.398125 \n",
       "L 257.483373 74.284369 \n",
       "\" clip-path=\"url(#p1a3a22fac7)\" style=\"fill: none; stroke: #e377c2; stroke-width: 2; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_14\">\n",
       "    <path d=\"M 292.681372 185.398125 \n",
       "L 292.681372 120.248859 \n",
       "\" clip-path=\"url(#p1a3a22fac7)\" style=\"fill: none; stroke: #e377c2; stroke-width: 2; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_15\">\n",
       "    <path d=\"M 293.100396 185.398125 \n",
       "L 293.100396 120.735524 \n",
       "\" clip-path=\"url(#p1a3a22fac7)\" style=\"fill: none; stroke: #7f7f7f; stroke-width: 2; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_16\">\n",
       "    <path d=\"M 378.58125 185.398125 \n",
       "L 378.58125 174.822374 \n",
       "\" clip-path=\"url(#p1a3a22fac7)\" style=\"fill: none; stroke: #7f7f7f; stroke-width: 2; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_17\">\n",
       "    <path d=\"M 43.78125 174.923817 \n",
       "L 50.066601 173.299255 \n",
       "L 55.932938 171.567858 \n",
       "L 61.799275 169.603152 \n",
       "L 67.246579 167.546362 \n",
       "L 72.693893 165.242277 \n",
       "L 77.722174 162.875254 \n",
       "L 82.750464 160.257791 \n",
       "L 87.359721 157.621835 \n",
       "L 91.968979 154.744266 \n",
       "L 96.578246 151.61091 \n",
       "L 101.187503 148.208619 \n",
       "L 105.79677 144.525853 \n",
       "L 110.406027 140.553293 \n",
       "L 115.015294 136.284621 \n",
       "L 119.624552 131.71738 \n",
       "L 124.233819 126.853868 \n",
       "L 129.262099 121.219946 \n",
       "L 134.290385 115.262906 \n",
       "L 140.156717 107.946545 \n",
       "L 146.861096 99.19075 \n",
       "L 156.079621 86.735363 \n",
       "L 166.974238 72.07159 \n",
       "L 172.42155 65.08758 \n",
       "L 177.030812 59.516835 \n",
       "L 181.221048 54.811482 \n",
       "L 184.992264 50.933063 \n",
       "L 188.344453 47.813369 \n",
       "L 191.277621 45.365508 \n",
       "L 194.210787 43.203496 \n",
       "L 197.143953 41.346905 \n",
       "L 199.658096 40.011809 \n",
       "L 202.172239 38.923088 \n",
       "L 204.686381 38.088378 \n",
       "L 207.200524 37.513606 \n",
       "L 209.714667 37.202882 \n",
       "L 212.228809 37.158407 \n",
       "L 214.742952 37.380535 \n",
       "L 217.257095 37.867664 \n",
       "L 219.771237 38.616306 \n",
       "L 222.28538 39.621123 \n",
       "L 224.799522 40.875045 \n",
       "L 227.313665 42.36935 \n",
       "L 230.246833 44.402745 \n",
       "L 233.179997 46.730639 \n",
       "L 236.113164 49.332223 \n",
       "L 239.465353 52.611436 \n",
       "L 243.236571 56.647457 \n",
       "L 247.426807 61.49964 \n",
       "L 252.036067 67.197014 \n",
       "L 257.902402 74.841211 \n",
       "L 266.701898 86.735355 \n",
       "L 278.015544 101.96463 \n",
       "L 284.719923 110.60121 \n",
       "L 290.586255 117.782565 \n",
       "L 295.614541 123.608062 \n",
       "L 300.642821 129.100907 \n",
       "L 305.671112 134.245601 \n",
       "L 310.280369 138.64993 \n",
       "L 314.889636 142.756515 \n",
       "L 319.498894 146.570015 \n",
       "L 324.108161 150.098491 \n",
       "L 328.717418 153.352536 \n",
       "L 333.326685 156.344666 \n",
       "L 337.935942 159.088644 \n",
       "L 342.964223 161.816196 \n",
       "L 347.992513 164.285203 \n",
       "L 353.020794 166.515089 \n",
       "L 358.468108 168.683107 \n",
       "L 363.915412 170.616309 \n",
       "L 369.781749 172.461109 \n",
       "L 376.06711 174.19359 \n",
       "L 378.58125 174.822374 \n",
       "L 378.58125 174.822374 \n",
       "\" clip-path=\"url(#p1a3a22fac7)\" style=\"fill: none; stroke: #000000; stroke-width: 2; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 43.78125 185.398125 \n",
       "L 43.78125 22.318125 \n",
       "\" style=\"fill: none; stroke: #262626; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 378.58125 185.398125 \n",
       "L 378.58125 22.318125 \n",
       "\" style=\"fill: none; stroke: #262626; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 43.78125 185.398125 \n",
       "L 378.58125 185.398125 \n",
       "\" style=\"fill: none; stroke: #262626; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 43.78125 22.318125 \n",
       "L 378.58125 22.318125 \n",
       "\" style=\"fill: none; stroke: #262626; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_17\">\n",
       "    <!-- Dequantization distribution for 8 discrete values -->\n",
       "    <g style=\"fill: #262626\" transform=\"translate(66.164062 16.318125)scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-44\" d=\"M 1259 4147 \n",
       "L 1259 519 \n",
       "L 2022 519 \n",
       "Q 2988 519 3436 956 \n",
       "Q 3884 1394 3884 2338 \n",
       "Q 3884 3275 3436 3711 \n",
       "Q 2988 4147 2022 4147 \n",
       "L 1259 4147 \n",
       "z\n",
       "M 628 4666 \n",
       "L 1925 4666 \n",
       "Q 3281 4666 3915 4102 \n",
       "Q 4550 3538 4550 2338 \n",
       "Q 4550 1131 3912 565 \n",
       "Q 3275 0 1925 0 \n",
       "L 628 0 \n",
       "L 628 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-71\" d=\"M 947 1747 \n",
       "Q 947 1113 1208 752 \n",
       "Q 1469 391 1925 391 \n",
       "Q 2381 391 2643 752 \n",
       "Q 2906 1113 2906 1747 \n",
       "Q 2906 2381 2643 2742 \n",
       "Q 2381 3103 1925 3103 \n",
       "Q 1469 3103 1208 2742 \n",
       "Q 947 2381 947 1747 \n",
       "z\n",
       "M 2906 525 \n",
       "Q 2725 213 2448 61 \n",
       "Q 2172 -91 1784 -91 \n",
       "Q 1150 -91 751 415 \n",
       "Q 353 922 353 1747 \n",
       "Q 353 2572 751 3078 \n",
       "Q 1150 3584 1784 3584 \n",
       "Q 2172 3584 2448 3432 \n",
       "Q 2725 3281 2906 2969 \n",
       "L 2906 3500 \n",
       "L 3481 3500 \n",
       "L 3481 -1331 \n",
       "L 2906 -1331 \n",
       "L 2906 525 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-75\" d=\"M 544 1381 \n",
       "L 544 3500 \n",
       "L 1119 3500 \n",
       "L 1119 1403 \n",
       "Q 1119 906 1312 657 \n",
       "Q 1506 409 1894 409 \n",
       "Q 2359 409 2629 706 \n",
       "Q 2900 1003 2900 1516 \n",
       "L 2900 3500 \n",
       "L 3475 3500 \n",
       "L 3475 0 \n",
       "L 2900 0 \n",
       "L 2900 538 \n",
       "Q 2691 219 2414 64 \n",
       "Q 2138 -91 1772 -91 \n",
       "Q 1169 -91 856 284 \n",
       "Q 544 659 544 1381 \n",
       "z\n",
       "M 1991 3584 \n",
       "L 1991 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \n",
       "L 2906 4863 \n",
       "L 3481 4863 \n",
       "L 3481 0 \n",
       "L 2906 0 \n",
       "L 2906 525 \n",
       "Q 2725 213 2448 61 \n",
       "Q 2172 -91 1784 -91 \n",
       "Q 1150 -91 751 415 \n",
       "Q 353 922 353 1747 \n",
       "Q 353 2572 751 3078 \n",
       "Q 1150 3584 1784 3584 \n",
       "Q 2172 3584 2448 3432 \n",
       "Q 2725 3281 2906 2969 \n",
       "z\n",
       "M 947 1747 \n",
       "Q 947 1113 1208 752 \n",
       "Q 1469 391 1925 391 \n",
       "Q 2381 391 2643 752 \n",
       "Q 2906 1113 2906 1747 \n",
       "Q 2906 2381 2643 2742 \n",
       "Q 2381 3103 1925 3103 \n",
       "Q 1469 3103 1208 2742 \n",
       "Q 947 2381 947 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
       "L 2834 2853 \n",
       "Q 2591 2978 2328 3040 \n",
       "Q 2066 3103 1784 3103 \n",
       "Q 1356 3103 1142 2972 \n",
       "Q 928 2841 928 2578 \n",
       "Q 928 2378 1081 2264 \n",
       "Q 1234 2150 1697 2047 \n",
       "L 1894 2003 \n",
       "Q 2506 1872 2764 1633 \n",
       "Q 3022 1394 3022 966 \n",
       "Q 3022 478 2636 193 \n",
       "Q 2250 -91 1575 -91 \n",
       "Q 1294 -91 989 -36 \n",
       "Q 684 19 347 128 \n",
       "L 347 722 \n",
       "Q 666 556 975 473 \n",
       "Q 1284 391 1588 391 \n",
       "Q 1994 391 2212 530 \n",
       "Q 2431 669 2431 922 \n",
       "Q 2431 1156 2273 1281 \n",
       "Q 2116 1406 1581 1522 \n",
       "L 1381 1569 \n",
       "Q 847 1681 609 1914 \n",
       "Q 372 2147 372 2553 \n",
       "Q 372 3047 722 3315 \n",
       "Q 1072 3584 1716 3584 \n",
       "Q 2034 3584 2315 3537 \n",
       "Q 2597 3491 2834 3397 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-66\" d=\"M 2375 4863 \n",
       "L 2375 4384 \n",
       "L 1825 4384 \n",
       "Q 1516 4384 1395 4259 \n",
       "Q 1275 4134 1275 3809 \n",
       "L 1275 3500 \n",
       "L 2222 3500 \n",
       "L 2222 3053 \n",
       "L 1275 3053 \n",
       "L 1275 0 \n",
       "L 697 0 \n",
       "L 697 3053 \n",
       "L 147 3053 \n",
       "L 147 3500 \n",
       "L 697 3500 \n",
       "L 697 3744 \n",
       "Q 697 4328 969 4595 \n",
       "Q 1241 4863 1831 4863 \n",
       "L 2375 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \n",
       "Q 1584 2216 1326 1975 \n",
       "Q 1069 1734 1069 1313 \n",
       "Q 1069 891 1326 650 \n",
       "Q 1584 409 2034 409 \n",
       "Q 2484 409 2743 651 \n",
       "Q 3003 894 3003 1313 \n",
       "Q 3003 1734 2745 1975 \n",
       "Q 2488 2216 2034 2216 \n",
       "z\n",
       "M 1403 2484 \n",
       "Q 997 2584 770 2862 \n",
       "Q 544 3141 544 3541 \n",
       "Q 544 4100 942 4425 \n",
       "Q 1341 4750 2034 4750 \n",
       "Q 2731 4750 3128 4425 \n",
       "Q 3525 4100 3525 3541 \n",
       "Q 3525 3141 3298 2862 \n",
       "Q 3072 2584 2669 2484 \n",
       "Q 3125 2378 3379 2068 \n",
       "Q 3634 1759 3634 1313 \n",
       "Q 3634 634 3220 271 \n",
       "Q 2806 -91 2034 -91 \n",
       "Q 1263 -91 848 271 \n",
       "Q 434 634 434 1313 \n",
       "Q 434 1759 690 2068 \n",
       "Q 947 2378 1403 2484 \n",
       "z\n",
       "M 1172 3481 \n",
       "Q 1172 3119 1398 2916 \n",
       "Q 1625 2713 2034 2713 \n",
       "Q 2441 2713 2670 2916 \n",
       "Q 2900 3119 2900 3481 \n",
       "Q 2900 3844 2670 4047 \n",
       "Q 2441 4250 2034 4250 \n",
       "Q 1625 4250 1398 4047 \n",
       "Q 1172 3844 1172 3481 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \n",
       "L 3122 2828 \n",
       "Q 2878 2963 2633 3030 \n",
       "Q 2388 3097 2138 3097 \n",
       "Q 1578 3097 1268 2742 \n",
       "Q 959 2388 959 1747 \n",
       "Q 959 1106 1268 751 \n",
       "Q 1578 397 2138 397 \n",
       "Q 2388 397 2633 464 \n",
       "Q 2878 531 3122 666 \n",
       "L 3122 134 \n",
       "Q 2881 22 2623 -34 \n",
       "Q 2366 -91 2075 -91 \n",
       "Q 1284 -91 818 406 \n",
       "Q 353 903 353 1747 \n",
       "Q 353 2603 823 3093 \n",
       "Q 1294 3584 2113 3584 \n",
       "Q 2378 3584 2631 3529 \n",
       "Q 2884 3475 3122 3366 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-76\" d=\"M 191 3500 \n",
       "L 800 3500 \n",
       "L 1894 563 \n",
       "L 2988 3500 \n",
       "L 3597 3500 \n",
       "L 2284 0 \n",
       "L 1503 0 \n",
       "L 191 3500 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-44\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"77.001953\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-71\" x=\"138.525391\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-75\" x=\"202.001953\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"265.380859\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6e\" x=\"326.660156\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-74\" x=\"390.039062\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" x=\"429.248047\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-7a\" x=\"457.03125\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"509.521484\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-74\" x=\"570.800781\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" x=\"610.009766\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"637.792969\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6e\" x=\"698.974609\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"762.353516\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-64\" x=\"794.140625\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" x=\"857.617188\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-73\" x=\"885.400391\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-74\" x=\"937.5\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"976.708984\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" x=\"1017.822266\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-62\" x=\"1045.605469\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-75\" x=\"1109.082031\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-74\" x=\"1172.460938\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" x=\"1211.669922\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"1239.453125\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6e\" x=\"1300.634766\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"1364.013672\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-66\" x=\"1395.800781\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"1431.005859\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"1492.1875\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"1533.300781\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-38\" x=\"1565.087891\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"1628.710938\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-64\" x=\"1660.498047\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" x=\"1723.974609\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-73\" x=\"1751.757812\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-63\" x=\"1803.857422\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"1858.837891\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"1897.701172\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-74\" x=\"1959.224609\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"1998.433594\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"2059.957031\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-76\" x=\"2091.744141\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"2150.923828\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"2212.203125\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-75\" x=\"2239.986328\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"2303.365234\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-73\" x=\"2364.888672\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 333.21875 147.743125 \n",
       "L 371.58125 147.743125 \n",
       "Q 373.58125 147.743125 373.58125 145.743125 \n",
       "L 373.58125 29.318125 \n",
       "Q 373.58125 27.318125 371.58125 27.318125 \n",
       "L 333.21875 27.318125 \n",
       "Q 331.21875 27.318125 331.21875 29.318125 \n",
       "L 331.21875 145.743125 \n",
       "Q 331.21875 147.743125 333.21875 147.743125 \n",
       "z\n",
       "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"patch_8\">\n",
       "     <path d=\"M 335.21875 38.916562 \n",
       "L 355.21875 38.916562 \n",
       "L 355.21875 31.916562 \n",
       "L 335.21875 31.916562 \n",
       "z\n",
       "\" style=\"fill: #1f77b4; fill-opacity: 0.5; stroke: #1f77b4; stroke-opacity: 0.5; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"text_18\">\n",
       "     <!-- 0 -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(363.21875 38.916562)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"patch_9\">\n",
       "     <path d=\"M 335.21875 53.594687 \n",
       "L 355.21875 53.594687 \n",
       "L 355.21875 46.594687 \n",
       "L 335.21875 46.594687 \n",
       "z\n",
       "\" style=\"fill: #ff7f0e; fill-opacity: 0.5; stroke: #ff7f0e; stroke-opacity: 0.5; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"text_19\">\n",
       "     <!-- 1 -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(363.21875 53.594687)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"patch_10\">\n",
       "     <path d=\"M 335.21875 68.272812 \n",
       "L 355.21875 68.272812 \n",
       "L 355.21875 61.272812 \n",
       "L 335.21875 61.272812 \n",
       "z\n",
       "\" style=\"fill: #2ca02c; fill-opacity: 0.5; stroke: #2ca02c; stroke-opacity: 0.5; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"text_20\">\n",
       "     <!-- 2 -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(363.21875 68.272812)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"patch_11\">\n",
       "     <path d=\"M 335.21875 82.950937 \n",
       "L 355.21875 82.950937 \n",
       "L 355.21875 75.950937 \n",
       "L 335.21875 75.950937 \n",
       "z\n",
       "\" style=\"fill: #d62728; fill-opacity: 0.5; stroke: #d62728; stroke-opacity: 0.5; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"text_21\">\n",
       "     <!-- 3 -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(363.21875 82.950937)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \n",
       "Q 3050 2419 3304 2112 \n",
       "Q 3559 1806 3559 1356 \n",
       "Q 3559 666 3084 287 \n",
       "Q 2609 -91 1734 -91 \n",
       "Q 1441 -91 1130 -33 \n",
       "Q 819 25 488 141 \n",
       "L 488 750 \n",
       "Q 750 597 1062 519 \n",
       "Q 1375 441 1716 441 \n",
       "Q 2309 441 2620 675 \n",
       "Q 2931 909 2931 1356 \n",
       "Q 2931 1769 2642 2001 \n",
       "Q 2353 2234 1838 2234 \n",
       "L 1294 2234 \n",
       "L 1294 2753 \n",
       "L 1863 2753 \n",
       "Q 2328 2753 2575 2939 \n",
       "Q 2822 3125 2822 3475 \n",
       "Q 2822 3834 2567 4026 \n",
       "Q 2313 4219 1838 4219 \n",
       "Q 1578 4219 1281 4162 \n",
       "Q 984 4106 628 3988 \n",
       "L 628 4550 \n",
       "Q 988 4650 1302 4700 \n",
       "Q 1616 4750 1894 4750 \n",
       "Q 2613 4750 3031 4423 \n",
       "Q 3450 4097 3450 3541 \n",
       "Q 3450 3153 3228 2886 \n",
       "Q 3006 2619 2597 2516 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-33\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"patch_12\">\n",
       "     <path d=\"M 335.21875 97.629062 \n",
       "L 355.21875 97.629062 \n",
       "L 355.21875 90.629062 \n",
       "L 335.21875 90.629062 \n",
       "z\n",
       "\" style=\"fill: #9467bd; fill-opacity: 0.5; stroke: #9467bd; stroke-opacity: 0.5; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"text_22\">\n",
       "     <!-- 4 -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(363.21875 97.629062)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"patch_13\">\n",
       "     <path d=\"M 335.21875 112.307187 \n",
       "L 355.21875 112.307187 \n",
       "L 355.21875 105.307187 \n",
       "L 335.21875 105.307187 \n",
       "z\n",
       "\" style=\"fill: #8c564b; fill-opacity: 0.5; stroke: #8c564b; stroke-opacity: 0.5; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"text_23\">\n",
       "     <!-- 5 -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(363.21875 112.307187)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"patch_14\">\n",
       "     <path d=\"M 335.21875 126.985312 \n",
       "L 355.21875 126.985312 \n",
       "L 355.21875 119.985312 \n",
       "L 335.21875 119.985312 \n",
       "z\n",
       "\" style=\"fill: #e377c2; fill-opacity: 0.5; stroke: #e377c2; stroke-opacity: 0.5; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"text_24\">\n",
       "     <!-- 6 -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(363.21875 126.985312)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \n",
       "Q 1688 2584 1439 2293 \n",
       "Q 1191 2003 1191 1497 \n",
       "Q 1191 994 1439 701 \n",
       "Q 1688 409 2113 409 \n",
       "Q 2538 409 2786 701 \n",
       "Q 3034 994 3034 1497 \n",
       "Q 3034 2003 2786 2293 \n",
       "Q 2538 2584 2113 2584 \n",
       "z\n",
       "M 3366 4563 \n",
       "L 3366 3988 \n",
       "Q 3128 4100 2886 4159 \n",
       "Q 2644 4219 2406 4219 \n",
       "Q 1781 4219 1451 3797 \n",
       "Q 1122 3375 1075 2522 \n",
       "Q 1259 2794 1537 2939 \n",
       "Q 1816 3084 2150 3084 \n",
       "Q 2853 3084 3261 2657 \n",
       "Q 3669 2231 3669 1497 \n",
       "Q 3669 778 3244 343 \n",
       "Q 2819 -91 2113 -91 \n",
       "Q 1303 -91 875 529 \n",
       "Q 447 1150 447 2328 \n",
       "Q 447 3434 972 4092 \n",
       "Q 1497 4750 2381 4750 \n",
       "Q 2619 4750 2861 4703 \n",
       "Q 3103 4656 3366 4563 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-36\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"patch_15\">\n",
       "     <path d=\"M 335.21875 141.663437 \n",
       "L 355.21875 141.663437 \n",
       "L 355.21875 134.663437 \n",
       "L 335.21875 134.663437 \n",
       "z\n",
       "\" style=\"fill: #7f7f7f; fill-opacity: 0.5; stroke: #7f7f7f; stroke-opacity: 0.5; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"text_25\">\n",
       "     <!-- 7 -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(363.21875 141.663437)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-37\" d=\"M 525 4666 \n",
       "L 3525 4666 \n",
       "L 3525 4397 \n",
       "L 1831 0 \n",
       "L 1172 0 \n",
       "L 2766 4134 \n",
       "L 525 4134 \n",
       "L 525 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-37\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p1a3a22fac7\">\n",
       "   <rect x=\"43.78125\" y=\"22.318125\" width=\"334.8\" height=\"163.08\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 432x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_dequantization(quants, prior=None):\n",
    "    \"\"\"\n",
    "    Function for visualizing the dequantization values of discrete values in continuous space\n",
    "    \"\"\"\n",
    "    # Prior over discrete values. If not given, a uniform is assumed\n",
    "    if prior is None:\n",
    "        prior = np.ones(quants, dtype=np.float32) / quants\n",
    "    prior = prior / prior.sum() * quants # In the following, we assume 1 for each value means uniform distribution\n",
    "\n",
    "    inp = torch.arange(-4, 4, 0.01).view(-1, 1, 1, 1) # Possible continuous values we want to consider\n",
    "    ldj = torch.zeros(inp.shape[0])\n",
    "    dequant_module = Dequantization(quants=quants)\n",
    "    # Invert dequantization on continuous values to find corresponding discrete value\n",
    "    out, ldj = dequant_module.forward(inp, ldj, reverse=True)\n",
    "    inp, out, prob = inp.squeeze().numpy(), out.squeeze().numpy(), ldj.exp().numpy()\n",
    "    prob = prob * prior[out] # Probability scaled by categorical prior\n",
    "    \n",
    "    # Plot volumes and continuous distribution\n",
    "    sns.set_style(\"white\")\n",
    "    fig = plt.figure(figsize=(6,3))\n",
    "    x_ticks = []\n",
    "    for v in np.unique(out):\n",
    "        indices = np.where(out==v)\n",
    "        color = to_rgb(f\"C{v}\")\n",
    "        plt.fill_between(inp[indices], prob[indices], np.zeros(indices[0].shape[0]), color=color+(0.5,), label=str(v))\n",
    "        plt.plot([inp[indices[0][0]]]*2,  [0, prob[indices[0][0]]],  color=color)\n",
    "        plt.plot([inp[indices[0][-1]]]*2, [0, prob[indices[0][-1]]], color=color)\n",
    "        x_ticks.append(inp[indices[0][0]])\n",
    "    x_ticks.append(inp.max())\n",
    "    plt.xticks(x_ticks, [f\"{x:.1f}\" for x in x_ticks])\n",
    "    plt.plot(inp,prob, color=(0.0,0.0,0.0))\n",
    "    # Set final plot properties\n",
    "    plt.ylim(0, prob.max()*1.1)\n",
    "    plt.xlim(inp.min(), inp.max())\n",
    "    plt.xlabel(\"z\")\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.title(f\"Dequantization distribution for {quants} discrete values\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "visualize_dequantization(quants=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualized distribution show the sub-volumes that are assigned to the different discrete values. The value $0$ has its volume between $[-\\infty, -1.9)$, the value $1$ is represented by the interval $[-1.9, -1.1)$, etc. The volume for each discrete value has the same probability mass. That's why the volumes close to the center (e.g. 3 and 4) have a smaller area on the z-axis as others ($z$ is being used to denote the output of the whole dequantization flow).\n",
    "\n",
    "Effectively, the consecutive normalizing flow models discrete images by the following objective:\n",
    "\n",
    "$$\\log p(x) = \\log \\mathbb{E}_{u\\sim q(u|x)}\\left[\\frac{p(x+u)}{q(u|x)} \\right] \\geq \\mathbb{E}_{u}\\left[\\log \\frac{p(x+u)}{q(u|x)} \\right]$$\n",
    "\n",
    "Although normalizing flows are exact in likelihood, we have a lower bound. Specifically, this is an example of the Jensen inequality because we need to move the log into the expectation so we can use Monte-carlo estimates. In general, this bound is considerably smaller than the ELBO in variational autoencoders. Actually, we can reduce the bound ourselves by estimating the expectation not by one, but by $M$ samples. In other words, we can apply importance sampling which leads to the following inequality:\n",
    "\n",
    "$$\\log p(x) = \\log \\mathbb{E}_{u\\sim q(u|x)}\\left[\\frac{p(x+u)}{q(u|x)} \\right] \\geq \\mathbb{E}_{u}\\left[\\log \\frac{1}{M} \\sum_{m=1}^{M} \\frac{p(x+u_m)}{q(u_m|x)} \\right] \\geq \\mathbb{E}_{u}\\left[\\log \\frac{p(x+u)}{q(u|x)} \\right]$$\n",
    "\n",
    "The importance sampling $\\frac{1}{M} \\sum_{m=1}^{M} \\frac{p(x+u_m)}{q(u_m|x)}$ becomes $\\mathbb{E}_{u\\sim q(u|x)}\\left[\\frac{p(x+u)}{q(u|x)} \\right]$ if $M\\to \\infty$, so that the more samples we use, the tighter the bound is. During testing, we can make use of this property and have it implemented in `test_step` in `ImageFlow`. In theory, we could also use this tighter bound during training. However, related work has shown that this does not necessarily lead to an improvement given the additional computational cost, and it is more efficient to stick with a single estimate [5]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Dequantization\n",
    "\n",
    "Dequantization uses a uniform distribution for the noise $u$ which effectively leads to images being represented as hypercubes (cube in high dimensions) with sharp borders. However, modeling such sharp borders is not easy for a flow as it uses smooth transformations to convert it into a Gaussian distribution. \n",
    "\n",
    "Another way of looking at it is if we change the prior distribution in the previous visualization. Imagine we have independent Gaussian noise on pixels which is commonly the case for any real-world taken picture. Therefore, the flow would have to model a distribution as above, but with the individual volumes scaled as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/pdf": "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\n",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"384.192188pt\" height=\"222.954375pt\" viewBox=\"0 0 384.192188 222.954375\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2022-06-10T09:54:07.982784</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 222.954375 \n",
       "L 384.192188 222.954375 \n",
       "L 384.192188 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 34.240625 185.398125 \n",
       "L 369.040625 185.398125 \n",
       "L 369.040625 22.318125 \n",
       "L 34.240625 22.318125 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"text_1\">\n",
       "      <!-- -4.0 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(24.485156 199.996562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-2d\" d=\"M 313 2009 \n",
       "L 1997 2009 \n",
       "L 1997 1497 \n",
       "L 313 1497 \n",
       "L 313 2009 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \n",
       "L 1344 794 \n",
       "L 1344 0 \n",
       "L 684 0 \n",
       "L 684 794 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2d\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-34\" x=\"36.083984\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"131.494141\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"text_2\">\n",
       "      <!-- -1.9 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(110.804052 199.996562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-39\" d=\"M 703 97 \n",
       "L 703 672 \n",
       "Q 941 559 1184 500 \n",
       "Q 1428 441 1663 441 \n",
       "Q 2288 441 2617 861 \n",
       "Q 2947 1281 2994 2138 \n",
       "Q 2813 1869 2534 1725 \n",
       "Q 2256 1581 1919 1581 \n",
       "Q 1219 1581 811 2004 \n",
       "Q 403 2428 403 3163 \n",
       "Q 403 3881 828 4315 \n",
       "Q 1253 4750 1959 4750 \n",
       "Q 2769 4750 3195 4129 \n",
       "Q 3622 3509 3622 2328 \n",
       "Q 3622 1225 3098 567 \n",
       "Q 2575 -91 1691 -91 \n",
       "Q 1453 -91 1209 -44 \n",
       "Q 966 3 703 97 \n",
       "z\n",
       "M 1959 2075 \n",
       "Q 2384 2075 2632 2365 \n",
       "Q 2881 2656 2881 3163 \n",
       "Q 2881 3666 2632 3958 \n",
       "Q 2384 4250 1959 4250 \n",
       "Q 1534 4250 1286 3958 \n",
       "Q 1038 3666 1038 3163 \n",
       "Q 1038 2656 1286 2365 \n",
       "Q 1534 2075 1959 2075 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2d\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-31\" x=\"36.083984\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-39\" x=\"131.494141\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"text_3\">\n",
       "      <!-- -1.1 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(146.421075 199.996562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-2d\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-31\" x=\"36.083984\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-31\" x=\"131.494141\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"text_4\">\n",
       "      <!-- -0.5 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(170.724456 199.996562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2d\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"36.083984\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"131.494141\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 0.0 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(193.898574 199.996562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 0.5 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(215.68781 199.996562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_7\">\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 1.1 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(239.991186 199.996562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-31\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_8\">\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 1.9 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(275.608208 199.996562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-39\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_9\">\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 4.0 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(361.089063 199.996562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_10\">\n",
       "     <!-- z -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(199.016406 213.674688)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-7a\" d=\"M 353 3500 \n",
       "L 3084 3500 \n",
       "L 3084 2975 \n",
       "L 922 459 \n",
       "L 3084 459 \n",
       "L 3084 0 \n",
       "L 275 0 \n",
       "L 275 525 \n",
       "L 2438 3041 \n",
       "L 353 3041 \n",
       "L 353 3500 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-7a\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 0 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(20.878125 189.197344)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 1 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(20.878125 164.431029)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 2 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(20.878125 139.664714)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 3 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(20.878125 114.898399)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \n",
       "Q 3050 2419 3304 2112 \n",
       "Q 3559 1806 3559 1356 \n",
       "Q 3559 666 3084 287 \n",
       "Q 2609 -91 1734 -91 \n",
       "Q 1441 -91 1130 -33 \n",
       "Q 819 25 488 141 \n",
       "L 488 750 \n",
       "Q 750 597 1062 519 \n",
       "Q 1375 441 1716 441 \n",
       "Q 2309 441 2620 675 \n",
       "Q 2931 909 2931 1356 \n",
       "Q 2931 1769 2642 2001 \n",
       "Q 2353 2234 1838 2234 \n",
       "L 1294 2234 \n",
       "L 1294 2753 \n",
       "L 1863 2753 \n",
       "Q 2328 2753 2575 2939 \n",
       "Q 2822 3125 2822 3475 \n",
       "Q 2822 3834 2567 4026 \n",
       "Q 2313 4219 1838 4219 \n",
       "Q 1578 4219 1281 4162 \n",
       "Q 984 4106 628 3988 \n",
       "L 628 4550 \n",
       "Q 988 4650 1302 4700 \n",
       "Q 1616 4750 1894 4750 \n",
       "Q 2613 4750 3031 4423 \n",
       "Q 3450 4097 3450 3541 \n",
       "Q 3450 3153 3228 2886 \n",
       "Q 3006 2619 2597 2516 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-33\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"text_15\">\n",
       "      <!-- 4 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(20.878125 90.132084)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"text_16\">\n",
       "      <!-- 5 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(20.878125 65.365769)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"text_17\">\n",
       "      <!-- 6 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(20.878125 40.599454)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \n",
       "Q 1688 2584 1439 2293 \n",
       "Q 1191 2003 1191 1497 \n",
       "Q 1191 994 1439 701 \n",
       "Q 1688 409 2113 409 \n",
       "Q 2538 409 2786 701 \n",
       "Q 3034 994 3034 1497 \n",
       "Q 3034 2003 2786 2293 \n",
       "Q 2538 2584 2113 2584 \n",
       "z\n",
       "M 3366 4563 \n",
       "L 3366 3988 \n",
       "Q 3128 4100 2886 4159 \n",
       "Q 2644 4219 2406 4219 \n",
       "Q 1781 4219 1451 3797 \n",
       "Q 1122 3375 1075 2522 \n",
       "Q 1259 2794 1537 2939 \n",
       "Q 1816 3084 2150 3084 \n",
       "Q 2853 3084 3261 2657 \n",
       "Q 3669 2231 3669 1497 \n",
       "Q 3669 778 3244 343 \n",
       "Q 2819 -91 2113 -91 \n",
       "Q 1303 -91 875 529 \n",
       "Q 447 1150 447 2328 \n",
       "Q 447 3434 972 4092 \n",
       "Q 1497 4750 2381 4750 \n",
       "Q 2619 4750 2861 4703 \n",
       "Q 3103 4656 3366 4563 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-36\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_18\">\n",
       "     <!-- Probability -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(14.798437 130.287031)rotate(-90)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-50\" d=\"M 1259 4147 \n",
       "L 1259 2394 \n",
       "L 2053 2394 \n",
       "Q 2494 2394 2734 2622 \n",
       "Q 2975 2850 2975 3272 \n",
       "Q 2975 3691 2734 3919 \n",
       "Q 2494 4147 2053 4147 \n",
       "L 1259 4147 \n",
       "z\n",
       "M 628 4666 \n",
       "L 2053 4666 \n",
       "Q 2838 4666 3239 4311 \n",
       "Q 3641 3956 3641 3272 \n",
       "Q 3641 2581 3239 2228 \n",
       "Q 2838 1875 2053 1875 \n",
       "L 1259 1875 \n",
       "L 1259 0 \n",
       "L 628 0 \n",
       "L 628 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
       "Q 2534 3019 2420 3045 \n",
       "Q 2306 3072 2169 3072 \n",
       "Q 1681 3072 1420 2755 \n",
       "Q 1159 2438 1159 1844 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1341 3275 1631 3429 \n",
       "Q 1922 3584 2338 3584 \n",
       "Q 2397 3584 2469 3576 \n",
       "Q 2541 3569 2628 3553 \n",
       "L 2631 2963 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-62\" d=\"M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "M 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2969 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \n",
       "L 1178 3500 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 3500 \n",
       "z\n",
       "M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 4134 \n",
       "L 603 4134 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \n",
       "L 1172 3500 \n",
       "L 2356 3500 \n",
       "L 2356 3053 \n",
       "L 1172 3053 \n",
       "L 1172 1153 \n",
       "Q 1172 725 1289 603 \n",
       "Q 1406 481 1766 481 \n",
       "L 2356 481 \n",
       "L 2356 0 \n",
       "L 1766 0 \n",
       "Q 1100 0 847 248 \n",
       "Q 594 497 594 1153 \n",
       "L 594 3053 \n",
       "L 172 3053 \n",
       "L 172 3500 \n",
       "L 594 3500 \n",
       "L 594 4494 \n",
       "L 1172 4494 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-79\" d=\"M 2059 -325 \n",
       "Q 1816 -950 1584 -1140 \n",
       "Q 1353 -1331 966 -1331 \n",
       "L 506 -1331 \n",
       "L 506 -850 \n",
       "L 844 -850 \n",
       "Q 1081 -850 1212 -737 \n",
       "Q 1344 -625 1503 -206 \n",
       "L 1606 56 \n",
       "L 191 3500 \n",
       "L 800 3500 \n",
       "L 1894 763 \n",
       "L 2988 3500 \n",
       "L 3597 3500 \n",
       "L 2059 -325 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"58.552734\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"97.416016\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-62\" x=\"158.597656\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"222.074219\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-62\" x=\"283.353516\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"346.830078\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" x=\"374.613281\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"402.396484\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" x=\"430.179688\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-79\" x=\"469.388672\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"PolyCollection_1\">\n",
       "    <defs>\n",
       "     <path id=\"mf504fdd74f\" d=\"M 34.240625 -37.55625 \n",
       "L 34.240625 -39.655963 \n",
       "L 34.659648 -39.676298 \n",
       "L 35.078672 -39.696824 \n",
       "L 35.497695 -39.717541 \n",
       "L 35.916719 -39.738449 \n",
       "L 36.335742 -39.759551 \n",
       "L 36.754765 -39.780851 \n",
       "L 37.173789 -39.802346 \n",
       "L 37.592812 -39.824042 \n",
       "L 38.011835 -39.845938 \n",
       "L 38.430859 -39.868037 \n",
       "L 38.849882 -39.89034 \n",
       "L 39.268906 -39.912848 \n",
       "L 39.687929 -39.935565 \n",
       "L 40.106952 -39.958491 \n",
       "L 40.525976 -39.981628 \n",
       "L 40.945009 -40.004977 \n",
       "L 41.364032 -40.028543 \n",
       "L 41.783056 -40.052323 \n",
       "L 42.202079 -40.076322 \n",
       "L 42.621103 -40.10054 \n",
       "L 43.040126 -40.124981 \n",
       "L 43.459149 -40.149646 \n",
       "L 43.878173 -40.174535 \n",
       "L 44.297196 -40.199653 \n",
       "L 44.716219 -40.224999 \n",
       "L 45.135243 -40.250575 \n",
       "L 45.554266 -40.276385 \n",
       "L 45.97329 -40.302428 \n",
       "L 46.392313 -40.328709 \n",
       "L 46.811336 -40.355229 \n",
       "L 47.23036 -40.381988 \n",
       "L 47.649383 -40.40899 \n",
       "L 48.068407 -40.436237 \n",
       "L 48.48743 -40.463728 \n",
       "L 48.906453 -40.491469 \n",
       "L 49.325477 -40.519459 \n",
       "L 49.7445 -40.547702 \n",
       "L 50.163523 -40.576198 \n",
       "L 50.582547 -40.604951 \n",
       "L 51.00158 -40.633962 \n",
       "L 51.420604 -40.663232 \n",
       "L 51.839627 -40.692764 \n",
       "L 52.25865 -40.722561 \n",
       "L 52.677674 -40.752622 \n",
       "L 53.096697 -40.782953 \n",
       "L 53.51572 -40.813553 \n",
       "L 53.934744 -40.844426 \n",
       "L 54.353767 -40.875573 \n",
       "L 54.772791 -40.906996 \n",
       "L 55.191814 -40.938698 \n",
       "L 55.610837 -40.970679 \n",
       "L 56.029861 -41.002945 \n",
       "L 56.448884 -41.035493 \n",
       "L 56.867907 -41.068329 \n",
       "L 57.286931 -41.101455 \n",
       "L 57.705954 -41.134871 \n",
       "L 58.124978 -41.168581 \n",
       "L 58.544001 -41.202585 \n",
       "L 58.963024 -41.236887 \n",
       "L 59.382048 -41.27149 \n",
       "L 59.801071 -41.306394 \n",
       "L 60.220095 -41.341603 \n",
       "L 60.639118 -41.377116 \n",
       "L 61.058151 -41.41294 \n",
       "L 61.477175 -41.449073 \n",
       "L 61.896198 -41.48552 \n",
       "L 62.315221 -41.52228 \n",
       "L 62.734245 -41.559359 \n",
       "L 63.153268 -41.596755 \n",
       "L 63.572292 -41.634474 \n",
       "L 63.991315 -41.672518 \n",
       "L 64.410338 -41.710889 \n",
       "L 64.829362 -41.749585 \n",
       "L 65.248385 -41.788614 \n",
       "L 65.667408 -41.827975 \n",
       "L 66.086432 -41.867671 \n",
       "L 66.505455 -41.907703 \n",
       "L 66.924479 -41.948076 \n",
       "L 67.343502 -41.988791 \n",
       "L 67.762525 -42.029852 \n",
       "L 68.181549 -42.071256 \n",
       "L 68.600572 -42.113009 \n",
       "L 69.019595 -42.155116 \n",
       "L 69.438619 -42.197573 \n",
       "L 69.857642 -42.240387 \n",
       "L 70.276666 -42.283558 \n",
       "L 70.695689 -42.327087 \n",
       "L 71.114722 -42.370982 \n",
       "L 71.533746 -42.415241 \n",
       "L 71.952769 -42.459864 \n",
       "L 72.371793 -42.504859 \n",
       "L 72.790816 -42.550224 \n",
       "L 73.209839 -42.595961 \n",
       "L 73.628863 -42.642074 \n",
       "L 74.047886 -42.688567 \n",
       "L 74.466909 -42.735439 \n",
       "L 74.885933 -42.782693 \n",
       "L 75.304956 -42.830334 \n",
       "L 75.72398 -42.87836 \n",
       "L 76.143003 -42.926775 \n",
       "L 76.562026 -42.975582 \n",
       "L 76.98105 -43.024782 \n",
       "L 77.400073 -43.074379 \n",
       "L 77.819096 -43.124373 \n",
       "L 78.23812 -43.174769 \n",
       "L 78.657143 -43.225567 \n",
       "L 79.076167 -43.27677 \n",
       "L 79.49519 -43.32838 \n",
       "L 79.914213 -43.3804 \n",
       "L 80.333237 -43.43283 \n",
       "L 80.75226 -43.485673 \n",
       "L 81.171283 -43.538931 \n",
       "L 81.590307 -43.592607 \n",
       "L 82.00933 -43.646703 \n",
       "L 82.428354 -43.70122 \n",
       "L 82.847377 -43.756163 \n",
       "L 83.2664 -43.811529 \n",
       "L 83.685424 -43.867325 \n",
       "L 84.104447 -43.923553 \n",
       "L 84.523481 -43.980209 \n",
       "L 84.942504 -44.037303 \n",
       "L 85.361527 -44.09483 \n",
       "L 85.780551 -44.152795 \n",
       "L 86.199574 -44.211201 \n",
       "L 86.618597 -44.27005 \n",
       "L 87.037621 -44.329343 \n",
       "L 87.456644 -44.38908 \n",
       "L 87.875668 -44.449266 \n",
       "L 88.294691 -44.509903 \n",
       "L 88.713714 -44.570988 \n",
       "L 89.132738 -44.632527 \n",
       "L 89.551761 -44.69452 \n",
       "L 89.970784 -44.75697 \n",
       "L 90.389808 -44.81988 \n",
       "L 90.808831 -44.88325 \n",
       "L 91.227855 -44.94708 \n",
       "L 91.646878 -45.011377 \n",
       "L 92.065901 -45.076133 \n",
       "L 92.484925 -45.141361 \n",
       "L 92.903948 -45.207054 \n",
       "L 93.322971 -45.273219 \n",
       "L 93.741995 -45.339852 \n",
       "L 94.161018 -45.40696 \n",
       "L 94.580052 -45.474542 \n",
       "L 94.999075 -45.542602 \n",
       "L 95.418098 -45.611136 \n",
       "L 95.837122 -45.680144 \n",
       "L 96.256145 -45.749636 \n",
       "L 96.675169 -45.819611 \n",
       "L 97.094192 -45.890059 \n",
       "L 97.513215 -45.960998 \n",
       "L 97.932239 -46.032418 \n",
       "L 98.351262 -46.104323 \n",
       "L 98.770285 -46.176714 \n",
       "L 99.189309 -46.24959 \n",
       "L 99.608332 -46.322957 \n",
       "L 100.027356 -46.396813 \n",
       "L 100.446379 -46.471154 \n",
       "L 100.865402 -46.545988 \n",
       "L 101.284426 -46.621316 \n",
       "L 101.703449 -46.697131 \n",
       "L 102.122472 -46.773444 \n",
       "L 102.541496 -46.850243 \n",
       "L 102.960519 -46.92754 \n",
       "L 103.379543 -47.005331 \n",
       "L 103.798566 -47.083613 \n",
       "L 104.217589 -47.162392 \n",
       "L 104.636623 -47.241668 \n",
       "L 105.055646 -47.321437 \n",
       "L 105.474669 -47.401699 \n",
       "L 105.893693 -47.48246 \n",
       "L 106.312716 -47.563717 \n",
       "L 106.73174 -47.645465 \n",
       "L 107.150763 -47.727711 \n",
       "L 107.569786 -47.810448 \n",
       "L 107.98881 -47.893684 \n",
       "L 108.407833 -47.977412 \n",
       "L 108.826857 -48.061638 \n",
       "L 109.24588 -48.146353 \n",
       "L 109.664903 -48.231563 \n",
       "L 110.083927 -48.317263 \n",
       "L 110.50295 -48.403455 \n",
       "L 110.921973 -48.490139 \n",
       "L 111.340997 -48.577316 \n",
       "L 111.76002 -48.664976 \n",
       "L 112.179044 -48.753131 \n",
       "L 112.598067 -48.841769 \n",
       "L 113.01709 -48.930893 \n",
       "L 113.436114 -49.020502 \n",
       "L 113.855137 -49.110591 \n",
       "L 114.27416 -49.201166 \n",
       "L 114.693194 -49.292218 \n",
       "L 115.112217 -49.383748 \n",
       "L 115.531241 -49.475759 \n",
       "L 115.950264 -49.56824 \n",
       "L 116.369287 -49.661195 \n",
       "L 116.788311 -49.754626 \n",
       "L 117.207334 -49.848521 \n",
       "L 117.626357 -49.942883 \n",
       "L 118.045381 -50.037708 \n",
       "L 118.464404 -50.133002 \n",
       "L 118.883428 -50.228745 \n",
       "L 119.302451 -50.324948 \n",
       "L 119.721474 -50.421612 \n",
       "L 120.140498 -50.518718 \n",
       "L 120.140498 -37.55625 \n",
       "L 120.140498 -37.55625 \n",
       "L 119.721474 -37.55625 \n",
       "L 119.302451 -37.55625 \n",
       "L 118.883428 -37.55625 \n",
       "L 118.464404 -37.55625 \n",
       "L 118.045381 -37.55625 \n",
       "L 117.626357 -37.55625 \n",
       "L 117.207334 -37.55625 \n",
       "L 116.788311 -37.55625 \n",
       "L 116.369287 -37.55625 \n",
       "L 115.950264 -37.55625 \n",
       "L 115.531241 -37.55625 \n",
       "L 115.112217 -37.55625 \n",
       "L 114.693194 -37.55625 \n",
       "L 114.27416 -37.55625 \n",
       "L 113.855137 -37.55625 \n",
       "L 113.436114 -37.55625 \n",
       "L 113.01709 -37.55625 \n",
       "L 112.598067 -37.55625 \n",
       "L 112.179044 -37.55625 \n",
       "L 111.76002 -37.55625 \n",
       "L 111.340997 -37.55625 \n",
       "L 110.921973 -37.55625 \n",
       "L 110.50295 -37.55625 \n",
       "L 110.083927 -37.55625 \n",
       "L 109.664903 -37.55625 \n",
       "L 109.24588 -37.55625 \n",
       "L 108.826857 -37.55625 \n",
       "L 108.407833 -37.55625 \n",
       "L 107.98881 -37.55625 \n",
       "L 107.569786 -37.55625 \n",
       "L 107.150763 -37.55625 \n",
       "L 106.73174 -37.55625 \n",
       "L 106.312716 -37.55625 \n",
       "L 105.893693 -37.55625 \n",
       "L 105.474669 -37.55625 \n",
       "L 105.055646 -37.55625 \n",
       "L 104.636623 -37.55625 \n",
       "L 104.217589 -37.55625 \n",
       "L 103.798566 -37.55625 \n",
       "L 103.379543 -37.55625 \n",
       "L 102.960519 -37.55625 \n",
       "L 102.541496 -37.55625 \n",
       "L 102.122472 -37.55625 \n",
       "L 101.703449 -37.55625 \n",
       "L 101.284426 -37.55625 \n",
       "L 100.865402 -37.55625 \n",
       "L 100.446379 -37.55625 \n",
       "L 100.027356 -37.55625 \n",
       "L 99.608332 -37.55625 \n",
       "L 99.189309 -37.55625 \n",
       "L 98.770285 -37.55625 \n",
       "L 98.351262 -37.55625 \n",
       "L 97.932239 -37.55625 \n",
       "L 97.513215 -37.55625 \n",
       "L 97.094192 -37.55625 \n",
       "L 96.675169 -37.55625 \n",
       "L 96.256145 -37.55625 \n",
       "L 95.837122 -37.55625 \n",
       "L 95.418098 -37.55625 \n",
       "L 94.999075 -37.55625 \n",
       "L 94.580052 -37.55625 \n",
       "L 94.161018 -37.55625 \n",
       "L 93.741995 -37.55625 \n",
       "L 93.322971 -37.55625 \n",
       "L 92.903948 -37.55625 \n",
       "L 92.484925 -37.55625 \n",
       "L 92.065901 -37.55625 \n",
       "L 91.646878 -37.55625 \n",
       "L 91.227855 -37.55625 \n",
       "L 90.808831 -37.55625 \n",
       "L 90.389808 -37.55625 \n",
       "L 89.970784 -37.55625 \n",
       "L 89.551761 -37.55625 \n",
       "L 89.132738 -37.55625 \n",
       "L 88.713714 -37.55625 \n",
       "L 88.294691 -37.55625 \n",
       "L 87.875668 -37.55625 \n",
       "L 87.456644 -37.55625 \n",
       "L 87.037621 -37.55625 \n",
       "L 86.618597 -37.55625 \n",
       "L 86.199574 -37.55625 \n",
       "L 85.780551 -37.55625 \n",
       "L 85.361527 -37.55625 \n",
       "L 84.942504 -37.55625 \n",
       "L 84.523481 -37.55625 \n",
       "L 84.104447 -37.55625 \n",
       "L 83.685424 -37.55625 \n",
       "L 83.2664 -37.55625 \n",
       "L 82.847377 -37.55625 \n",
       "L 82.428354 -37.55625 \n",
       "L 82.00933 -37.55625 \n",
       "L 81.590307 -37.55625 \n",
       "L 81.171283 -37.55625 \n",
       "L 80.75226 -37.55625 \n",
       "L 80.333237 -37.55625 \n",
       "L 79.914213 -37.55625 \n",
       "L 79.49519 -37.55625 \n",
       "L 79.076167 -37.55625 \n",
       "L 78.657143 -37.55625 \n",
       "L 78.23812 -37.55625 \n",
       "L 77.819096 -37.55625 \n",
       "L 77.400073 -37.55625 \n",
       "L 76.98105 -37.55625 \n",
       "L 76.562026 -37.55625 \n",
       "L 76.143003 -37.55625 \n",
       "L 75.72398 -37.55625 \n",
       "L 75.304956 -37.55625 \n",
       "L 74.885933 -37.55625 \n",
       "L 74.466909 -37.55625 \n",
       "L 74.047886 -37.55625 \n",
       "L 73.628863 -37.55625 \n",
       "L 73.209839 -37.55625 \n",
       "L 72.790816 -37.55625 \n",
       "L 72.371793 -37.55625 \n",
       "L 71.952769 -37.55625 \n",
       "L 71.533746 -37.55625 \n",
       "L 71.114722 -37.55625 \n",
       "L 70.695689 -37.55625 \n",
       "L 70.276666 -37.55625 \n",
       "L 69.857642 -37.55625 \n",
       "L 69.438619 -37.55625 \n",
       "L 69.019595 -37.55625 \n",
       "L 68.600572 -37.55625 \n",
       "L 68.181549 -37.55625 \n",
       "L 67.762525 -37.55625 \n",
       "L 67.343502 -37.55625 \n",
       "L 66.924479 -37.55625 \n",
       "L 66.505455 -37.55625 \n",
       "L 66.086432 -37.55625 \n",
       "L 65.667408 -37.55625 \n",
       "L 65.248385 -37.55625 \n",
       "L 64.829362 -37.55625 \n",
       "L 64.410338 -37.55625 \n",
       "L 63.991315 -37.55625 \n",
       "L 63.572292 -37.55625 \n",
       "L 63.153268 -37.55625 \n",
       "L 62.734245 -37.55625 \n",
       "L 62.315221 -37.55625 \n",
       "L 61.896198 -37.55625 \n",
       "L 61.477175 -37.55625 \n",
       "L 61.058151 -37.55625 \n",
       "L 60.639118 -37.55625 \n",
       "L 60.220095 -37.55625 \n",
       "L 59.801071 -37.55625 \n",
       "L 59.382048 -37.55625 \n",
       "L 58.963024 -37.55625 \n",
       "L 58.544001 -37.55625 \n",
       "L 58.124978 -37.55625 \n",
       "L 57.705954 -37.55625 \n",
       "L 57.286931 -37.55625 \n",
       "L 56.867907 -37.55625 \n",
       "L 56.448884 -37.55625 \n",
       "L 56.029861 -37.55625 \n",
       "L 55.610837 -37.55625 \n",
       "L 55.191814 -37.55625 \n",
       "L 54.772791 -37.55625 \n",
       "L 54.353767 -37.55625 \n",
       "L 53.934744 -37.55625 \n",
       "L 53.51572 -37.55625 \n",
       "L 53.096697 -37.55625 \n",
       "L 52.677674 -37.55625 \n",
       "L 52.25865 -37.55625 \n",
       "L 51.839627 -37.55625 \n",
       "L 51.420604 -37.55625 \n",
       "L 51.00158 -37.55625 \n",
       "L 50.582547 -37.55625 \n",
       "L 50.163523 -37.55625 \n",
       "L 49.7445 -37.55625 \n",
       "L 49.325477 -37.55625 \n",
       "L 48.906453 -37.55625 \n",
       "L 48.48743 -37.55625 \n",
       "L 48.068407 -37.55625 \n",
       "L 47.649383 -37.55625 \n",
       "L 47.23036 -37.55625 \n",
       "L 46.811336 -37.55625 \n",
       "L 46.392313 -37.55625 \n",
       "L 45.97329 -37.55625 \n",
       "L 45.554266 -37.55625 \n",
       "L 45.135243 -37.55625 \n",
       "L 44.716219 -37.55625 \n",
       "L 44.297196 -37.55625 \n",
       "L 43.878173 -37.55625 \n",
       "L 43.459149 -37.55625 \n",
       "L 43.040126 -37.55625 \n",
       "L 42.621103 -37.55625 \n",
       "L 42.202079 -37.55625 \n",
       "L 41.783056 -37.55625 \n",
       "L 41.364032 -37.55625 \n",
       "L 40.945009 -37.55625 \n",
       "L 40.525976 -37.55625 \n",
       "L 40.106952 -37.55625 \n",
       "L 39.687929 -37.55625 \n",
       "L 39.268906 -37.55625 \n",
       "L 38.849882 -37.55625 \n",
       "L 38.430859 -37.55625 \n",
       "L 38.011835 -37.55625 \n",
       "L 37.592812 -37.55625 \n",
       "L 37.173789 -37.55625 \n",
       "L 36.754765 -37.55625 \n",
       "L 36.335742 -37.55625 \n",
       "L 35.916719 -37.55625 \n",
       "L 35.497695 -37.55625 \n",
       "L 35.078672 -37.55625 \n",
       "L 34.659648 -37.55625 \n",
       "L 34.240625 -37.55625 \n",
       "z\n",
       "\" style=\"stroke: #1f77b4; stroke-opacity: 0.5\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#p71e3478c5c)\">\n",
       "     <use xlink:href=\"#mf504fdd74f\" x=\"0\" y=\"222.954375\" style=\"fill: #1f77b4; fill-opacity: 0.5; stroke: #1f77b4; stroke-opacity: 0.5\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"PolyCollection_2\">\n",
       "    <defs>\n",
       "     <path id=\"m03f3326a1a\" d=\"M 120.559521 -37.55625 \n",
       "L 120.559521 -72.382988 \n",
       "L 120.978549 -72.644339 \n",
       "L 121.397573 -72.906859 \n",
       "L 121.816596 -73.170547 \n",
       "L 122.23562 -73.435396 \n",
       "L 122.654643 -73.701388 \n",
       "L 123.073666 -73.968536 \n",
       "L 123.49269 -74.2368 \n",
       "L 123.911713 -74.506215 \n",
       "L 124.330742 -74.776719 \n",
       "L 124.74976 -75.048328 \n",
       "L 125.168783 -75.321021 \n",
       "L 125.587807 -75.594787 \n",
       "L 126.00683 -75.869627 \n",
       "L 126.425853 -76.14553 \n",
       "L 126.844877 -76.422458 \n",
       "L 127.2639 -76.70042 \n",
       "L 127.682929 -76.979394 \n",
       "L 128.101952 -77.259371 \n",
       "L 128.520975 -77.540333 \n",
       "L 128.939999 -77.822259 \n",
       "L 129.359022 -78.105158 \n",
       "L 129.778045 -78.388992 \n",
       "L 130.197069 -78.673752 \n",
       "L 130.616092 -78.959424 \n",
       "L 131.035121 -79.245988 \n",
       "L 131.454144 -79.533455 \n",
       "L 131.873167 -79.821753 \n",
       "L 132.292191 -80.110916 \n",
       "L 132.711214 -80.400896 \n",
       "L 133.130237 -80.691693 \n",
       "L 133.549261 -80.983284 \n",
       "L 133.968284 -81.275645 \n",
       "L 134.387313 -81.568766 \n",
       "L 134.806331 -81.86261 \n",
       "L 135.225354 -82.157172 \n",
       "L 135.644378 -82.452423 \n",
       "L 136.063401 -82.748365 \n",
       "L 136.482425 -83.044948 \n",
       "L 136.901448 -83.342165 \n",
       "L 137.320471 -83.639996 \n",
       "L 137.7395 -83.938432 \n",
       "L 138.158523 -84.237415 \n",
       "L 138.577546 -84.536946 \n",
       "L 138.99657 -84.836993 \n",
       "L 139.415593 -85.137535 \n",
       "L 139.834617 -85.438564 \n",
       "L 140.25364 -85.740037 \n",
       "L 140.672663 -86.041925 \n",
       "L 141.091692 -86.344225 \n",
       "L 141.51071 -86.646888 \n",
       "L 141.929733 -86.949892 \n",
       "L 142.348757 -87.253235 \n",
       "L 142.76778 -87.556857 \n",
       "L 143.186804 -87.860763 \n",
       "L 143.605827 -88.1649 \n",
       "L 144.02485 -88.469245 \n",
       "L 144.443879 -88.773793 \n",
       "L 144.862902 -89.078488 \n",
       "L 145.281925 -89.383315 \n",
       "L 145.700949 -89.688241 \n",
       "L 146.119972 -89.993223 \n",
       "L 146.538996 -90.298253 \n",
       "L 146.958019 -90.603302 \n",
       "L 147.377042 -90.908318 \n",
       "L 147.796071 -91.213282 \n",
       "L 148.215094 -91.518165 \n",
       "L 148.634118 -91.822935 \n",
       "L 149.053141 -92.127559 \n",
       "L 149.472164 -92.431989 \n",
       "L 149.891188 -92.73622 \n",
       "L 150.310211 -93.040206 \n",
       "L 150.729234 -93.343909 \n",
       "L 151.148263 -93.647304 \n",
       "L 151.567281 -93.95036 \n",
       "L 151.986305 -94.253032 \n",
       "L 152.405328 -94.55528 \n",
       "L 152.824351 -94.857084 \n",
       "L 153.243375 -95.158401 \n",
       "L 153.662398 -95.459207 \n",
       "L 154.081421 -95.759457 \n",
       "L 154.50045 -96.059106 \n",
       "L 154.919473 -96.358137 \n",
       "L 155.338497 -96.656497 \n",
       "L 155.75752 -96.954163 \n",
       "L 155.75752 -37.55625 \n",
       "L 155.75752 -37.55625 \n",
       "L 155.338497 -37.55625 \n",
       "L 154.919473 -37.55625 \n",
       "L 154.50045 -37.55625 \n",
       "L 154.081421 -37.55625 \n",
       "L 153.662398 -37.55625 \n",
       "L 153.243375 -37.55625 \n",
       "L 152.824351 -37.55625 \n",
       "L 152.405328 -37.55625 \n",
       "L 151.986305 -37.55625 \n",
       "L 151.567281 -37.55625 \n",
       "L 151.148263 -37.55625 \n",
       "L 150.729234 -37.55625 \n",
       "L 150.310211 -37.55625 \n",
       "L 149.891188 -37.55625 \n",
       "L 149.472164 -37.55625 \n",
       "L 149.053141 -37.55625 \n",
       "L 148.634118 -37.55625 \n",
       "L 148.215094 -37.55625 \n",
       "L 147.796071 -37.55625 \n",
       "L 147.377042 -37.55625 \n",
       "L 146.958019 -37.55625 \n",
       "L 146.538996 -37.55625 \n",
       "L 146.119972 -37.55625 \n",
       "L 145.700949 -37.55625 \n",
       "L 145.281925 -37.55625 \n",
       "L 144.862902 -37.55625 \n",
       "L 144.443879 -37.55625 \n",
       "L 144.02485 -37.55625 \n",
       "L 143.605827 -37.55625 \n",
       "L 143.186804 -37.55625 \n",
       "L 142.76778 -37.55625 \n",
       "L 142.348757 -37.55625 \n",
       "L 141.929733 -37.55625 \n",
       "L 141.51071 -37.55625 \n",
       "L 141.091692 -37.55625 \n",
       "L 140.672663 -37.55625 \n",
       "L 140.25364 -37.55625 \n",
       "L 139.834617 -37.55625 \n",
       "L 139.415593 -37.55625 \n",
       "L 138.99657 -37.55625 \n",
       "L 138.577546 -37.55625 \n",
       "L 138.158523 -37.55625 \n",
       "L 137.7395 -37.55625 \n",
       "L 137.320471 -37.55625 \n",
       "L 136.901448 -37.55625 \n",
       "L 136.482425 -37.55625 \n",
       "L 136.063401 -37.55625 \n",
       "L 135.644378 -37.55625 \n",
       "L 135.225354 -37.55625 \n",
       "L 134.806331 -37.55625 \n",
       "L 134.387313 -37.55625 \n",
       "L 133.968284 -37.55625 \n",
       "L 133.549261 -37.55625 \n",
       "L 133.130237 -37.55625 \n",
       "L 132.711214 -37.55625 \n",
       "L 132.292191 -37.55625 \n",
       "L 131.873167 -37.55625 \n",
       "L 131.454144 -37.55625 \n",
       "L 131.035121 -37.55625 \n",
       "L 130.616092 -37.55625 \n",
       "L 130.197069 -37.55625 \n",
       "L 129.778045 -37.55625 \n",
       "L 129.359022 -37.55625 \n",
       "L 128.939999 -37.55625 \n",
       "L 128.520975 -37.55625 \n",
       "L 128.101952 -37.55625 \n",
       "L 127.682929 -37.55625 \n",
       "L 127.2639 -37.55625 \n",
       "L 126.844877 -37.55625 \n",
       "L 126.425853 -37.55625 \n",
       "L 126.00683 -37.55625 \n",
       "L 125.587807 -37.55625 \n",
       "L 125.168783 -37.55625 \n",
       "L 124.74976 -37.55625 \n",
       "L 124.330742 -37.55625 \n",
       "L 123.911713 -37.55625 \n",
       "L 123.49269 -37.55625 \n",
       "L 123.073666 -37.55625 \n",
       "L 122.654643 -37.55625 \n",
       "L 122.23562 -37.55625 \n",
       "L 121.816596 -37.55625 \n",
       "L 121.397573 -37.55625 \n",
       "L 120.978549 -37.55625 \n",
       "L 120.559521 -37.55625 \n",
       "z\n",
       "\" style=\"stroke: #ff7f0e; stroke-opacity: 0.5\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#p71e3478c5c)\">\n",
       "     <use xlink:href=\"#m03f3326a1a\" x=\"0\" y=\"222.954375\" style=\"fill: #ff7f0e; fill-opacity: 0.5; stroke: #ff7f0e; stroke-opacity: 0.5\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"PolyCollection_3\">\n",
       "    <defs>\n",
       "     <path id=\"m9fac17fc9c\" d=\"M 156.176543 -37.55625 \n",
       "L 156.176543 -156.945904 \n",
       "L 156.595567 -157.538212 \n",
       "L 157.01459 -158.128885 \n",
       "L 157.433613 -158.717839 \n",
       "L 157.852642 -159.305045 \n",
       "L 158.271665 -159.89039 \n",
       "L 158.690689 -160.473798 \n",
       "L 159.109712 -161.055194 \n",
       "L 159.528735 -161.63454 \n",
       "L 159.947761 -162.211703 \n",
       "L 160.366785 -162.786627 \n",
       "L 160.785808 -163.359218 \n",
       "L 161.204831 -163.929428 \n",
       "L 161.623855 -164.497172 \n",
       "L 162.042878 -165.062327 \n",
       "L 162.461902 -165.624866 \n",
       "L 162.880925 -166.184702 \n",
       "L 163.299951 -166.741732 \n",
       "L 163.718974 -167.295872 \n",
       "L 164.137998 -167.847083 \n",
       "L 164.557021 -168.395232 \n",
       "L 164.976044 -168.940302 \n",
       "L 165.395068 -169.482141 \n",
       "L 165.814091 -170.020711 \n",
       "L 166.233114 -170.555936 \n",
       "L 166.65214 -171.087704 \n",
       "L 167.071164 -171.615928 \n",
       "L 167.490187 -172.140591 \n",
       "L 167.90921 -172.66157 \n",
       "L 168.328234 -173.178788 \n",
       "L 168.747257 -173.692133 \n",
       "L 169.166281 -174.201557 \n",
       "L 169.585304 -174.706975 \n",
       "L 170.00433 -175.20835 \n",
       "L 170.423353 -175.70553 \n",
       "L 170.842377 -176.198458 \n",
       "L 171.2614 -176.687079 \n",
       "L 171.680423 -177.171259 \n",
       "L 172.099447 -177.650979 \n",
       "L 172.51847 -178.126146 \n",
       "L 172.937494 -178.596637 \n",
       "L 173.356519 -179.062432 \n",
       "L 173.775543 -179.523427 \n",
       "L 174.194566 -179.979548 \n",
       "L 174.61359 -180.43069 \n",
       "L 175.032615 -180.876815 \n",
       "L 175.451639 -181.317819 \n",
       "L 175.870662 -181.753666 \n",
       "L 176.289686 -182.184259 \n",
       "L 176.708711 -182.609476 \n",
       "L 177.127735 -183.029337 \n",
       "L 177.546758 -183.443699 \n",
       "L 177.965782 -183.852516 \n",
       "L 178.384805 -184.255683 \n",
       "L 178.803828 -184.6532 \n",
       "L 179.222852 -185.044935 \n",
       "L 179.641875 -185.430794 \n",
       "L 180.060901 -185.810795 \n",
       "L 180.060901 -37.55625 \n",
       "L 180.060901 -37.55625 \n",
       "L 179.641875 -37.55625 \n",
       "L 179.222852 -37.55625 \n",
       "L 178.803828 -37.55625 \n",
       "L 178.384805 -37.55625 \n",
       "L 177.965782 -37.55625 \n",
       "L 177.546758 -37.55625 \n",
       "L 177.127735 -37.55625 \n",
       "L 176.708711 -37.55625 \n",
       "L 176.289686 -37.55625 \n",
       "L 175.870662 -37.55625 \n",
       "L 175.451639 -37.55625 \n",
       "L 175.032615 -37.55625 \n",
       "L 174.61359 -37.55625 \n",
       "L 174.194566 -37.55625 \n",
       "L 173.775543 -37.55625 \n",
       "L 173.356519 -37.55625 \n",
       "L 172.937494 -37.55625 \n",
       "L 172.51847 -37.55625 \n",
       "L 172.099447 -37.55625 \n",
       "L 171.680423 -37.55625 \n",
       "L 171.2614 -37.55625 \n",
       "L 170.842377 -37.55625 \n",
       "L 170.423353 -37.55625 \n",
       "L 170.00433 -37.55625 \n",
       "L 169.585304 -37.55625 \n",
       "L 169.166281 -37.55625 \n",
       "L 168.747257 -37.55625 \n",
       "L 168.328234 -37.55625 \n",
       "L 167.90921 -37.55625 \n",
       "L 167.490187 -37.55625 \n",
       "L 167.071164 -37.55625 \n",
       "L 166.65214 -37.55625 \n",
       "L 166.233114 -37.55625 \n",
       "L 165.814091 -37.55625 \n",
       "L 165.395068 -37.55625 \n",
       "L 164.976044 -37.55625 \n",
       "L 164.557021 -37.55625 \n",
       "L 164.137998 -37.55625 \n",
       "L 163.718974 -37.55625 \n",
       "L 163.299951 -37.55625 \n",
       "L 162.880925 -37.55625 \n",
       "L 162.461902 -37.55625 \n",
       "L 162.042878 -37.55625 \n",
       "L 161.623855 -37.55625 \n",
       "L 161.204831 -37.55625 \n",
       "L 160.785808 -37.55625 \n",
       "L 160.366785 -37.55625 \n",
       "L 159.947761 -37.55625 \n",
       "L 159.528735 -37.55625 \n",
       "L 159.109712 -37.55625 \n",
       "L 158.690689 -37.55625 \n",
       "L 158.271665 -37.55625 \n",
       "L 157.852642 -37.55625 \n",
       "L 157.433613 -37.55625 \n",
       "L 157.01459 -37.55625 \n",
       "L 156.595567 -37.55625 \n",
       "L 156.176543 -37.55625 \n",
       "z\n",
       "\" style=\"stroke: #2ca02c; stroke-opacity: 0.5\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#p71e3478c5c)\">\n",
       "     <use xlink:href=\"#m9fac17fc9c\" x=\"0\" y=\"222.954375\" style=\"fill: #2ca02c; fill-opacity: 0.5; stroke: #2ca02c; stroke-opacity: 0.5\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"PolyCollection_4\">\n",
       "    <defs>\n",
       "     <path id=\"m811810ea94\" d=\"M 180.479924 -37.55625 \n",
       "L 180.479924 -111.870524 \n",
       "L 180.898948 -112.054502 \n",
       "L 181.317971 -112.235428 \n",
       "L 181.736996 -112.413274 \n",
       "L 182.156019 -112.587993 \n",
       "L 182.575044 -112.759548 \n",
       "L 182.994067 -112.927937 \n",
       "L 183.413091 -113.093119 \n",
       "L 183.832115 -113.255036 \n",
       "L 184.251139 -113.413671 \n",
       "L 184.670162 -113.569018 \n",
       "L 185.089185 -113.72103 \n",
       "L 185.508209 -113.869669 \n",
       "L 185.927233 -114.014926 \n",
       "L 186.346257 -114.156763 \n",
       "L 186.76528 -114.295146 \n",
       "L 187.184305 -114.430063 \n",
       "L 187.603328 -114.561493 \n",
       "L 188.022351 -114.68939 \n",
       "L 188.441376 -114.813734 \n",
       "L 188.860399 -114.934513 \n",
       "L 189.279424 -115.051696 \n",
       "L 189.698447 -115.165261 \n",
       "L 190.117471 -115.275193 \n",
       "L 190.536495 -115.38146 \n",
       "L 190.955519 -115.484042 \n",
       "L 191.374542 -115.58293 \n",
       "L 191.793566 -115.678095 \n",
       "L 192.21259 -115.769524 \n",
       "L 192.631614 -115.857189 \n",
       "L 193.050638 -115.941083 \n",
       "L 193.469662 -116.021194 \n",
       "L 193.888685 -116.097484 \n",
       "L 194.307709 -116.169966 \n",
       "L 194.726732 -116.238607 \n",
       "L 195.145756 -116.303399 \n",
       "L 195.56478 -116.364326 \n",
       "L 195.983804 -116.421385 \n",
       "L 196.402828 -116.474556 \n",
       "L 196.821851 -116.52383 \n",
       "L 197.240875 -116.569212 \n",
       "L 197.659899 -116.610654 \n",
       "L 198.078923 -116.648189 \n",
       "L 198.497947 -116.681789 \n",
       "L 198.91697 -116.711455 \n",
       "L 199.335994 -116.737162 \n",
       "L 199.755018 -116.758938 \n",
       "L 200.174042 -116.776757 \n",
       "L 200.593065 -116.79063 \n",
       "L 201.012089 -116.800532 \n",
       "L 201.431113 -116.806474 \n",
       "L 201.431113 -37.55625 \n",
       "L 201.431113 -37.55625 \n",
       "L 201.012089 -37.55625 \n",
       "L 200.593065 -37.55625 \n",
       "L 200.174042 -37.55625 \n",
       "L 199.755018 -37.55625 \n",
       "L 199.335994 -37.55625 \n",
       "L 198.91697 -37.55625 \n",
       "L 198.497947 -37.55625 \n",
       "L 198.078923 -37.55625 \n",
       "L 197.659899 -37.55625 \n",
       "L 197.240875 -37.55625 \n",
       "L 196.821851 -37.55625 \n",
       "L 196.402828 -37.55625 \n",
       "L 195.983804 -37.55625 \n",
       "L 195.56478 -37.55625 \n",
       "L 195.145756 -37.55625 \n",
       "L 194.726732 -37.55625 \n",
       "L 194.307709 -37.55625 \n",
       "L 193.888685 -37.55625 \n",
       "L 193.469662 -37.55625 \n",
       "L 193.050638 -37.55625 \n",
       "L 192.631614 -37.55625 \n",
       "L 192.21259 -37.55625 \n",
       "L 191.793566 -37.55625 \n",
       "L 191.374542 -37.55625 \n",
       "L 190.955519 -37.55625 \n",
       "L 190.536495 -37.55625 \n",
       "L 190.117471 -37.55625 \n",
       "L 189.698447 -37.55625 \n",
       "L 189.279424 -37.55625 \n",
       "L 188.860399 -37.55625 \n",
       "L 188.441376 -37.55625 \n",
       "L 188.022351 -37.55625 \n",
       "L 187.603328 -37.55625 \n",
       "L 187.184305 -37.55625 \n",
       "L 186.76528 -37.55625 \n",
       "L 186.346257 -37.55625 \n",
       "L 185.927233 -37.55625 \n",
       "L 185.508209 -37.55625 \n",
       "L 185.089185 -37.55625 \n",
       "L 184.670162 -37.55625 \n",
       "L 184.251139 -37.55625 \n",
       "L 183.832115 -37.55625 \n",
       "L 183.413091 -37.55625 \n",
       "L 182.994067 -37.55625 \n",
       "L 182.575044 -37.55625 \n",
       "L 182.156019 -37.55625 \n",
       "L 181.736996 -37.55625 \n",
       "L 181.317971 -37.55625 \n",
       "L 180.898948 -37.55625 \n",
       "L 180.479924 -37.55625 \n",
       "z\n",
       "\" style=\"stroke: #d62728; stroke-opacity: 0.5\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#p71e3478c5c)\">\n",
       "     <use xlink:href=\"#m811810ea94\" x=\"0\" y=\"222.954375\" style=\"fill: #d62728; fill-opacity: 0.5; stroke: #d62728; stroke-opacity: 0.5\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"PolyCollection_5\">\n",
       "    <defs>\n",
       "     <path id=\"m7d05c0894d\" d=\"M 201.850137 -37.55625 \n",
       "L 201.850137 -67.275828 \n",
       "L 202.26916 -67.275084 \n",
       "L 202.688184 -67.272856 \n",
       "L 203.107208 -67.269143 \n",
       "L 203.526232 -67.263944 \n",
       "L 203.945256 -67.257262 \n",
       "L 204.364279 -67.249099 \n",
       "L 204.783303 -67.239452 \n",
       "L 205.202327 -67.228327 \n",
       "L 205.621351 -67.215727 \n",
       "L 206.040375 -67.201651 \n",
       "L 206.459398 -67.186107 \n",
       "L 206.878422 -67.169093 \n",
       "L 207.297446 -67.150615 \n",
       "L 207.71647 -67.130676 \n",
       "L 208.135493 -67.109279 \n",
       "L 208.554517 -67.086434 \n",
       "L 208.973541 -67.062134 \n",
       "L 209.392564 -67.036393 \n",
       "L 209.811588 -67.009213 \n",
       "L 210.230612 -66.980601 \n",
       "L 210.649636 -66.950563 \n",
       "L 211.06866 -66.919102 \n",
       "L 211.487683 -66.886224 \n",
       "L 211.906707 -66.851942 \n",
       "L 212.325731 -66.816255 \n",
       "L 212.744755 -66.779172 \n",
       "L 213.163778 -66.740704 \n",
       "L 213.582803 -66.700854 \n",
       "L 214.001826 -66.659629 \n",
       "L 214.420849 -66.617042 \n",
       "L 214.839874 -66.573098 \n",
       "L 215.258897 -66.527807 \n",
       "L 215.677921 -66.481177 \n",
       "L 216.096945 -66.433213 \n",
       "L 216.515969 -66.383933 \n",
       "L 216.934992 -66.333336 \n",
       "L 217.354017 -66.281442 \n",
       "L 217.77304 -66.228253 \n",
       "L 218.192063 -66.173782 \n",
       "L 218.611088 -66.118042 \n",
       "L 219.030111 -66.06104 \n",
       "L 219.449136 -66.002786 \n",
       "L 219.868159 -65.943295 \n",
       "L 220.287183 -65.882572 \n",
       "L 220.706208 -65.820633 \n",
       "L 221.125231 -65.75749 \n",
       "L 221.544254 -65.693152 \n",
       "L 221.963278 -65.627634 \n",
       "L 222.382301 -65.560942 \n",
       "L 222.801326 -65.493094 \n",
       "L 223.220349 -65.424103 \n",
       "L 223.220349 -37.55625 \n",
       "L 223.220349 -37.55625 \n",
       "L 222.801326 -37.55625 \n",
       "L 222.382301 -37.55625 \n",
       "L 221.963278 -37.55625 \n",
       "L 221.544254 -37.55625 \n",
       "L 221.125231 -37.55625 \n",
       "L 220.706208 -37.55625 \n",
       "L 220.287183 -37.55625 \n",
       "L 219.868159 -37.55625 \n",
       "L 219.449136 -37.55625 \n",
       "L 219.030111 -37.55625 \n",
       "L 218.611088 -37.55625 \n",
       "L 218.192063 -37.55625 \n",
       "L 217.77304 -37.55625 \n",
       "L 217.354017 -37.55625 \n",
       "L 216.934992 -37.55625 \n",
       "L 216.515969 -37.55625 \n",
       "L 216.096945 -37.55625 \n",
       "L 215.677921 -37.55625 \n",
       "L 215.258897 -37.55625 \n",
       "L 214.839874 -37.55625 \n",
       "L 214.420849 -37.55625 \n",
       "L 214.001826 -37.55625 \n",
       "L 213.582803 -37.55625 \n",
       "L 213.163778 -37.55625 \n",
       "L 212.744755 -37.55625 \n",
       "L 212.325731 -37.55625 \n",
       "L 211.906707 -37.55625 \n",
       "L 211.487683 -37.55625 \n",
       "L 211.06866 -37.55625 \n",
       "L 210.649636 -37.55625 \n",
       "L 210.230612 -37.55625 \n",
       "L 209.811588 -37.55625 \n",
       "L 209.392564 -37.55625 \n",
       "L 208.973541 -37.55625 \n",
       "L 208.554517 -37.55625 \n",
       "L 208.135493 -37.55625 \n",
       "L 207.71647 -37.55625 \n",
       "L 207.297446 -37.55625 \n",
       "L 206.878422 -37.55625 \n",
       "L 206.459398 -37.55625 \n",
       "L 206.040375 -37.55625 \n",
       "L 205.621351 -37.55625 \n",
       "L 205.202327 -37.55625 \n",
       "L 204.783303 -37.55625 \n",
       "L 204.364279 -37.55625 \n",
       "L 203.945256 -37.55625 \n",
       "L 203.526232 -37.55625 \n",
       "L 203.107208 -37.55625 \n",
       "L 202.688184 -37.55625 \n",
       "L 202.26916 -37.55625 \n",
       "L 201.850137 -37.55625 \n",
       "z\n",
       "\" style=\"stroke: #9467bd; stroke-opacity: 0.5\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#p71e3478c5c)\">\n",
       "     <use xlink:href=\"#m7d05c0894d\" x=\"0\" y=\"222.954375\" style=\"fill: #9467bd; fill-opacity: 0.5; stroke: #9467bd; stroke-opacity: 0.5\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"PolyCollection_6\">\n",
       "    <defs>\n",
       "     <path id=\"m1c628ac199\" d=\"M 223.639372 -37.55625 \n",
       "L 223.639372 -46.822159 \n",
       "L 224.058396 -46.798409 \n",
       "L 224.477419 -46.774292 \n",
       "L 224.896445 -46.749809 \n",
       "L 225.315468 -46.724966 \n",
       "L 225.734492 -46.699767 \n",
       "L 226.153515 -46.674216 \n",
       "L 226.572539 -46.648318 \n",
       "L 226.991564 -46.622079 \n",
       "L 227.410588 -46.595499 \n",
       "L 227.829611 -46.568588 \n",
       "L 228.248635 -46.541349 \n",
       "L 228.667658 -46.513785 \n",
       "L 229.086681 -46.485902 \n",
       "L 229.505705 -46.457705 \n",
       "L 229.924728 -46.429197 \n",
       "L 230.343754 -46.400386 \n",
       "L 230.762777 -46.371274 \n",
       "L 231.181801 -46.341867 \n",
       "L 231.600824 -46.312171 \n",
       "L 232.01985 -46.282188 \n",
       "L 232.438873 -46.251926 \n",
       "L 232.857897 -46.221388 \n",
       "L 233.27692 -46.19058 \n",
       "L 233.695946 -46.159506 \n",
       "L 234.114969 -46.128172 \n",
       "L 234.533993 -46.096582 \n",
       "L 234.953016 -46.064743 \n",
       "L 235.37204 -46.032659 \n",
       "L 235.791063 -46.000332 \n",
       "L 236.210086 -45.967773 \n",
       "L 236.62911 -45.934982 \n",
       "L 237.048136 -45.901966 \n",
       "L 237.467159 -45.86873 \n",
       "L 237.886182 -45.835278 \n",
       "L 238.305206 -45.801618 \n",
       "L 238.724229 -45.767753 \n",
       "L 239.143252 -45.733688 \n",
       "L 239.562276 -45.699426 \n",
       "L 239.981299 -45.664976 \n",
       "L 240.400325 -45.630342 \n",
       "L 240.819348 -45.595527 \n",
       "L 241.238372 -45.560538 \n",
       "L 241.657395 -45.52538 \n",
       "L 242.076419 -45.490056 \n",
       "L 242.495442 -45.454574 \n",
       "L 242.914465 -45.418935 \n",
       "L 243.333489 -45.383147 \n",
       "L 243.752515 -45.347215 \n",
       "L 244.171538 -45.311143 \n",
       "L 244.590561 -45.274935 \n",
       "L 245.009585 -45.238597 \n",
       "L 245.428608 -45.202134 \n",
       "L 245.847632 -45.16555 \n",
       "L 246.266655 -45.12885 \n",
       "L 246.685678 -45.09204 \n",
       "L 247.104702 -45.055123 \n",
       "L 247.523725 -45.018104 \n",
       "L 247.523725 -37.55625 \n",
       "L 247.523725 -37.55625 \n",
       "L 247.104702 -37.55625 \n",
       "L 246.685678 -37.55625 \n",
       "L 246.266655 -37.55625 \n",
       "L 245.847632 -37.55625 \n",
       "L 245.428608 -37.55625 \n",
       "L 245.009585 -37.55625 \n",
       "L 244.590561 -37.55625 \n",
       "L 244.171538 -37.55625 \n",
       "L 243.752515 -37.55625 \n",
       "L 243.333489 -37.55625 \n",
       "L 242.914465 -37.55625 \n",
       "L 242.495442 -37.55625 \n",
       "L 242.076419 -37.55625 \n",
       "L 241.657395 -37.55625 \n",
       "L 241.238372 -37.55625 \n",
       "L 240.819348 -37.55625 \n",
       "L 240.400325 -37.55625 \n",
       "L 239.981299 -37.55625 \n",
       "L 239.562276 -37.55625 \n",
       "L 239.143252 -37.55625 \n",
       "L 238.724229 -37.55625 \n",
       "L 238.305206 -37.55625 \n",
       "L 237.886182 -37.55625 \n",
       "L 237.467159 -37.55625 \n",
       "L 237.048136 -37.55625 \n",
       "L 236.62911 -37.55625 \n",
       "L 236.210086 -37.55625 \n",
       "L 235.791063 -37.55625 \n",
       "L 235.37204 -37.55625 \n",
       "L 234.953016 -37.55625 \n",
       "L 234.533993 -37.55625 \n",
       "L 234.114969 -37.55625 \n",
       "L 233.695946 -37.55625 \n",
       "L 233.27692 -37.55625 \n",
       "L 232.857897 -37.55625 \n",
       "L 232.438873 -37.55625 \n",
       "L 232.01985 -37.55625 \n",
       "L 231.600824 -37.55625 \n",
       "L 231.181801 -37.55625 \n",
       "L 230.762777 -37.55625 \n",
       "L 230.343754 -37.55625 \n",
       "L 229.924728 -37.55625 \n",
       "L 229.505705 -37.55625 \n",
       "L 229.086681 -37.55625 \n",
       "L 228.667658 -37.55625 \n",
       "L 228.248635 -37.55625 \n",
       "L 227.829611 -37.55625 \n",
       "L 227.410588 -37.55625 \n",
       "L 226.991564 -37.55625 \n",
       "L 226.572539 -37.55625 \n",
       "L 226.153515 -37.55625 \n",
       "L 225.734492 -37.55625 \n",
       "L 225.315468 -37.55625 \n",
       "L 224.896445 -37.55625 \n",
       "L 224.477419 -37.55625 \n",
       "L 224.058396 -37.55625 \n",
       "L 223.639372 -37.55625 \n",
       "z\n",
       "\" style=\"stroke: #8c564b; stroke-opacity: 0.5\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#p71e3478c5c)\">\n",
       "     <use xlink:href=\"#m1c628ac199\" x=\"0\" y=\"222.954375\" style=\"fill: #8c564b; fill-opacity: 0.5; stroke: #8c564b; stroke-opacity: 0.5\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"PolyCollection_7\">\n",
       "    <defs>\n",
       "     <path id=\"m0a4cd2900d\" d=\"M 247.942748 -37.55625 \n",
       "L 247.942748 -41.26862 \n",
       "L 248.361777 -41.250015 \n",
       "L 248.7808 -41.231368 \n",
       "L 249.199824 -41.212678 \n",
       "L 249.618847 -41.19395 \n",
       "L 250.03787 -41.175185 \n",
       "L 250.456894 -41.156385 \n",
       "L 250.875917 -41.137552 \n",
       "L 251.29494 -41.11869 \n",
       "L 251.713969 -41.099799 \n",
       "L 252.132992 -41.080882 \n",
       "L 252.552016 -41.061941 \n",
       "L 252.971039 -41.042979 \n",
       "L 253.390062 -41.023998 \n",
       "L 253.809086 -41.004998 \n",
       "L 254.228109 -40.985985 \n",
       "L 254.647132 -40.966957 \n",
       "L 255.066161 -40.947918 \n",
       "L 255.485179 -40.92887 \n",
       "L 255.904203 -40.909815 \n",
       "L 256.323226 -40.890754 \n",
       "L 256.742249 -40.871691 \n",
       "L 257.161273 -40.852625 \n",
       "L 257.580296 -40.833561 \n",
       "L 257.99932 -40.814499 \n",
       "L 258.418348 -40.795442 \n",
       "L 258.837371 -40.77639 \n",
       "L 259.256395 -40.757346 \n",
       "L 259.675418 -40.738313 \n",
       "L 260.094441 -40.719291 \n",
       "L 260.513465 -40.700282 \n",
       "L 260.932488 -40.681289 \n",
       "L 261.351512 -40.662312 \n",
       "L 261.77054 -40.643353 \n",
       "L 262.189563 -40.624415 \n",
       "L 262.608587 -40.605498 \n",
       "L 263.02761 -40.586605 \n",
       "L 263.446633 -40.567736 \n",
       "L 263.865657 -40.548895 \n",
       "L 264.28468 -40.53008 \n",
       "L 264.703704 -40.511296 \n",
       "L 265.122732 -40.492543 \n",
       "L 265.54175 -40.473823 \n",
       "L 265.960774 -40.455136 \n",
       "L 266.379797 -40.436484 \n",
       "L 266.79882 -40.417871 \n",
       "L 267.217844 -40.399294 \n",
       "L 267.636867 -40.380757 \n",
       "L 268.055891 -40.362261 \n",
       "L 268.474919 -40.343807 \n",
       "L 268.893942 -40.325397 \n",
       "L 269.312966 -40.307032 \n",
       "L 269.731989 -40.288712 \n",
       "L 270.151013 -40.270439 \n",
       "L 270.570036 -40.252215 \n",
       "L 270.989059 -40.23404 \n",
       "L 271.408083 -40.215917 \n",
       "L 271.827111 -40.197844 \n",
       "L 272.246129 -40.179825 \n",
       "L 272.665153 -40.161859 \n",
       "L 273.084176 -40.143948 \n",
       "L 273.5032 -40.126094 \n",
       "L 273.922223 -40.108296 \n",
       "L 274.341246 -40.090557 \n",
       "L 274.76027 -40.072876 \n",
       "L 275.179298 -40.055255 \n",
       "L 275.598321 -40.037695 \n",
       "L 276.017345 -40.020196 \n",
       "L 276.436368 -40.002761 \n",
       "L 276.855392 -39.985388 \n",
       "L 277.274415 -39.96808 \n",
       "L 277.693438 -39.950837 \n",
       "L 278.112462 -39.933659 \n",
       "L 278.53149 -39.916548 \n",
       "L 278.950513 -39.899505 \n",
       "L 279.369537 -39.882529 \n",
       "L 279.78856 -39.865623 \n",
       "L 280.207584 -39.848785 \n",
       "L 280.626607 -39.832018 \n",
       "L 281.04563 -39.815322 \n",
       "L 281.464654 -39.798697 \n",
       "L 281.883682 -39.782143 \n",
       "L 282.302701 -39.765662 \n",
       "L 282.721724 -39.749255 \n",
       "L 283.140747 -39.732922 \n",
       "L 283.140747 -37.55625 \n",
       "L 283.140747 -37.55625 \n",
       "L 282.721724 -37.55625 \n",
       "L 282.302701 -37.55625 \n",
       "L 281.883682 -37.55625 \n",
       "L 281.464654 -37.55625 \n",
       "L 281.04563 -37.55625 \n",
       "L 280.626607 -37.55625 \n",
       "L 280.207584 -37.55625 \n",
       "L 279.78856 -37.55625 \n",
       "L 279.369537 -37.55625 \n",
       "L 278.950513 -37.55625 \n",
       "L 278.53149 -37.55625 \n",
       "L 278.112462 -37.55625 \n",
       "L 277.693438 -37.55625 \n",
       "L 277.274415 -37.55625 \n",
       "L 276.855392 -37.55625 \n",
       "L 276.436368 -37.55625 \n",
       "L 276.017345 -37.55625 \n",
       "L 275.598321 -37.55625 \n",
       "L 275.179298 -37.55625 \n",
       "L 274.76027 -37.55625 \n",
       "L 274.341246 -37.55625 \n",
       "L 273.922223 -37.55625 \n",
       "L 273.5032 -37.55625 \n",
       "L 273.084176 -37.55625 \n",
       "L 272.665153 -37.55625 \n",
       "L 272.246129 -37.55625 \n",
       "L 271.827111 -37.55625 \n",
       "L 271.408083 -37.55625 \n",
       "L 270.989059 -37.55625 \n",
       "L 270.570036 -37.55625 \n",
       "L 270.151013 -37.55625 \n",
       "L 269.731989 -37.55625 \n",
       "L 269.312966 -37.55625 \n",
       "L 268.893942 -37.55625 \n",
       "L 268.474919 -37.55625 \n",
       "L 268.055891 -37.55625 \n",
       "L 267.636867 -37.55625 \n",
       "L 267.217844 -37.55625 \n",
       "L 266.79882 -37.55625 \n",
       "L 266.379797 -37.55625 \n",
       "L 265.960774 -37.55625 \n",
       "L 265.54175 -37.55625 \n",
       "L 265.122732 -37.55625 \n",
       "L 264.703704 -37.55625 \n",
       "L 264.28468 -37.55625 \n",
       "L 263.865657 -37.55625 \n",
       "L 263.446633 -37.55625 \n",
       "L 263.02761 -37.55625 \n",
       "L 262.608587 -37.55625 \n",
       "L 262.189563 -37.55625 \n",
       "L 261.77054 -37.55625 \n",
       "L 261.351512 -37.55625 \n",
       "L 260.932488 -37.55625 \n",
       "L 260.513465 -37.55625 \n",
       "L 260.094441 -37.55625 \n",
       "L 259.675418 -37.55625 \n",
       "L 259.256395 -37.55625 \n",
       "L 258.837371 -37.55625 \n",
       "L 258.418348 -37.55625 \n",
       "L 257.99932 -37.55625 \n",
       "L 257.580296 -37.55625 \n",
       "L 257.161273 -37.55625 \n",
       "L 256.742249 -37.55625 \n",
       "L 256.323226 -37.55625 \n",
       "L 255.904203 -37.55625 \n",
       "L 255.485179 -37.55625 \n",
       "L 255.066161 -37.55625 \n",
       "L 254.647132 -37.55625 \n",
       "L 254.228109 -37.55625 \n",
       "L 253.809086 -37.55625 \n",
       "L 253.390062 -37.55625 \n",
       "L 252.971039 -37.55625 \n",
       "L 252.552016 -37.55625 \n",
       "L 252.132992 -37.55625 \n",
       "L 251.713969 -37.55625 \n",
       "L 251.29494 -37.55625 \n",
       "L 250.875917 -37.55625 \n",
       "L 250.456894 -37.55625 \n",
       "L 250.03787 -37.55625 \n",
       "L 249.618847 -37.55625 \n",
       "L 249.199824 -37.55625 \n",
       "L 248.7808 -37.55625 \n",
       "L 248.361777 -37.55625 \n",
       "L 247.942748 -37.55625 \n",
       "z\n",
       "\" style=\"stroke: #e377c2; stroke-opacity: 0.5\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#p71e3478c5c)\">\n",
       "     <use xlink:href=\"#m0a4cd2900d\" x=\"0\" y=\"222.954375\" style=\"fill: #e377c2; fill-opacity: 0.5; stroke: #e377c2; stroke-opacity: 0.5\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"PolyCollection_8\">\n",
       "    <defs>\n",
       "     <path id=\"m18a7d08777\" d=\"M 283.559771 -37.55625 \n",
       "L 283.559771 -39.716662 \n",
       "L 283.978794 -39.700477 \n",
       "L 284.397817 -39.684367 \n",
       "L 284.816841 -39.668333 \n",
       "L 285.235869 -39.652375 \n",
       "L 285.654893 -39.636494 \n",
       "L 286.073916 -39.620689 \n",
       "L 286.492939 -39.604962 \n",
       "L 286.911963 -39.589313 \n",
       "L 287.330986 -39.573741 \n",
       "L 287.750009 -39.558249 \n",
       "L 288.169033 -39.542835 \n",
       "L 288.588056 -39.5275 \n",
       "L 289.00708 -39.512245 \n",
       "L 289.426103 -39.497069 \n",
       "L 289.845126 -39.481974 \n",
       "L 290.26415 -39.466959 \n",
       "L 290.683173 -39.452024 \n",
       "L 291.102196 -39.43717 \n",
       "L 291.52122 -39.422397 \n",
       "L 291.940243 -39.407705 \n",
       "L 292.359277 -39.393094 \n",
       "L 292.7783 -39.378565 \n",
       "L 293.197323 -39.364118 \n",
       "L 293.616347 -39.349752 \n",
       "L 294.03537 -39.335468 \n",
       "L 294.454393 -39.321267 \n",
       "L 294.873417 -39.307148 \n",
       "L 295.29244 -39.29311 \n",
       "L 295.711464 -39.279156 \n",
       "L 296.130487 -39.265283 \n",
       "L 296.54951 -39.251493 \n",
       "L 296.968534 -39.237786 \n",
       "L 297.387557 -39.224161 \n",
       "L 297.806581 -39.210618 \n",
       "L 298.225604 -39.197159 \n",
       "L 298.644627 -39.183781 \n",
       "L 299.063651 -39.170486 \n",
       "L 299.482674 -39.157274 \n",
       "L 299.901697 -39.144144 \n",
       "L 300.320721 -39.131097 \n",
       "L 300.739744 -39.118132 \n",
       "L 301.158768 -39.105249 \n",
       "L 301.577791 -39.092449 \n",
       "L 301.996814 -39.07973 \n",
       "L 302.415848 -39.067094 \n",
       "L 302.834871 -39.05454 \n",
       "L 303.253894 -39.042067 \n",
       "L 303.672918 -39.029677 \n",
       "L 304.091941 -39.017368 \n",
       "L 304.510965 -39.00514 \n",
       "L 304.929988 -38.992994 \n",
       "L 305.349011 -38.980929 \n",
       "L 305.768035 -38.968945 \n",
       "L 306.187058 -38.957041 \n",
       "L 306.606081 -38.945219 \n",
       "L 307.025105 -38.933476 \n",
       "L 307.444128 -38.921815 \n",
       "L 307.863152 -38.910233 \n",
       "L 308.282175 -38.898731 \n",
       "L 308.701198 -38.887308 \n",
       "L 309.120222 -38.875966 \n",
       "L 309.539245 -38.864702 \n",
       "L 309.958269 -38.853518 \n",
       "L 310.377292 -38.842412 \n",
       "L 310.796315 -38.831385 \n",
       "L 311.215339 -38.820435 \n",
       "L 311.634362 -38.809564 \n",
       "L 312.053385 -38.798771 \n",
       "L 312.472419 -38.788055 \n",
       "L 312.891442 -38.777417 \n",
       "L 313.310466 -38.766855 \n",
       "L 313.729489 -38.75637 \n",
       "L 314.148512 -38.745962 \n",
       "L 314.567536 -38.735629 \n",
       "L 314.986559 -38.725373 \n",
       "L 315.405582 -38.715192 \n",
       "L 315.824606 -38.705086 \n",
       "L 316.243629 -38.695055 \n",
       "L 316.662653 -38.685099 \n",
       "L 317.081676 -38.675217 \n",
       "L 317.500699 -38.665409 \n",
       "L 317.919723 -38.655674 \n",
       "L 318.338746 -38.646013 \n",
       "L 318.757769 -38.636425 \n",
       "L 319.176793 -38.62691 \n",
       "L 319.595816 -38.617467 \n",
       "L 320.01484 -38.608096 \n",
       "L 320.433863 -38.598797 \n",
       "L 320.852886 -38.589569 \n",
       "L 321.27191 -38.580412 \n",
       "L 321.690933 -38.571326 \n",
       "L 322.109957 -38.56231 \n",
       "L 322.52899 -38.553364 \n",
       "L 322.948013 -38.544487 \n",
       "L 323.367037 -38.53568 \n",
       "L 323.78606 -38.526941 \n",
       "L 324.205083 -38.518272 \n",
       "L 324.624107 -38.50967 \n",
       "L 325.04313 -38.501136 \n",
       "L 325.462154 -38.49267 \n",
       "L 325.881177 -38.484271 \n",
       "L 326.3002 -38.475938 \n",
       "L 326.719224 -38.467672 \n",
       "L 327.138247 -38.459472 \n",
       "L 327.55727 -38.451338 \n",
       "L 327.976294 -38.443268 \n",
       "L 328.395317 -38.435264 \n",
       "L 328.814341 -38.427324 \n",
       "L 329.233364 -38.419448 \n",
       "L 329.652387 -38.411636 \n",
       "L 330.071411 -38.403887 \n",
       "L 330.490434 -38.396202 \n",
       "L 330.909457 -38.388579 \n",
       "L 331.328481 -38.381018 \n",
       "L 331.747504 -38.373519 \n",
       "L 332.166528 -38.366082 \n",
       "L 332.585551 -38.358705 \n",
       "L 333.004574 -38.35139 \n",
       "L 333.423598 -38.344135 \n",
       "L 333.842621 -38.33694 \n",
       "L 334.261645 -38.329804 \n",
       "L 334.680668 -38.322728 \n",
       "L 335.099691 -38.31571 \n",
       "L 335.518715 -38.308751 \n",
       "L 335.937748 -38.30185 \n",
       "L 336.356771 -38.295007 \n",
       "L 336.775795 -38.288221 \n",
       "L 337.194818 -38.281492 \n",
       "L 337.613842 -38.27482 \n",
       "L 338.032865 -38.268204 \n",
       "L 338.451888 -38.261644 \n",
       "L 338.870912 -38.255139 \n",
       "L 339.289935 -38.24869 \n",
       "L 339.708958 -38.242295 \n",
       "L 340.127982 -38.235954 \n",
       "L 340.547005 -38.229668 \n",
       "L 340.966029 -38.223435 \n",
       "L 341.385052 -38.217255 \n",
       "L 341.804075 -38.211128 \n",
       "L 342.223099 -38.205054 \n",
       "L 342.642122 -38.199032 \n",
       "L 343.061145 -38.193061 \n",
       "L 343.480169 -38.187142 \n",
       "L 343.899192 -38.181274 \n",
       "L 344.318216 -38.175457 \n",
       "L 344.737239 -38.16969 \n",
       "L 345.156262 -38.163973 \n",
       "L 345.575286 -38.158305 \n",
       "L 345.994319 -38.152687 \n",
       "L 346.413343 -38.147118 \n",
       "L 346.832366 -38.141597 \n",
       "L 347.251389 -38.136124 \n",
       "L 347.670413 -38.130699 \n",
       "L 348.089436 -38.125322 \n",
       "L 348.508459 -38.119991 \n",
       "L 348.927483 -38.114708 \n",
       "L 349.346506 -38.10947 \n",
       "L 349.76553 -38.104279 \n",
       "L 350.184553 -38.099134 \n",
       "L 350.603576 -38.094034 \n",
       "L 351.0226 -38.088979 \n",
       "L 351.441623 -38.083968 \n",
       "L 351.860646 -38.079002 \n",
       "L 352.27967 -38.07408 \n",
       "L 352.698693 -38.069202 \n",
       "L 353.117717 -38.064367 \n",
       "L 353.53674 -38.059575 \n",
       "L 353.955763 -38.054825 \n",
       "L 354.374787 -38.050118 \n",
       "L 354.79381 -38.045453 \n",
       "L 355.212833 -38.04083 \n",
       "L 355.631857 -38.036248 \n",
       "L 356.05089 -38.031707 \n",
       "L 356.469914 -38.027206 \n",
       "L 356.888937 -38.022746 \n",
       "L 357.30796 -38.018327 \n",
       "L 357.726984 -38.013946 \n",
       "L 358.146007 -38.009606 \n",
       "L 358.565031 -38.005304 \n",
       "L 358.984054 -38.001041 \n",
       "L 359.403077 -37.996817 \n",
       "L 359.822101 -37.992631 \n",
       "L 360.241124 -37.988483 \n",
       "L 360.660147 -37.984372 \n",
       "L 361.079171 -37.980299 \n",
       "L 361.498194 -37.976262 \n",
       "L 361.917218 -37.972262 \n",
       "L 362.336241 -37.968299 \n",
       "L 362.755264 -37.964371 \n",
       "L 363.174288 -37.96048 \n",
       "L 363.593311 -37.956624 \n",
       "L 364.012334 -37.952803 \n",
       "L 364.431358 -37.949017 \n",
       "L 364.850381 -37.945265 \n",
       "L 365.269405 -37.941548 \n",
       "L 365.688428 -37.937865 \n",
       "L 366.107461 -37.934215 \n",
       "L 366.526485 -37.930599 \n",
       "L 366.945508 -37.927017 \n",
       "L 367.364531 -37.923467 \n",
       "L 367.783555 -37.91995 \n",
       "L 368.202578 -37.916465 \n",
       "L 368.621602 -37.913012 \n",
       "L 369.040625 -37.909591 \n",
       "L 369.040625 -37.55625 \n",
       "L 369.040625 -37.55625 \n",
       "L 368.621602 -37.55625 \n",
       "L 368.202578 -37.55625 \n",
       "L 367.783555 -37.55625 \n",
       "L 367.364531 -37.55625 \n",
       "L 366.945508 -37.55625 \n",
       "L 366.526485 -37.55625 \n",
       "L 366.107461 -37.55625 \n",
       "L 365.688428 -37.55625 \n",
       "L 365.269405 -37.55625 \n",
       "L 364.850381 -37.55625 \n",
       "L 364.431358 -37.55625 \n",
       "L 364.012334 -37.55625 \n",
       "L 363.593311 -37.55625 \n",
       "L 363.174288 -37.55625 \n",
       "L 362.755264 -37.55625 \n",
       "L 362.336241 -37.55625 \n",
       "L 361.917218 -37.55625 \n",
       "L 361.498194 -37.55625 \n",
       "L 361.079171 -37.55625 \n",
       "L 360.660147 -37.55625 \n",
       "L 360.241124 -37.55625 \n",
       "L 359.822101 -37.55625 \n",
       "L 359.403077 -37.55625 \n",
       "L 358.984054 -37.55625 \n",
       "L 358.565031 -37.55625 \n",
       "L 358.146007 -37.55625 \n",
       "L 357.726984 -37.55625 \n",
       "L 357.30796 -37.55625 \n",
       "L 356.888937 -37.55625 \n",
       "L 356.469914 -37.55625 \n",
       "L 356.05089 -37.55625 \n",
       "L 355.631857 -37.55625 \n",
       "L 355.212833 -37.55625 \n",
       "L 354.79381 -37.55625 \n",
       "L 354.374787 -37.55625 \n",
       "L 353.955763 -37.55625 \n",
       "L 353.53674 -37.55625 \n",
       "L 353.117717 -37.55625 \n",
       "L 352.698693 -37.55625 \n",
       "L 352.27967 -37.55625 \n",
       "L 351.860646 -37.55625 \n",
       "L 351.441623 -37.55625 \n",
       "L 351.0226 -37.55625 \n",
       "L 350.603576 -37.55625 \n",
       "L 350.184553 -37.55625 \n",
       "L 349.76553 -37.55625 \n",
       "L 349.346506 -37.55625 \n",
       "L 348.927483 -37.55625 \n",
       "L 348.508459 -37.55625 \n",
       "L 348.089436 -37.55625 \n",
       "L 347.670413 -37.55625 \n",
       "L 347.251389 -37.55625 \n",
       "L 346.832366 -37.55625 \n",
       "L 346.413343 -37.55625 \n",
       "L 345.994319 -37.55625 \n",
       "L 345.575286 -37.55625 \n",
       "L 345.156262 -37.55625 \n",
       "L 344.737239 -37.55625 \n",
       "L 344.318216 -37.55625 \n",
       "L 343.899192 -37.55625 \n",
       "L 343.480169 -37.55625 \n",
       "L 343.061145 -37.55625 \n",
       "L 342.642122 -37.55625 \n",
       "L 342.223099 -37.55625 \n",
       "L 341.804075 -37.55625 \n",
       "L 341.385052 -37.55625 \n",
       "L 340.966029 -37.55625 \n",
       "L 340.547005 -37.55625 \n",
       "L 340.127982 -37.55625 \n",
       "L 339.708958 -37.55625 \n",
       "L 339.289935 -37.55625 \n",
       "L 338.870912 -37.55625 \n",
       "L 338.451888 -37.55625 \n",
       "L 338.032865 -37.55625 \n",
       "L 337.613842 -37.55625 \n",
       "L 337.194818 -37.55625 \n",
       "L 336.775795 -37.55625 \n",
       "L 336.356771 -37.55625 \n",
       "L 335.937748 -37.55625 \n",
       "L 335.518715 -37.55625 \n",
       "L 335.099691 -37.55625 \n",
       "L 334.680668 -37.55625 \n",
       "L 334.261645 -37.55625 \n",
       "L 333.842621 -37.55625 \n",
       "L 333.423598 -37.55625 \n",
       "L 333.004574 -37.55625 \n",
       "L 332.585551 -37.55625 \n",
       "L 332.166528 -37.55625 \n",
       "L 331.747504 -37.55625 \n",
       "L 331.328481 -37.55625 \n",
       "L 330.909457 -37.55625 \n",
       "L 330.490434 -37.55625 \n",
       "L 330.071411 -37.55625 \n",
       "L 329.652387 -37.55625 \n",
       "L 329.233364 -37.55625 \n",
       "L 328.814341 -37.55625 \n",
       "L 328.395317 -37.55625 \n",
       "L 327.976294 -37.55625 \n",
       "L 327.55727 -37.55625 \n",
       "L 327.138247 -37.55625 \n",
       "L 326.719224 -37.55625 \n",
       "L 326.3002 -37.55625 \n",
       "L 325.881177 -37.55625 \n",
       "L 325.462154 -37.55625 \n",
       "L 325.04313 -37.55625 \n",
       "L 324.624107 -37.55625 \n",
       "L 324.205083 -37.55625 \n",
       "L 323.78606 -37.55625 \n",
       "L 323.367037 -37.55625 \n",
       "L 322.948013 -37.55625 \n",
       "L 322.52899 -37.55625 \n",
       "L 322.109957 -37.55625 \n",
       "L 321.690933 -37.55625 \n",
       "L 321.27191 -37.55625 \n",
       "L 320.852886 -37.55625 \n",
       "L 320.433863 -37.55625 \n",
       "L 320.01484 -37.55625 \n",
       "L 319.595816 -37.55625 \n",
       "L 319.176793 -37.55625 \n",
       "L 318.757769 -37.55625 \n",
       "L 318.338746 -37.55625 \n",
       "L 317.919723 -37.55625 \n",
       "L 317.500699 -37.55625 \n",
       "L 317.081676 -37.55625 \n",
       "L 316.662653 -37.55625 \n",
       "L 316.243629 -37.55625 \n",
       "L 315.824606 -37.55625 \n",
       "L 315.405582 -37.55625 \n",
       "L 314.986559 -37.55625 \n",
       "L 314.567536 -37.55625 \n",
       "L 314.148512 -37.55625 \n",
       "L 313.729489 -37.55625 \n",
       "L 313.310466 -37.55625 \n",
       "L 312.891442 -37.55625 \n",
       "L 312.472419 -37.55625 \n",
       "L 312.053385 -37.55625 \n",
       "L 311.634362 -37.55625 \n",
       "L 311.215339 -37.55625 \n",
       "L 310.796315 -37.55625 \n",
       "L 310.377292 -37.55625 \n",
       "L 309.958269 -37.55625 \n",
       "L 309.539245 -37.55625 \n",
       "L 309.120222 -37.55625 \n",
       "L 308.701198 -37.55625 \n",
       "L 308.282175 -37.55625 \n",
       "L 307.863152 -37.55625 \n",
       "L 307.444128 -37.55625 \n",
       "L 307.025105 -37.55625 \n",
       "L 306.606081 -37.55625 \n",
       "L 306.187058 -37.55625 \n",
       "L 305.768035 -37.55625 \n",
       "L 305.349011 -37.55625 \n",
       "L 304.929988 -37.55625 \n",
       "L 304.510965 -37.55625 \n",
       "L 304.091941 -37.55625 \n",
       "L 303.672918 -37.55625 \n",
       "L 303.253894 -37.55625 \n",
       "L 302.834871 -37.55625 \n",
       "L 302.415848 -37.55625 \n",
       "L 301.996814 -37.55625 \n",
       "L 301.577791 -37.55625 \n",
       "L 301.158768 -37.55625 \n",
       "L 300.739744 -37.55625 \n",
       "L 300.320721 -37.55625 \n",
       "L 299.901697 -37.55625 \n",
       "L 299.482674 -37.55625 \n",
       "L 299.063651 -37.55625 \n",
       "L 298.644627 -37.55625 \n",
       "L 298.225604 -37.55625 \n",
       "L 297.806581 -37.55625 \n",
       "L 297.387557 -37.55625 \n",
       "L 296.968534 -37.55625 \n",
       "L 296.54951 -37.55625 \n",
       "L 296.130487 -37.55625 \n",
       "L 295.711464 -37.55625 \n",
       "L 295.29244 -37.55625 \n",
       "L 294.873417 -37.55625 \n",
       "L 294.454393 -37.55625 \n",
       "L 294.03537 -37.55625 \n",
       "L 293.616347 -37.55625 \n",
       "L 293.197323 -37.55625 \n",
       "L 292.7783 -37.55625 \n",
       "L 292.359277 -37.55625 \n",
       "L 291.940243 -37.55625 \n",
       "L 291.52122 -37.55625 \n",
       "L 291.102196 -37.55625 \n",
       "L 290.683173 -37.55625 \n",
       "L 290.26415 -37.55625 \n",
       "L 289.845126 -37.55625 \n",
       "L 289.426103 -37.55625 \n",
       "L 289.00708 -37.55625 \n",
       "L 288.588056 -37.55625 \n",
       "L 288.169033 -37.55625 \n",
       "L 287.750009 -37.55625 \n",
       "L 287.330986 -37.55625 \n",
       "L 286.911963 -37.55625 \n",
       "L 286.492939 -37.55625 \n",
       "L 286.073916 -37.55625 \n",
       "L 285.654893 -37.55625 \n",
       "L 285.235869 -37.55625 \n",
       "L 284.816841 -37.55625 \n",
       "L 284.397817 -37.55625 \n",
       "L 283.978794 -37.55625 \n",
       "L 283.559771 -37.55625 \n",
       "z\n",
       "\" style=\"stroke: #7f7f7f; stroke-opacity: 0.5\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#p71e3478c5c)\">\n",
       "     <use xlink:href=\"#m18a7d08777\" x=\"0\" y=\"222.954375\" style=\"fill: #7f7f7f; fill-opacity: 0.5; stroke: #7f7f7f; stroke-opacity: 0.5\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_1\">\n",
       "    <path d=\"M 34.240625 185.398125 \n",
       "L 34.240625 183.298412 \n",
       "\" clip-path=\"url(#p71e3478c5c)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 2; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_2\">\n",
       "    <path d=\"M 120.140498 185.398125 \n",
       "L 120.140498 172.435657 \n",
       "\" clip-path=\"url(#p71e3478c5c)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 2; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_3\">\n",
       "    <path d=\"M 120.559521 185.398125 \n",
       "L 120.559521 150.571387 \n",
       "\" clip-path=\"url(#p71e3478c5c)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 2; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_4\">\n",
       "    <path d=\"M 155.75752 185.398125 \n",
       "L 155.75752 126.000212 \n",
       "\" clip-path=\"url(#p71e3478c5c)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 2; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_5\">\n",
       "    <path d=\"M 156.176543 185.398125 \n",
       "L 156.176543 66.008471 \n",
       "\" clip-path=\"url(#p71e3478c5c)\" style=\"fill: none; stroke: #2ca02c; stroke-width: 2; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_6\">\n",
       "    <path d=\"M 180.060901 185.398125 \n",
       "L 180.060901 37.14358 \n",
       "\" clip-path=\"url(#p71e3478c5c)\" style=\"fill: none; stroke: #2ca02c; stroke-width: 2; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_7\">\n",
       "    <path d=\"M 180.479924 185.398125 \n",
       "L 180.479924 111.083851 \n",
       "\" clip-path=\"url(#p71e3478c5c)\" style=\"fill: none; stroke: #d62728; stroke-width: 2; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_8\">\n",
       "    <path d=\"M 201.431113 185.398125 \n",
       "L 201.431113 106.147901 \n",
       "\" clip-path=\"url(#p71e3478c5c)\" style=\"fill: none; stroke: #d62728; stroke-width: 2; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_9\">\n",
       "    <path d=\"M 201.850137 185.398125 \n",
       "L 201.850137 155.678547 \n",
       "\" clip-path=\"url(#p71e3478c5c)\" style=\"fill: none; stroke: #9467bd; stroke-width: 2; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_10\">\n",
       "    <path d=\"M 223.220349 185.398125 \n",
       "L 223.220349 157.530272 \n",
       "\" clip-path=\"url(#p71e3478c5c)\" style=\"fill: none; stroke: #9467bd; stroke-width: 2; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_11\">\n",
       "    <path d=\"M 223.639372 185.398125 \n",
       "L 223.639372 176.132216 \n",
       "\" clip-path=\"url(#p71e3478c5c)\" style=\"fill: none; stroke: #8c564b; stroke-width: 2; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_12\">\n",
       "    <path d=\"M 247.523725 185.398125 \n",
       "L 247.523725 177.936271 \n",
       "\" clip-path=\"url(#p71e3478c5c)\" style=\"fill: none; stroke: #8c564b; stroke-width: 2; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_13\">\n",
       "    <path d=\"M 247.942748 185.398125 \n",
       "L 247.942748 181.685755 \n",
       "\" clip-path=\"url(#p71e3478c5c)\" style=\"fill: none; stroke: #e377c2; stroke-width: 2; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_14\">\n",
       "    <path d=\"M 283.140747 185.398125 \n",
       "L 283.140747 183.221453 \n",
       "\" clip-path=\"url(#p71e3478c5c)\" style=\"fill: none; stroke: #e377c2; stroke-width: 2; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_15\">\n",
       "    <path d=\"M 283.559771 185.398125 \n",
       "L 283.559771 183.237713 \n",
       "\" clip-path=\"url(#p71e3478c5c)\" style=\"fill: none; stroke: #7f7f7f; stroke-width: 2; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_16\">\n",
       "    <path d=\"M 369.040625 185.398125 \n",
       "L 369.040625 185.044784 \n",
       "\" clip-path=\"url(#p71e3478c5c)\" style=\"fill: none; stroke: #7f7f7f; stroke-width: 2; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_17\">\n",
       "    <path d=\"M 34.240625 183.298412 \n",
       "L 48.068407 182.518138 \n",
       "L 60.220095 181.612772 \n",
       "L 71.114722 180.583393 \n",
       "L 81.171283 179.415444 \n",
       "L 90.808831 178.071125 \n",
       "L 100.027356 176.557562 \n",
       "L 108.826857 174.892737 \n",
       "L 118.045381 172.916667 \n",
       "L 120.140498 172.435657 \n",
       "L 120.559521 150.571387 \n",
       "L 126.844877 146.531917 \n",
       "L 133.968284 141.67873 \n",
       "L 142.76778 135.397518 \n",
       "L 155.75752 126.000212 \n",
       "L 156.176543 66.008471 \n",
       "L 162.042878 57.892048 \n",
       "L 166.65214 51.866671 \n",
       "L 170.842377 46.755917 \n",
       "L 174.61359 42.523685 \n",
       "L 177.965782 39.101859 \n",
       "L 180.060901 37.14358 \n",
       "L 180.479924 111.083851 \n",
       "L 184.251139 109.540704 \n",
       "L 187.603328 108.392882 \n",
       "L 190.955519 107.470333 \n",
       "L 194.307709 106.784409 \n",
       "L 197.659899 106.343721 \n",
       "L 201.012089 106.153843 \n",
       "L 201.431113 106.147901 \n",
       "L 201.850137 155.678547 \n",
       "L 206.878422 155.785282 \n",
       "L 211.906707 156.102433 \n",
       "L 217.354017 156.672933 \n",
       "L 222.801326 157.461281 \n",
       "L 223.220349 157.530272 \n",
       "L 223.639372 176.132216 \n",
       "L 234.533993 176.857793 \n",
       "L 247.523725 177.936271 \n",
       "L 247.942748 181.685755 \n",
       "L 293.616347 183.604623 \n",
       "L 315.405582 184.239183 \n",
       "L 339.289935 184.705685 \n",
       "L 368.202578 185.03791 \n",
       "L 369.040625 185.044784 \n",
       "L 369.040625 185.044784 \n",
       "\" clip-path=\"url(#p71e3478c5c)\" style=\"fill: none; stroke: #000000; stroke-width: 2; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 34.240625 185.398125 \n",
       "L 34.240625 22.318125 \n",
       "\" style=\"fill: none; stroke: #262626; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 369.040625 185.398125 \n",
       "L 369.040625 22.318125 \n",
       "\" style=\"fill: none; stroke: #262626; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 34.240625 185.398125 \n",
       "L 369.040625 185.398125 \n",
       "\" style=\"fill: none; stroke: #262626; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 34.240625 22.318125 \n",
       "L 369.040625 22.318125 \n",
       "\" style=\"fill: none; stroke: #262626; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_19\">\n",
       "    <!-- Dequantization distribution for 8 discrete values -->\n",
       "    <g style=\"fill: #262626\" transform=\"translate(56.623438 16.318125)scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-44\" d=\"M 1259 4147 \n",
       "L 1259 519 \n",
       "L 2022 519 \n",
       "Q 2988 519 3436 956 \n",
       "Q 3884 1394 3884 2338 \n",
       "Q 3884 3275 3436 3711 \n",
       "Q 2988 4147 2022 4147 \n",
       "L 1259 4147 \n",
       "z\n",
       "M 628 4666 \n",
       "L 1925 4666 \n",
       "Q 3281 4666 3915 4102 \n",
       "Q 4550 3538 4550 2338 \n",
       "Q 4550 1131 3912 565 \n",
       "Q 3275 0 1925 0 \n",
       "L 628 0 \n",
       "L 628 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-71\" d=\"M 947 1747 \n",
       "Q 947 1113 1208 752 \n",
       "Q 1469 391 1925 391 \n",
       "Q 2381 391 2643 752 \n",
       "Q 2906 1113 2906 1747 \n",
       "Q 2906 2381 2643 2742 \n",
       "Q 2381 3103 1925 3103 \n",
       "Q 1469 3103 1208 2742 \n",
       "Q 947 2381 947 1747 \n",
       "z\n",
       "M 2906 525 \n",
       "Q 2725 213 2448 61 \n",
       "Q 2172 -91 1784 -91 \n",
       "Q 1150 -91 751 415 \n",
       "Q 353 922 353 1747 \n",
       "Q 353 2572 751 3078 \n",
       "Q 1150 3584 1784 3584 \n",
       "Q 2172 3584 2448 3432 \n",
       "Q 2725 3281 2906 2969 \n",
       "L 2906 3500 \n",
       "L 3481 3500 \n",
       "L 3481 -1331 \n",
       "L 2906 -1331 \n",
       "L 2906 525 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-75\" d=\"M 544 1381 \n",
       "L 544 3500 \n",
       "L 1119 3500 \n",
       "L 1119 1403 \n",
       "Q 1119 906 1312 657 \n",
       "Q 1506 409 1894 409 \n",
       "Q 2359 409 2629 706 \n",
       "Q 2900 1003 2900 1516 \n",
       "L 2900 3500 \n",
       "L 3475 3500 \n",
       "L 3475 0 \n",
       "L 2900 0 \n",
       "L 2900 538 \n",
       "Q 2691 219 2414 64 \n",
       "Q 2138 -91 1772 -91 \n",
       "Q 1169 -91 856 284 \n",
       "Q 544 659 544 1381 \n",
       "z\n",
       "M 1991 3584 \n",
       "L 1991 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \n",
       "L 2906 4863 \n",
       "L 3481 4863 \n",
       "L 3481 0 \n",
       "L 2906 0 \n",
       "L 2906 525 \n",
       "Q 2725 213 2448 61 \n",
       "Q 2172 -91 1784 -91 \n",
       "Q 1150 -91 751 415 \n",
       "Q 353 922 353 1747 \n",
       "Q 353 2572 751 3078 \n",
       "Q 1150 3584 1784 3584 \n",
       "Q 2172 3584 2448 3432 \n",
       "Q 2725 3281 2906 2969 \n",
       "z\n",
       "M 947 1747 \n",
       "Q 947 1113 1208 752 \n",
       "Q 1469 391 1925 391 \n",
       "Q 2381 391 2643 752 \n",
       "Q 2906 1113 2906 1747 \n",
       "Q 2906 2381 2643 2742 \n",
       "Q 2381 3103 1925 3103 \n",
       "Q 1469 3103 1208 2742 \n",
       "Q 947 2381 947 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
       "L 2834 2853 \n",
       "Q 2591 2978 2328 3040 \n",
       "Q 2066 3103 1784 3103 \n",
       "Q 1356 3103 1142 2972 \n",
       "Q 928 2841 928 2578 \n",
       "Q 928 2378 1081 2264 \n",
       "Q 1234 2150 1697 2047 \n",
       "L 1894 2003 \n",
       "Q 2506 1872 2764 1633 \n",
       "Q 3022 1394 3022 966 \n",
       "Q 3022 478 2636 193 \n",
       "Q 2250 -91 1575 -91 \n",
       "Q 1294 -91 989 -36 \n",
       "Q 684 19 347 128 \n",
       "L 347 722 \n",
       "Q 666 556 975 473 \n",
       "Q 1284 391 1588 391 \n",
       "Q 1994 391 2212 530 \n",
       "Q 2431 669 2431 922 \n",
       "Q 2431 1156 2273 1281 \n",
       "Q 2116 1406 1581 1522 \n",
       "L 1381 1569 \n",
       "Q 847 1681 609 1914 \n",
       "Q 372 2147 372 2553 \n",
       "Q 372 3047 722 3315 \n",
       "Q 1072 3584 1716 3584 \n",
       "Q 2034 3584 2315 3537 \n",
       "Q 2597 3491 2834 3397 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-66\" d=\"M 2375 4863 \n",
       "L 2375 4384 \n",
       "L 1825 4384 \n",
       "Q 1516 4384 1395 4259 \n",
       "Q 1275 4134 1275 3809 \n",
       "L 1275 3500 \n",
       "L 2222 3500 \n",
       "L 2222 3053 \n",
       "L 1275 3053 \n",
       "L 1275 0 \n",
       "L 697 0 \n",
       "L 697 3053 \n",
       "L 147 3053 \n",
       "L 147 3500 \n",
       "L 697 3500 \n",
       "L 697 3744 \n",
       "Q 697 4328 969 4595 \n",
       "Q 1241 4863 1831 4863 \n",
       "L 2375 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \n",
       "Q 1584 2216 1326 1975 \n",
       "Q 1069 1734 1069 1313 \n",
       "Q 1069 891 1326 650 \n",
       "Q 1584 409 2034 409 \n",
       "Q 2484 409 2743 651 \n",
       "Q 3003 894 3003 1313 \n",
       "Q 3003 1734 2745 1975 \n",
       "Q 2488 2216 2034 2216 \n",
       "z\n",
       "M 1403 2484 \n",
       "Q 997 2584 770 2862 \n",
       "Q 544 3141 544 3541 \n",
       "Q 544 4100 942 4425 \n",
       "Q 1341 4750 2034 4750 \n",
       "Q 2731 4750 3128 4425 \n",
       "Q 3525 4100 3525 3541 \n",
       "Q 3525 3141 3298 2862 \n",
       "Q 3072 2584 2669 2484 \n",
       "Q 3125 2378 3379 2068 \n",
       "Q 3634 1759 3634 1313 \n",
       "Q 3634 634 3220 271 \n",
       "Q 2806 -91 2034 -91 \n",
       "Q 1263 -91 848 271 \n",
       "Q 434 634 434 1313 \n",
       "Q 434 1759 690 2068 \n",
       "Q 947 2378 1403 2484 \n",
       "z\n",
       "M 1172 3481 \n",
       "Q 1172 3119 1398 2916 \n",
       "Q 1625 2713 2034 2713 \n",
       "Q 2441 2713 2670 2916 \n",
       "Q 2900 3119 2900 3481 \n",
       "Q 2900 3844 2670 4047 \n",
       "Q 2441 4250 2034 4250 \n",
       "Q 1625 4250 1398 4047 \n",
       "Q 1172 3844 1172 3481 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \n",
       "L 3122 2828 \n",
       "Q 2878 2963 2633 3030 \n",
       "Q 2388 3097 2138 3097 \n",
       "Q 1578 3097 1268 2742 \n",
       "Q 959 2388 959 1747 \n",
       "Q 959 1106 1268 751 \n",
       "Q 1578 397 2138 397 \n",
       "Q 2388 397 2633 464 \n",
       "Q 2878 531 3122 666 \n",
       "L 3122 134 \n",
       "Q 2881 22 2623 -34 \n",
       "Q 2366 -91 2075 -91 \n",
       "Q 1284 -91 818 406 \n",
       "Q 353 903 353 1747 \n",
       "Q 353 2603 823 3093 \n",
       "Q 1294 3584 2113 3584 \n",
       "Q 2378 3584 2631 3529 \n",
       "Q 2884 3475 3122 3366 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-76\" d=\"M 191 3500 \n",
       "L 800 3500 \n",
       "L 1894 563 \n",
       "L 2988 3500 \n",
       "L 3597 3500 \n",
       "L 2284 0 \n",
       "L 1503 0 \n",
       "L 191 3500 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-44\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"77.001953\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-71\" x=\"138.525391\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-75\" x=\"202.001953\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"265.380859\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6e\" x=\"326.660156\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-74\" x=\"390.039062\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" x=\"429.248047\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-7a\" x=\"457.03125\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"509.521484\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-74\" x=\"570.800781\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" x=\"610.009766\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"637.792969\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6e\" x=\"698.974609\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"762.353516\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-64\" x=\"794.140625\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" x=\"857.617188\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-73\" x=\"885.400391\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-74\" x=\"937.5\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"976.708984\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" x=\"1017.822266\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-62\" x=\"1045.605469\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-75\" x=\"1109.082031\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-74\" x=\"1172.460938\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" x=\"1211.669922\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"1239.453125\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6e\" x=\"1300.634766\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"1364.013672\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-66\" x=\"1395.800781\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"1431.005859\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"1492.1875\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"1533.300781\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-38\" x=\"1565.087891\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"1628.710938\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-64\" x=\"1660.498047\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" x=\"1723.974609\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-73\" x=\"1751.757812\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-63\" x=\"1803.857422\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"1858.837891\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"1897.701172\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-74\" x=\"1959.224609\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"1998.433594\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"2059.957031\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-76\" x=\"2091.744141\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"2150.923828\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"2212.203125\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-75\" x=\"2239.986328\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"2303.365234\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-73\" x=\"2364.888672\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 323.678125 147.743125 \n",
       "L 362.040625 147.743125 \n",
       "Q 364.040625 147.743125 364.040625 145.743125 \n",
       "L 364.040625 29.318125 \n",
       "Q 364.040625 27.318125 362.040625 27.318125 \n",
       "L 323.678125 27.318125 \n",
       "Q 321.678125 27.318125 321.678125 29.318125 \n",
       "L 321.678125 145.743125 \n",
       "Q 321.678125 147.743125 323.678125 147.743125 \n",
       "z\n",
       "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"patch_8\">\n",
       "     <path d=\"M 325.678125 38.916562 \n",
       "L 345.678125 38.916562 \n",
       "L 345.678125 31.916562 \n",
       "L 325.678125 31.916562 \n",
       "z\n",
       "\" style=\"fill: #1f77b4; fill-opacity: 0.5; stroke: #1f77b4; stroke-opacity: 0.5; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"text_20\">\n",
       "     <!-- 0 -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(353.678125 38.916562)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"patch_9\">\n",
       "     <path d=\"M 325.678125 53.594687 \n",
       "L 345.678125 53.594687 \n",
       "L 345.678125 46.594687 \n",
       "L 325.678125 46.594687 \n",
       "z\n",
       "\" style=\"fill: #ff7f0e; fill-opacity: 0.5; stroke: #ff7f0e; stroke-opacity: 0.5; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"text_21\">\n",
       "     <!-- 1 -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(353.678125 53.594687)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"patch_10\">\n",
       "     <path d=\"M 325.678125 68.272812 \n",
       "L 345.678125 68.272812 \n",
       "L 345.678125 61.272812 \n",
       "L 325.678125 61.272812 \n",
       "z\n",
       "\" style=\"fill: #2ca02c; fill-opacity: 0.5; stroke: #2ca02c; stroke-opacity: 0.5; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"text_22\">\n",
       "     <!-- 2 -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(353.678125 68.272812)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"patch_11\">\n",
       "     <path d=\"M 325.678125 82.950937 \n",
       "L 345.678125 82.950937 \n",
       "L 345.678125 75.950937 \n",
       "L 325.678125 75.950937 \n",
       "z\n",
       "\" style=\"fill: #d62728; fill-opacity: 0.5; stroke: #d62728; stroke-opacity: 0.5; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"text_23\">\n",
       "     <!-- 3 -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(353.678125 82.950937)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-33\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"patch_12\">\n",
       "     <path d=\"M 325.678125 97.629062 \n",
       "L 345.678125 97.629062 \n",
       "L 345.678125 90.629062 \n",
       "L 325.678125 90.629062 \n",
       "z\n",
       "\" style=\"fill: #9467bd; fill-opacity: 0.5; stroke: #9467bd; stroke-opacity: 0.5; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"text_24\">\n",
       "     <!-- 4 -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(353.678125 97.629062)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"patch_13\">\n",
       "     <path d=\"M 325.678125 112.307187 \n",
       "L 345.678125 112.307187 \n",
       "L 345.678125 105.307187 \n",
       "L 325.678125 105.307187 \n",
       "z\n",
       "\" style=\"fill: #8c564b; fill-opacity: 0.5; stroke: #8c564b; stroke-opacity: 0.5; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"text_25\">\n",
       "     <!-- 5 -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(353.678125 112.307187)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"patch_14\">\n",
       "     <path d=\"M 325.678125 126.985312 \n",
       "L 345.678125 126.985312 \n",
       "L 345.678125 119.985312 \n",
       "L 325.678125 119.985312 \n",
       "z\n",
       "\" style=\"fill: #e377c2; fill-opacity: 0.5; stroke: #e377c2; stroke-opacity: 0.5; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"text_26\">\n",
       "     <!-- 6 -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(353.678125 126.985312)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-36\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"patch_15\">\n",
       "     <path d=\"M 325.678125 141.663437 \n",
       "L 345.678125 141.663437 \n",
       "L 345.678125 134.663437 \n",
       "L 325.678125 134.663437 \n",
       "z\n",
       "\" style=\"fill: #7f7f7f; fill-opacity: 0.5; stroke: #7f7f7f; stroke-opacity: 0.5; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"text_27\">\n",
       "     <!-- 7 -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(353.678125 141.663437)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-37\" d=\"M 525 4666 \n",
       "L 3525 4666 \n",
       "L 3525 4397 \n",
       "L 1831 0 \n",
       "L 1172 0 \n",
       "L 2766 4134 \n",
       "L 525 4134 \n",
       "L 525 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-37\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p71e3478c5c\">\n",
       "   <rect x=\"34.240625\" y=\"22.318125\" width=\"334.8\" height=\"163.08\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 432x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_dequantization(quants=8, prior=np.array([0.075, 0.2, 0.4, 0.2, 0.075, 0.025, 0.0125, 0.0125]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming such a probability into a Gaussian is a difficult task, especially with such hard borders. Dequantization has therefore been extended to more sophisticated, learnable distributions beyond uniform in a variational framework. In particular, if we remember the learning objective $\\log p(x) = \\log \\mathbb{E}_{u}\\left[\\frac{p(x+u)}{q(u|x)} \\right]$, the uniform distribution can be replaced by a learned distribution $q_{\\theta}(u|x)$ with support over $u\\in[0,1)^D$. This approach is called Variational Dequantization and has been proposed by Ho et al. [3]. How can we learn such a distribution? We can use a second normalizing flow that takes $x$ as external input and learns a flexible distribution over $u$. To ensure a support over $[0,1)^D$, we can apply a sigmoid activation function as final flow transformation. \n",
    "\n",
    "Inheriting the original dequantization class, we can implement variational dequantization as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalDequantization(Dequantization):\n",
    "    \n",
    "    def __init__(self, var_flows, alpha=1e-5):\n",
    "        \"\"\"\n",
    "        Inputs: \n",
    "            var_flows - A list of flow transformations to use for modeling q(u|x)\n",
    "            alpha - Small constant, see Dequantization for details\n",
    "        \"\"\"\n",
    "        super().__init__(alpha=alpha)\n",
    "        self.flows = nn.ModuleList(var_flows)\n",
    "        \n",
    "    def dequant(self, z, ldj):\n",
    "        z = z.to(torch.float32)\n",
    "        img = (z / 255.0) * 2 - 1 # We condition the flows on x, i.e. the original image\n",
    "        \n",
    "        # Prior of u is a uniform distribution as before\n",
    "        # As most flow transformations are defined on [-infinity,+infinity], we apply an inverse sigmoid first.\n",
    "        deq_noise = torch.rand_like(z).detach()\n",
    "        deq_noise, ldj = self.sigmoid(deq_noise, ldj, reverse=True)\n",
    "        for flow in self.flows:\n",
    "            deq_noise, ldj = flow(deq_noise, ldj, reverse=False, orig_img=img)\n",
    "        deq_noise, ldj = self.sigmoid(deq_noise, ldj, reverse=False)\n",
    "        \n",
    "        # After the flows, apply u as in standard dequantization\n",
    "        z = (z + deq_noise) / 256.0\n",
    "        ldj -= np.log(256.0) * np.prod(z.shape[1:])\n",
    "        return z, ldj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variational dequantization can be used as a substitute for dequantization. We will compare dequantization and variational dequantization in later experiments. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coupling layers\n",
    "\n",
    "Next, we look at possible transformations to apply inside the flow. A recent popular flow layer, which works well in combination with deep neural networks, is the coupling layer introduced by Dinh et al. [1]. The input $z$ is arbitrarily split into two parts, $z_{1:j}$ and $z_{j+1:d}$, of which the first remains unchanged by the flow. Yet, $z_{1:j}$ is used to parameterize the transformation for the second part, $z_{j+1:d}$. Various transformations have been proposed in recent time [3,4], but here we will settle for the simplest and most efficient one: affine coupling. In this coupling layer, we apply an affine transformation by shifting the input by a bias $\\mu$ and scale it by $\\sigma$. In other words, our transformation looks as follows:\n",
    "\n",
    "$$z'_{j+1:d} = \\mu_{\\theta}(z_{1:j}) + \\sigma_{\\theta}(z_{1:j}) \\odot z_{j+1:d}$$\n",
    "\n",
    "The functions $\\mu$ and $\\sigma$ are implemented as a shared neural network, and the sum and multiplication are performed element-wise. The LDJ is thereby the sum of the logs of the scaling factors: $\\sum_i \\left[\\log \\sigma_{\\theta}(z_{1:j})\\right]_i$. Inverting the layer can as simply be done as subtracting the bias and dividing by the scale: \n",
    "\n",
    "$$z_{j+1:d} = \\left(z'_{j+1:d} - \\mu_{\\theta}(z_{1:j})\\right) / \\sigma_{\\theta}(z_{1:j})$$\n",
    "\n",
    "We can also visualize the coupling layer in form of a computation graph, where $z_1$ represents $z_{1:j}$, and $z_2$ represents $z_{j+1:d}$:\n",
    "\n",
    "<center width=\"100%\" style=\"padding: 10px\"><img src=\"coupling_flow.svg\" width=\"450px\"></center>\n",
    "\n",
    "In our implementation, we will realize the splitting of variables as masking. The variables to be transformed, $z_{j+1:d}$, are masked when passing $z$ to the shared network to predict the transformation parameters. When applying the transformation, we mask the parameters for $z_{1:j}$ so that we have an identity operation for those variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CouplingLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, network, mask, c_in):\n",
    "        \"\"\"\n",
    "        Coupling layer inside a normalizing flow.\n",
    "        Inputs:\n",
    "            network - A PyTorch nn.Module constituting the deep neural network for mu and sigma.\n",
    "                      Output shape should be twice the channel size as the input.\n",
    "            mask - Binary mask (0 or 1) where 0 denotes that the element should be transformed,\n",
    "                   while 1 means the latent will be used as input to the NN.\n",
    "            c_in - Number of input channels\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.network = network\n",
    "        self.scaling_factor = nn.Parameter(torch.zeros(c_in))\n",
    "        # Register mask as buffer as it is a tensor which is not a parameter, \n",
    "        # but should be part of the modules state.\n",
    "        self.register_buffer('mask', mask)\n",
    "    \n",
    "    def forward(self, z, ldj, reverse=False, orig_img=None):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            z - Latent input to the flow\n",
    "            ldj - The current ldj of the previous flows. \n",
    "                  The ldj of this layer will be added to this tensor.\n",
    "            reverse - If True, we apply the inverse of the layer.\n",
    "            orig_img (optional) - Only needed in VarDeq. Allows external\n",
    "                                  input to condition the flow on (e.g. original image)\n",
    "        \"\"\"\n",
    "        # Apply network to masked input\n",
    "        z_in = z * self.mask\n",
    "        if orig_img is None:\n",
    "            nn_out = self.network(z_in)\n",
    "        else:\n",
    "            nn_out = self.network(torch.cat([z_in, orig_img], dim=1))\n",
    "        s, t = nn_out.chunk(2, dim=1)\n",
    "        \n",
    "        # Stabilize scaling output\n",
    "        s_fac = self.scaling_factor.exp().view(1, -1, 1, 1)\n",
    "        s = torch.tanh(s / s_fac) * s_fac\n",
    "        \n",
    "        # Mask outputs (only transform the second part)\n",
    "        s = s * (1 - self.mask)\n",
    "        t = t * (1 - self.mask)\n",
    "        \n",
    "        # Affine transformation\n",
    "        if not reverse:\n",
    "            # Whether we first shift and then scale, or the other way round,\n",
    "            # is a design choice, and usually does not have a big impact\n",
    "            z = (z + t) * torch.exp(s)\n",
    "            ldj += s.sum(dim=[1,2,3])\n",
    "        else:\n",
    "            z = (z * torch.exp(-s)) - t\n",
    "            ldj -= s.sum(dim=[1,2,3])\n",
    "            \n",
    "        return z, ldj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For stabilization purposes, we apply a $\\tanh$ activation function on the scaling output. This prevents sudden large output values for the scaling that can destabilize training. To still allow scaling factors smaller or larger than -1 and 1 respectively, we have a learnable parameter per dimension, called `scaling_factor`. This scales the tanh to different limits. Below, we visualize the effect of the scaling factor on the output activation of the scaling terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/pdf": "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\n",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"710.613911pt\" height=\"212.744063pt\" viewBox=\"0 0 710.613911 212.744063\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2022-06-10T09:54:08.293462</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 212.744063 \n",
       "L 710.613911 212.744063 \n",
       "L 710.613911 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 32.916406 185.398125 \n",
       "L 209.126933 185.398125 \n",
       "L 209.126933 22.318125 \n",
       "L 32.916406 22.318125 \n",
       "z\n",
       "\" style=\"fill: #eaeaf2\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path d=\"M 40.925976 185.398125 \n",
       "L 40.925976 22.318125 \n",
       "\" clip-path=\"url(#pf3cb250ed8)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 5.0 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(27.570429 203.256406)scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \n",
       "L 4684 2272 \n",
       "L 4684 1741 \n",
       "L 678 1741 \n",
       "L 678 2272 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \n",
       "L 1344 794 \n",
       "L 1344 0 \n",
       "L 684 0 \n",
       "L 684 794 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"83.789062\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"179.199219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <path d=\"M 81.013911 185.398125 \n",
       "L 81.013911 22.318125 \n",
       "\" clip-path=\"url(#pf3cb250ed8)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 2.5 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(67.658364 203.256406)scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"83.789062\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"179.199219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path d=\"M 121.101847 185.398125 \n",
       "L 121.101847 22.318125 \n",
       "\" clip-path=\"url(#pf3cb250ed8)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 0.0 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(112.355128 203.256406)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <path d=\"M 161.189783 185.398125 \n",
       "L 161.189783 22.318125 \n",
       "\" clip-path=\"url(#pf3cb250ed8)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 2.5 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(152.443064 203.256406)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path d=\"M 201.277719 185.398125 \n",
       "L 201.277719 22.318125 \n",
       "\" clip-path=\"url(#pf3cb250ed8)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 5.0 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(192.531 203.256406)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <path d=\"M 32.916406 185.398125 \n",
       "L 209.126933 185.398125 \n",
       "\" clip-path=\"url(#pf3cb250ed8)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 3 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(7.2 189.577266)scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \n",
       "Q 3050 2419 3304 2112 \n",
       "Q 3559 1806 3559 1356 \n",
       "Q 3559 666 3084 287 \n",
       "Q 2609 -91 1734 -91 \n",
       "Q 1441 -91 1130 -33 \n",
       "Q 819 25 488 141 \n",
       "L 488 750 \n",
       "Q 750 597 1062 519 \n",
       "Q 1375 441 1716 441 \n",
       "Q 2309 441 2620 675 \n",
       "Q 2931 909 2931 1356 \n",
       "Q 2931 1769 2642 2001 \n",
       "Q 2353 2234 1838 2234 \n",
       "L 1294 2234 \n",
       "L 1294 2753 \n",
       "L 1863 2753 \n",
       "Q 2328 2753 2575 2939 \n",
       "Q 2822 3125 2822 3475 \n",
       "Q 2822 3834 2567 4026 \n",
       "Q 2313 4219 1838 4219 \n",
       "Q 1578 4219 1281 4162 \n",
       "Q 984 4106 628 3988 \n",
       "L 628 4550 \n",
       "Q 988 4650 1302 4700 \n",
       "Q 1616 4750 1894 4750 \n",
       "Q 2613 4750 3031 4423 \n",
       "Q 3450 4097 3450 3541 \n",
       "Q 3450 3153 3228 2886 \n",
       "Q 3006 2619 2597 2516 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-33\" x=\"83.789062\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path d=\"M 32.916406 158.218125 \n",
       "L 209.126933 158.218125 \n",
       "\" clip-path=\"url(#pf3cb250ed8)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 2 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(7.2 162.397266)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"83.789062\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <path d=\"M 32.916406 131.038125 \n",
       "L 209.126933 131.038125 \n",
       "\" clip-path=\"url(#pf3cb250ed8)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 1 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(7.2 135.217266)scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-31\" x=\"83.789062\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path d=\"M 32.916406 103.858125 \n",
       "L 209.126933 103.858125 \n",
       "\" clip-path=\"url(#pf3cb250ed8)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(16.417656 108.037266)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <path d=\"M 32.916406 76.678125 \n",
       "L 209.126933 76.678125 \n",
       "\" clip-path=\"url(#pf3cb250ed8)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 1 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(16.417656 80.857266)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path d=\"M 32.916406 49.498125 \n",
       "L 209.126933 49.498125 \n",
       "\" clip-path=\"url(#pf3cb250ed8)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 2 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(16.417656 53.677266)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <path d=\"M 32.916406 22.318125 \n",
       "L 209.126933 22.318125 \n",
       "\" clip-path=\"url(#pf3cb250ed8)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 3 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(16.417656 26.497266)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#DejaVuSans-33\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_13\">\n",
       "    <path d=\"M 40.925976 117.448125 \n",
       "L 98.973307 117.33968 \n",
       "L 103.623509 117.10519 \n",
       "L 106.509838 116.752839 \n",
       "L 108.754763 116.25384 \n",
       "L 110.518632 115.637718 \n",
       "L 112.122149 114.832986 \n",
       "L 113.565316 113.849795 \n",
       "L 115.008481 112.570361 \n",
       "L 116.451646 110.961148 \n",
       "L 117.894812 109.021632 \n",
       "L 119.819033 106.014158 \n",
       "L 124.629585 98.236697 \n",
       "L 126.233103 96.18114 \n",
       "L 127.676269 94.683925 \n",
       "L 129.119434 93.50806 \n",
       "L 130.5626 92.613058 \n",
       "L 132.166117 91.885997 \n",
       "L 133.929987 91.33265 \n",
       "L 136.014559 90.911219 \n",
       "L 138.740539 90.597776 \n",
       "L 142.588981 90.395298 \n",
       "L 149.484105 90.290985 \n",
       "L 173.376515 90.268184 \n",
       "L 201.117363 90.268125 \n",
       "L 201.117363 90.268125 \n",
       "\" clip-path=\"url(#pf3cb250ed8)\" style=\"fill: none; stroke: #4c72b0; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 32.916406 185.398125 \n",
       "L 32.916406 22.318125 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 209.126933 185.398125 \n",
       "L 209.126933 22.318125 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 32.916406 185.398125 \n",
       "L 209.126933 185.398125 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 32.916406 22.318125 \n",
       "L 209.126933 22.318125 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_13\">\n",
       "    <!-- Scaling factor: 0.5 -->\n",
       "    <g style=\"fill: #262626\" transform=\"translate(66.441357 16.318125)scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-53\" d=\"M 3425 4513 \n",
       "L 3425 3897 \n",
       "Q 3066 4069 2747 4153 \n",
       "Q 2428 4238 2131 4238 \n",
       "Q 1616 4238 1336 4038 \n",
       "Q 1056 3838 1056 3469 \n",
       "Q 1056 3159 1242 3001 \n",
       "Q 1428 2844 1947 2747 \n",
       "L 2328 2669 \n",
       "Q 3034 2534 3370 2195 \n",
       "Q 3706 1856 3706 1288 \n",
       "Q 3706 609 3251 259 \n",
       "Q 2797 -91 1919 -91 \n",
       "Q 1588 -91 1214 -16 \n",
       "Q 841 59 441 206 \n",
       "L 441 856 \n",
       "Q 825 641 1194 531 \n",
       "Q 1563 422 1919 422 \n",
       "Q 2459 422 2753 634 \n",
       "Q 3047 847 3047 1241 \n",
       "Q 3047 1584 2836 1778 \n",
       "Q 2625 1972 2144 2069 \n",
       "L 1759 2144 \n",
       "Q 1053 2284 737 2584 \n",
       "Q 422 2884 422 3419 \n",
       "Q 422 4038 858 4394 \n",
       "Q 1294 4750 2059 4750 \n",
       "Q 2388 4750 2728 4690 \n",
       "Q 3069 4631 3425 4513 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \n",
       "L 3122 2828 \n",
       "Q 2878 2963 2633 3030 \n",
       "Q 2388 3097 2138 3097 \n",
       "Q 1578 3097 1268 2742 \n",
       "Q 959 2388 959 1747 \n",
       "Q 959 1106 1268 751 \n",
       "Q 1578 397 2138 397 \n",
       "Q 2388 397 2633 464 \n",
       "Q 2878 531 3122 666 \n",
       "L 3122 134 \n",
       "Q 2881 22 2623 -34 \n",
       "Q 2366 -91 2075 -91 \n",
       "Q 1284 -91 818 406 \n",
       "Q 353 903 353 1747 \n",
       "Q 353 2603 823 3093 \n",
       "Q 1294 3584 2113 3584 \n",
       "Q 2378 3584 2631 3529 \n",
       "Q 2884 3475 3122 3366 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-69\" d=\"M 603 3500 \n",
       "L 1178 3500 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 3500 \n",
       "z\n",
       "M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 4134 \n",
       "L 603 4134 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-67\" d=\"M 2906 1791 \n",
       "Q 2906 2416 2648 2759 \n",
       "Q 2391 3103 1925 3103 \n",
       "Q 1463 3103 1205 2759 \n",
       "Q 947 2416 947 1791 \n",
       "Q 947 1169 1205 825 \n",
       "Q 1463 481 1925 481 \n",
       "Q 2391 481 2648 825 \n",
       "Q 2906 1169 2906 1791 \n",
       "z\n",
       "M 3481 434 \n",
       "Q 3481 -459 3084 -895 \n",
       "Q 2688 -1331 1869 -1331 \n",
       "Q 1566 -1331 1297 -1286 \n",
       "Q 1028 -1241 775 -1147 \n",
       "L 775 -588 \n",
       "Q 1028 -725 1275 -790 \n",
       "Q 1522 -856 1778 -856 \n",
       "Q 2344 -856 2625 -561 \n",
       "Q 2906 -266 2906 331 \n",
       "L 2906 616 \n",
       "Q 2728 306 2450 153 \n",
       "Q 2172 0 1784 0 \n",
       "Q 1141 0 747 490 \n",
       "Q 353 981 353 1791 \n",
       "Q 353 2603 747 3093 \n",
       "Q 1141 3584 1784 3584 \n",
       "Q 2172 3584 2450 3431 \n",
       "Q 2728 3278 2906 2969 \n",
       "L 2906 3500 \n",
       "L 3481 3500 \n",
       "L 3481 434 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-66\" d=\"M 2375 4863 \n",
       "L 2375 4384 \n",
       "L 1825 4384 \n",
       "Q 1516 4384 1395 4259 \n",
       "Q 1275 4134 1275 3809 \n",
       "L 1275 3500 \n",
       "L 2222 3500 \n",
       "L 2222 3053 \n",
       "L 1275 3053 \n",
       "L 1275 0 \n",
       "L 697 0 \n",
       "L 697 3053 \n",
       "L 147 3053 \n",
       "L 147 3500 \n",
       "L 697 3500 \n",
       "L 697 3744 \n",
       "Q 697 4328 969 4595 \n",
       "Q 1241 4863 1831 4863 \n",
       "L 2375 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \n",
       "L 1172 3500 \n",
       "L 2356 3500 \n",
       "L 2356 3053 \n",
       "L 1172 3053 \n",
       "L 1172 1153 \n",
       "Q 1172 725 1289 603 \n",
       "Q 1406 481 1766 481 \n",
       "L 2356 481 \n",
       "L 2356 0 \n",
       "L 1766 0 \n",
       "Q 1100 0 847 248 \n",
       "Q 594 497 594 1153 \n",
       "L 594 3053 \n",
       "L 172 3053 \n",
       "L 172 3500 \n",
       "L 594 3500 \n",
       "L 594 4494 \n",
       "L 1172 4494 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
       "Q 2534 3019 2420 3045 \n",
       "Q 2306 3072 2169 3072 \n",
       "Q 1681 3072 1420 2755 \n",
       "Q 1159 2438 1159 1844 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1341 3275 1631 3429 \n",
       "Q 1922 3584 2338 3584 \n",
       "Q 2397 3584 2469 3576 \n",
       "Q 2541 3569 2628 3553 \n",
       "L 2631 2963 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-3a\" d=\"M 750 794 \n",
       "L 1409 794 \n",
       "L 1409 0 \n",
       "L 750 0 \n",
       "L 750 794 \n",
       "z\n",
       "M 750 3309 \n",
       "L 1409 3309 \n",
       "L 1409 2516 \n",
       "L 750 2516 \n",
       "L 750 3309 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-53\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-63\" x=\"63.476562\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"118.457031\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"179.736328\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" x=\"207.519531\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6e\" x=\"235.302734\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-67\" x=\"298.681641\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"362.158203\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-66\" x=\"393.945312\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"429.150391\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-63\" x=\"490.429688\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-74\" x=\"545.410156\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"584.619141\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"645.800781\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-3a\" x=\"685.164062\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"718.855469\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-30\" x=\"750.642578\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-2e\" x=\"814.265625\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-35\" x=\"846.052734\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_2\">\n",
       "   <g id=\"patch_7\">\n",
       "    <path d=\"M 279.611143 185.398125 \n",
       "L 455.821669 185.398125 \n",
       "L 455.821669 22.318125 \n",
       "L 279.611143 22.318125 \n",
       "z\n",
       "\" style=\"fill: #eaeaf2\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_3\">\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_14\">\n",
       "      <path d=\"M 287.620712 185.398125 \n",
       "L 287.620712 22.318125 \n",
       "\" clip-path=\"url(#p2ca02685d0)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 5.0 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(274.265166 203.256406)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"83.789062\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"179.199219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_7\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <path d=\"M 327.708648 185.398125 \n",
       "L 327.708648 22.318125 \n",
       "\" clip-path=\"url(#p2ca02685d0)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_15\">\n",
       "      <!-- 2.5 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(314.353101 203.256406)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"83.789062\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"179.199219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_8\">\n",
       "     <g id=\"line2d_16\">\n",
       "      <path d=\"M 367.796584 185.398125 \n",
       "L 367.796584 22.318125 \n",
       "\" clip-path=\"url(#p2ca02685d0)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_16\">\n",
       "      <!-- 0.0 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(359.049865 203.256406)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_9\">\n",
       "     <g id=\"line2d_17\">\n",
       "      <path d=\"M 407.88452 185.398125 \n",
       "L 407.88452 22.318125 \n",
       "\" clip-path=\"url(#p2ca02685d0)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_17\">\n",
       "      <!-- 2.5 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(399.137801 203.256406)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_10\">\n",
       "     <g id=\"line2d_18\">\n",
       "      <path d=\"M 447.972455 185.398125 \n",
       "L 447.972455 22.318125 \n",
       "\" clip-path=\"url(#p2ca02685d0)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_18\">\n",
       "      <!-- 5.0 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(439.225737 203.256406)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_4\">\n",
       "    <g id=\"ytick_8\">\n",
       "     <g id=\"line2d_19\">\n",
       "      <path d=\"M 279.611143 185.398125 \n",
       "L 455.821669 185.398125 \n",
       "\" clip-path=\"url(#p2ca02685d0)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_19\">\n",
       "      <!-- 3 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(253.894737 189.577266)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-33\" x=\"83.789062\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_9\">\n",
       "     <g id=\"line2d_20\">\n",
       "      <path d=\"M 279.611143 158.218125 \n",
       "L 455.821669 158.218125 \n",
       "\" clip-path=\"url(#p2ca02685d0)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_20\">\n",
       "      <!-- 2 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(253.894737 162.397266)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"83.789062\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_10\">\n",
       "     <g id=\"line2d_21\">\n",
       "      <path d=\"M 279.611143 131.038125 \n",
       "L 455.821669 131.038125 \n",
       "\" clip-path=\"url(#p2ca02685d0)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_21\">\n",
       "      <!-- 1 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(253.894737 135.217266)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-31\" x=\"83.789062\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_11\">\n",
       "     <g id=\"line2d_22\">\n",
       "      <path d=\"M 279.611143 103.858125 \n",
       "L 455.821669 103.858125 \n",
       "\" clip-path=\"url(#p2ca02685d0)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_22\">\n",
       "      <!-- 0 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(263.112393 108.037266)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_12\">\n",
       "     <g id=\"line2d_23\">\n",
       "      <path d=\"M 279.611143 76.678125 \n",
       "L 455.821669 76.678125 \n",
       "\" clip-path=\"url(#p2ca02685d0)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_23\">\n",
       "      <!-- 1 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(263.112393 80.857266)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_13\">\n",
       "     <g id=\"line2d_24\">\n",
       "      <path d=\"M 279.611143 49.498125 \n",
       "L 455.821669 49.498125 \n",
       "\" clip-path=\"url(#p2ca02685d0)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_24\">\n",
       "      <!-- 2 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(263.112393 53.677266)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_14\">\n",
       "     <g id=\"line2d_25\">\n",
       "      <path d=\"M 279.611143 22.318125 \n",
       "L 455.821669 22.318125 \n",
       "\" clip-path=\"url(#p2ca02685d0)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_25\">\n",
       "      <!-- 3 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(263.112393 26.497266)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#DejaVuSans-33\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_26\">\n",
       "    <path d=\"M 287.620712 131.035658 \n",
       "L 318.889303 130.916475 \n",
       "L 327.708648 130.674301 \n",
       "L 333.320958 130.310413 \n",
       "L 337.490105 129.825166 \n",
       "L 340.85749 129.213302 \n",
       "L 343.743823 128.460055 \n",
       "L 346.149098 127.614894 \n",
       "L 348.394022 126.599074 \n",
       "L 350.478595 125.417277 \n",
       "L 352.563169 123.965428 \n",
       "L 354.48739 122.353463 \n",
       "L 356.411611 120.456321 \n",
       "L 358.335831 118.260688 \n",
       "L 360.420404 115.547814 \n",
       "L 362.82568 112.024005 \n",
       "L 365.712011 107.371754 \n",
       "L 373.569247 94.475207 \n",
       "L 375.974523 91.085015 \n",
       "L 378.059096 88.504155 \n",
       "L 380.143668 86.274583 \n",
       "L 382.067889 84.522444 \n",
       "L 384.152461 82.933153 \n",
       "L 386.237036 81.631569 \n",
       "L 388.481958 80.507067 \n",
       "L 390.887234 79.56742 \n",
       "L 393.452861 78.807174 \n",
       "L 396.339194 78.18131 \n",
       "L 399.866933 77.655855 \n",
       "L 404.196429 77.252204 \n",
       "L 409.808739 76.964727 \n",
       "L 418.147029 76.779772 \n",
       "L 433.8615 76.692466 \n",
       "L 447.8121 76.680643 \n",
       "L 447.8121 76.680643 \n",
       "\" clip-path=\"url(#p2ca02685d0)\" style=\"fill: none; stroke: #4c72b0; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_8\">\n",
       "    <path d=\"M 279.611143 185.398125 \n",
       "L 279.611143 22.318125 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_9\">\n",
       "    <path d=\"M 455.821669 185.398125 \n",
       "L 455.821669 22.318125 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_10\">\n",
       "    <path d=\"M 279.611143 185.398125 \n",
       "L 455.821669 185.398125 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_11\">\n",
       "    <path d=\"M 279.611143 22.318125 \n",
       "L 455.821669 22.318125 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_26\">\n",
       "    <!-- Scaling factor: 1 -->\n",
       "    <g style=\"fill: #262626\" transform=\"translate(318.860469 16.318125)scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#DejaVuSans-53\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-63\" x=\"63.476562\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"118.457031\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"179.736328\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" x=\"207.519531\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6e\" x=\"235.302734\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-67\" x=\"298.681641\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"362.158203\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-66\" x=\"393.945312\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"429.150391\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-63\" x=\"490.429688\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-74\" x=\"545.410156\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"584.619141\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"645.800781\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-3a\" x=\"685.164062\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"718.855469\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-31\" x=\"750.642578\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_3\">\n",
       "   <g id=\"patch_12\">\n",
       "    <path d=\"M 526.30588 185.398125 \n",
       "L 702.516406 185.398125 \n",
       "L 702.516406 22.318125 \n",
       "L 526.30588 22.318125 \n",
       "z\n",
       "\" style=\"fill: #eaeaf2\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_5\">\n",
       "    <g id=\"xtick_11\">\n",
       "     <g id=\"line2d_27\">\n",
       "      <path d=\"M 534.315449 185.398125 \n",
       "L 534.315449 22.318125 \n",
       "\" clip-path=\"url(#p1694276303)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_27\">\n",
       "      <!-- 5.0 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(520.959902 203.256406)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"83.789062\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"179.199219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_12\">\n",
       "     <g id=\"line2d_28\">\n",
       "      <path d=\"M 574.403385 185.398125 \n",
       "L 574.403385 22.318125 \n",
       "\" clip-path=\"url(#p1694276303)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_28\">\n",
       "      <!-- 2.5 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(561.047838 203.256406)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"83.789062\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"179.199219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_13\">\n",
       "     <g id=\"line2d_29\">\n",
       "      <path d=\"M 614.491321 185.398125 \n",
       "L 614.491321 22.318125 \n",
       "\" clip-path=\"url(#p1694276303)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_29\">\n",
       "      <!-- 0.0 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(605.744602 203.256406)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_14\">\n",
       "     <g id=\"line2d_30\">\n",
       "      <path d=\"M 654.579257 185.398125 \n",
       "L 654.579257 22.318125 \n",
       "\" clip-path=\"url(#p1694276303)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_30\">\n",
       "      <!-- 2.5 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(645.832538 203.256406)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_15\">\n",
       "     <g id=\"line2d_31\">\n",
       "      <path d=\"M 694.667192 185.398125 \n",
       "L 694.667192 22.318125 \n",
       "\" clip-path=\"url(#p1694276303)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_31\">\n",
       "      <!-- 5.0 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(685.920474 203.256406)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_6\">\n",
       "    <g id=\"ytick_15\">\n",
       "     <g id=\"line2d_32\">\n",
       "      <path d=\"M 526.30588 185.398125 \n",
       "L 702.516406 185.398125 \n",
       "\" clip-path=\"url(#p1694276303)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_32\">\n",
       "      <!-- 3 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(500.589474 189.577266)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-33\" x=\"83.789062\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_16\">\n",
       "     <g id=\"line2d_33\">\n",
       "      <path d=\"M 526.30588 158.218125 \n",
       "L 702.516406 158.218125 \n",
       "\" clip-path=\"url(#p1694276303)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_33\">\n",
       "      <!-- 2 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(500.589474 162.397266)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"83.789062\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_17\">\n",
       "     <g id=\"line2d_34\">\n",
       "      <path d=\"M 526.30588 131.038125 \n",
       "L 702.516406 131.038125 \n",
       "\" clip-path=\"url(#p1694276303)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_34\">\n",
       "      <!-- 1 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(500.589474 135.217266)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-31\" x=\"83.789062\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_18\">\n",
       "     <g id=\"line2d_35\">\n",
       "      <path d=\"M 526.30588 103.858125 \n",
       "L 702.516406 103.858125 \n",
       "\" clip-path=\"url(#p1694276303)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_35\">\n",
       "      <!-- 0 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(509.80713 108.037266)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_19\">\n",
       "     <g id=\"line2d_36\">\n",
       "      <path d=\"M 526.30588 76.678125 \n",
       "L 702.516406 76.678125 \n",
       "\" clip-path=\"url(#p1694276303)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_36\">\n",
       "      <!-- 1 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(509.80713 80.857266)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_20\">\n",
       "     <g id=\"line2d_37\">\n",
       "      <path d=\"M 526.30588 49.498125 \n",
       "L 702.516406 49.498125 \n",
       "\" clip-path=\"url(#p1694276303)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_37\">\n",
       "      <!-- 2 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(509.80713 53.677266)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_21\">\n",
       "     <g id=\"line2d_38\">\n",
       "      <path d=\"M 526.30588 22.318125 \n",
       "L 702.516406 22.318125 \n",
       "\" clip-path=\"url(#p1694276303)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_38\">\n",
       "      <!-- 3 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(509.80713 26.497266)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#DejaVuSans-33\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_39\">\n",
       "    <path d=\"M 534.315449 157.490478 \n",
       "L 542.493392 157.011752 \n",
       "L 549.067811 156.410507 \n",
       "L 554.519769 155.695503 \n",
       "L 559.33032 154.840361 \n",
       "L 563.499465 153.877442 \n",
       "L 567.347907 152.759155 \n",
       "L 570.875646 151.498853 \n",
       "L 574.082682 150.121969 \n",
       "L 577.129366 148.578067 \n",
       "L 580.015695 146.875234 \n",
       "L 582.902029 144.912004 \n",
       "L 585.628008 142.796077 \n",
       "L 588.353987 140.406487 \n",
       "L 591.079966 137.727958 \n",
       "L 593.966296 134.566065 \n",
       "L 596.852629 131.066405 \n",
       "L 599.899312 127.015503 \n",
       "L 603.266699 122.143499 \n",
       "L 606.954789 116.402646 \n",
       "L 611.765341 108.467629 \n",
       "L 622.989963 89.780722 \n",
       "L 626.838405 83.905735 \n",
       "L 630.205792 79.166919 \n",
       "L 633.252474 75.249001 \n",
       "L 636.138806 71.880351 \n",
       "L 639.025137 68.849598 \n",
       "L 641.911469 66.150083 \n",
       "L 644.7978 63.767025 \n",
       "L 647.684131 61.67988 \n",
       "L 650.570463 59.864518 \n",
       "L 653.617147 58.214522 \n",
       "L 656.824179 56.739751 \n",
       "L 660.191566 55.443079 \n",
       "L 663.719305 54.321143 \n",
       "L 667.567747 53.328299 \n",
       "L 671.897244 52.446582 \n",
       "L 676.707799 51.697857 \n",
       "L 682.320108 51.057567 \n",
       "L 688.894527 50.538067 \n",
       "L 694.506837 50.233037 \n",
       "L 694.506837 50.233037 \n",
       "\" clip-path=\"url(#p1694276303)\" style=\"fill: none; stroke: #4c72b0; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_13\">\n",
       "    <path d=\"M 526.30588 185.398125 \n",
       "L 526.30588 22.318125 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_14\">\n",
       "    <path d=\"M 702.516406 185.398125 \n",
       "L 702.516406 22.318125 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_15\">\n",
       "    <path d=\"M 526.30588 185.398125 \n",
       "L 702.516406 185.398125 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_16\">\n",
       "    <path d=\"M 526.30588 22.318125 \n",
       "L 702.516406 22.318125 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_39\">\n",
       "    <!-- Scaling factor: 2 -->\n",
       "    <g style=\"fill: #262626\" transform=\"translate(565.555206 16.318125)scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#DejaVuSans-53\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-63\" x=\"63.476562\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"118.457031\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"179.736328\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" x=\"207.519531\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6e\" x=\"235.302734\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-67\" x=\"298.681641\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"362.158203\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-66\" x=\"393.945312\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"429.150391\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-63\" x=\"490.429688\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-74\" x=\"545.410156\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"584.619141\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"645.800781\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-3a\" x=\"685.164062\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"718.855469\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-32\" x=\"750.642578\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pf3cb250ed8\">\n",
       "   <rect x=\"32.916406\" y=\"22.318125\" width=\"176.210526\" height=\"163.08\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"p2ca02685d0\">\n",
       "   <rect x=\"279.611143\" y=\"22.318125\" width=\"176.210526\" height=\"163.08\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"p1694276303\">\n",
       "   <rect x=\"526.30588\" y=\"22.318125\" width=\"176.210526\" height=\"163.08\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 864x216 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    x = torch.arange(-5,5,0.01)\n",
    "    scaling_factors = [0.5, 1, 2]\n",
    "    sns.set()\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(12,3))\n",
    "    for i, scale in enumerate(scaling_factors):\n",
    "        y = torch.tanh(x / scale) * scale\n",
    "        ax[i].plot(x.numpy(), y.numpy())\n",
    "        ax[i].set_title(\"Scaling factor: \" + str(scale))\n",
    "        ax[i].set_ylim(-3, 3)\n",
    "    plt.subplots_adjust(wspace=0.4)\n",
    "    sns.reset_orig()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coupling layers generalize to any masking technique we could think of. However, the most common approach for images is to split the input $z$ in half, using a checkerboard mask or channel mask. A checkerboard mask splits the variables across the height and width dimensions and assigns each other pixel to $z_{j+1:d}$. Thereby, the mask is shared across channels. In contrast, the channel mask assigns half of the channels to $z_{j+1:d}$, and the other half to $z_{1:j+1}$. Note that when we apply multiple coupling layers, we invert the masking for each other layer so that each variable is transformed a similar amount of times. \n",
    "\n",
    "Let's implement a function that creates a checkerboard mask and a channel mask for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_checkerboard_mask(h, w, invert=False):\n",
    "    x, y = torch.arange(h, dtype=torch.int32), torch.arange(w, dtype=torch.int32)\n",
    "    xx, yy = torch.meshgrid(x, y)\n",
    "    mask = torch.fmod(xx + yy, 2)\n",
    "    mask = mask.to(torch.float32).view(1, 1, h, w)\n",
    "    if invert:\n",
    "        mask = 1 - mask\n",
    "    return mask\n",
    "\n",
    "def create_channel_mask(c_in, invert=False):\n",
    "    mask = torch.cat([torch.ones(c_in//2, dtype=torch.float32), \n",
    "                      torch.zeros(c_in-c_in//2, dtype=torch.float32)])\n",
    "    mask = mask.view(1, c_in, 1, 1)\n",
    "    if invert:\n",
    "        mask = 1 - mask\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the corresponding masks for an image of size $8\\times 8\\times 2$ (2 channels):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "application/pdf": "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\n",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"163.89pt\" height=\"111.058125pt\" viewBox=\"0 0 163.89 111.058125\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2022-06-10T09:54:08.542631</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M -0 111.058125 \n",
       "L 163.89 111.058125 \n",
       "L 163.89 0 \n",
       "L -0 0 \n",
       "L -0 111.058125 \n",
       "z\n",
       "\" style=\"fill: none\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g clip-path=\"url(#pdb06052d4d)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "iVBORw0KGgoAAAANSUhEUgAAAJYAAABSCAYAAAC2eC1AAAABYElEQVR4nO3aUWrDMBQAwar03srN3QvE+hDe1C4z4J+ER4JYTILfmHMeX3Cx77/+AvxPwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSP7uDr9fr7etjjNOZ4zhfpPjk3Gpmznn63srZeaw+7y7nsZrbPQ93LBLCIiEsEsIiISwSwiKxHdYY4+11HMfpdTbz6bnVzNXnsfq8u5zHam6XOxYJYZEQFglhkRAWie2w7vCPZXduNXP1eez+O73LOe5yxyIhLBLCIiEsEsIiISwSHkJ7CO0hNM8hLBLCIiEsEsIiISwSthtsN9hu4DmERUJYJIRFQlgkhEXCdoPtBtsNPIewSAiLhLBICIuEsEjYbrDdYLuB5xAWCWGREBYJYZEQFgnbDbYbbDfwHMIiISwSwiIhLBJjzrn/0x9OuGOREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGR+AV6W4vZL8erlAAAAABJRU5ErkJggg==\" id=\"image8fffbe7e58\" transform=\"scale(1 -1)translate(0 -82)\" x=\"7.2\" y=\"-21.858125\" width=\"150\" height=\"82\"/>\n",
       "   </g>\n",
       "   <g id=\"text_1\">\n",
       "    <!-- Checkerboard mask -->\n",
       "    <g transform=\"translate(22.190625 16.318125)scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-43\" d=\"M 4122 4306 \n",
       "L 4122 3641 \n",
       "Q 3803 3938 3442 4084 \n",
       "Q 3081 4231 2675 4231 \n",
       "Q 1875 4231 1450 3742 \n",
       "Q 1025 3253 1025 2328 \n",
       "Q 1025 1406 1450 917 \n",
       "Q 1875 428 2675 428 \n",
       "Q 3081 428 3442 575 \n",
       "Q 3803 722 4122 1019 \n",
       "L 4122 359 \n",
       "Q 3791 134 3420 21 \n",
       "Q 3050 -91 2638 -91 \n",
       "Q 1578 -91 968 557 \n",
       "Q 359 1206 359 2328 \n",
       "Q 359 3453 968 4101 \n",
       "Q 1578 4750 2638 4750 \n",
       "Q 3056 4750 3426 4639 \n",
       "Q 3797 4528 4122 4306 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \n",
       "L 3122 2828 \n",
       "Q 2878 2963 2633 3030 \n",
       "Q 2388 3097 2138 3097 \n",
       "Q 1578 3097 1268 2742 \n",
       "Q 959 2388 959 1747 \n",
       "Q 959 1106 1268 751 \n",
       "Q 1578 397 2138 397 \n",
       "Q 2388 397 2633 464 \n",
       "Q 2878 531 3122 666 \n",
       "L 3122 134 \n",
       "Q 2881 22 2623 -34 \n",
       "Q 2366 -91 2075 -91 \n",
       "Q 1284 -91 818 406 \n",
       "Q 353 903 353 1747 \n",
       "Q 353 2603 823 3093 \n",
       "Q 1294 3584 2113 3584 \n",
       "Q 2378 3584 2631 3529 \n",
       "Q 2884 3475 3122 3366 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6b\" d=\"M 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 1991 \n",
       "L 2875 3500 \n",
       "L 3609 3500 \n",
       "L 1753 1863 \n",
       "L 3688 0 \n",
       "L 2938 0 \n",
       "L 1159 1709 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
       "Q 2534 3019 2420 3045 \n",
       "Q 2306 3072 2169 3072 \n",
       "Q 1681 3072 1420 2755 \n",
       "Q 1159 2438 1159 1844 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1341 3275 1631 3429 \n",
       "Q 1922 3584 2338 3584 \n",
       "Q 2397 3584 2469 3576 \n",
       "Q 2541 3569 2628 3553 \n",
       "L 2631 2963 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-62\" d=\"M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "M 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2969 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \n",
       "L 2906 4863 \n",
       "L 3481 4863 \n",
       "L 3481 0 \n",
       "L 2906 0 \n",
       "L 2906 525 \n",
       "Q 2725 213 2448 61 \n",
       "Q 2172 -91 1784 -91 \n",
       "Q 1150 -91 751 415 \n",
       "Q 353 922 353 1747 \n",
       "Q 353 2572 751 3078 \n",
       "Q 1150 3584 1784 3584 \n",
       "Q 2172 3584 2448 3432 \n",
       "Q 2725 3281 2906 2969 \n",
       "z\n",
       "M 947 1747 \n",
       "Q 947 1113 1208 752 \n",
       "Q 1469 391 1925 391 \n",
       "Q 2381 391 2643 752 \n",
       "Q 2906 1113 2906 1747 \n",
       "Q 2906 2381 2643 2742 \n",
       "Q 2381 3103 1925 3103 \n",
       "Q 1469 3103 1208 2742 \n",
       "Q 947 2381 947 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6d\" d=\"M 3328 2828 \n",
       "Q 3544 3216 3844 3400 \n",
       "Q 4144 3584 4550 3584 \n",
       "Q 5097 3584 5394 3201 \n",
       "Q 5691 2819 5691 2113 \n",
       "L 5691 0 \n",
       "L 5113 0 \n",
       "L 5113 2094 \n",
       "Q 5113 2597 4934 2840 \n",
       "Q 4756 3084 4391 3084 \n",
       "Q 3944 3084 3684 2787 \n",
       "Q 3425 2491 3425 1978 \n",
       "L 3425 0 \n",
       "L 2847 0 \n",
       "L 2847 2094 \n",
       "Q 2847 2600 2669 2842 \n",
       "Q 2491 3084 2119 3084 \n",
       "Q 1678 3084 1418 2786 \n",
       "Q 1159 2488 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1356 3278 1631 3431 \n",
       "Q 1906 3584 2284 3584 \n",
       "Q 2666 3584 2933 3390 \n",
       "Q 3200 3197 3328 2828 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
       "L 2834 2853 \n",
       "Q 2591 2978 2328 3040 \n",
       "Q 2066 3103 1784 3103 \n",
       "Q 1356 3103 1142 2972 \n",
       "Q 928 2841 928 2578 \n",
       "Q 928 2378 1081 2264 \n",
       "Q 1234 2150 1697 2047 \n",
       "L 1894 2003 \n",
       "Q 2506 1872 2764 1633 \n",
       "Q 3022 1394 3022 966 \n",
       "Q 3022 478 2636 193 \n",
       "Q 2250 -91 1575 -91 \n",
       "Q 1294 -91 989 -36 \n",
       "Q 684 19 347 128 \n",
       "L 347 722 \n",
       "Q 666 556 975 473 \n",
       "Q 1284 391 1588 391 \n",
       "Q 1994 391 2212 530 \n",
       "Q 2431 669 2431 922 \n",
       "Q 2431 1156 2273 1281 \n",
       "Q 2116 1406 1581 1522 \n",
       "L 1381 1569 \n",
       "Q 847 1681 609 1914 \n",
       "Q 372 2147 372 2553 \n",
       "Q 372 3047 722 3315 \n",
       "Q 1072 3584 1716 3584 \n",
       "Q 2034 3584 2315 3537 \n",
       "Q 2597 3491 2834 3397 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-43\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-68\" x=\"69.824219\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"133.203125\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-63\" x=\"194.726562\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6b\" x=\"249.707031\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"303.992188\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"365.515625\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-62\" x=\"406.628906\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"470.105469\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"531.287109\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"592.566406\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-64\" x=\"631.929688\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"695.40625\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6d\" x=\"727.193359\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"824.605469\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-73\" x=\"885.884766\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6b\" x=\"937.984375\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pdb06052d4d\">\n",
       "   <rect x=\"7.2\" y=\"22.318125\" width=\"149.49\" height=\"81.54\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 216x108 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/pdf": "JVBERi0xLjQKJazcIKu6CjEgMCBvYmoKPDwgL1BhZ2VzIDIgMCBSIC9UeXBlIC9DYXRhbG9nID4+CmVuZG9iago4IDAgb2JqCjw8IC9FeHRHU3RhdGUgNCAwIFIgL0ZvbnQgMyAwIFIgL1BhdHRlcm4gNSAwIFIKL1Byb2NTZXQgWyAvUERGIC9UZXh0IC9JbWFnZUIgL0ltYWdlQyAvSW1hZ2VJIF0gL1NoYWRpbmcgNiAwIFIKL1hPYmplY3QgNyAwIFIgPj4KZW5kb2JqCjExIDAgb2JqCjw8IC9Bbm5vdHMgMTAgMCBSIC9Db250ZW50cyA5IDAgUiAvTWVkaWFCb3ggWyAwIDAgMTYzLjg5IDExMS4wNjUgXQovUGFyZW50IDIgMCBSIC9SZXNvdXJjZXMgOCAwIFIgL1R5cGUgL1BhZ2UgPj4KZW5kb2JqCjkgMCBvYmoKPDwgL0ZpbHRlciAvRmxhdGVEZWNvZGUgL0xlbmd0aCAxMiAwIFIgPj4Kc3RyZWFtCnicVY/BbsIwEETv+xVzbA+1vY5D4iOQNio3qKUeEAeUptA0SZVGan6fNRJQDiPt2PM8a13Uf19VvSkXWL6RvrlqJEZDes44jDBoRBMYJe5DT0YuOuJZonIvY3sZmVmZWSoHErkzMXQk6mlApuxZ7LxyHjmr1OG3xjt66LmN1bKFaBKqFIDTyBvk9spWHfQro/jBmtYYLpzB4T8bPQ3yJ4O4DxKvbJawTeGdypy8QosA/cJgi/BJsSR80BYPy+O+7+sW3X78fsQOYUXPgaSLTitnRzIKZW5kc3RyZWFtCmVuZG9iagoxMiAwIG9iagoyMTEKZW5kb2JqCjEwIDAgb2JqClsgXQplbmRvYmoKMTggMCBvYmoKPDwgL0ZpbHRlciAvRmxhdGVEZWNvZGUgL0xlbmd0aCAyMzUgPj4Kc3RyZWFtCnicNVFJbgAxCLvnFf5ApbAn75mq6qH9/7WGUS8DA9jYJO/BRiQ+xJDuKFd8yuo0y/A7WeTFz0rh5L2ICqQqwgppB89yVjMMnhuZApcz8VlmPpkWOxZQTcRxduQ0g0GIaVxHy+kw0zzoCbk+GHFjp1muYkjr3VK9vtfynyrKR9bdLLdO2dRK3aJn7Elcdl5PbWlfGHUUNwWRDh87vAf5IuYsLjqRbvabKYeVpCE4LYAfiaFUzw6vESZ+ZiR4yp5O76M0vPZB0/W9e0FHbiZkKrdQRiqerDTGjKH6jWgmqe//gZ71vb7+AENNVLkKZW5kc3RyZWFtCmVuZG9iagoxOSAwIG9iago8PCAvRmlsdGVyIC9GbGF0ZURlY29kZSAvTGVuZ3RoIDMwNyA+PgpzdHJlYW0KeJw9kktuAzEMQ/c+hS4QwPrZnvOkKLqY3n/bJyXpihzZFkVqlrpMWVMekDSThH/p8HCxnfI7bM9mZuBaopeJ5ZTn0BVi7qJ82cxGXVknxeqEZjq36FE5Fwc2Taqfqyyl3S54Dtcmnlv2ET+80KAe1DUuCTd0V6NlKTRjqvt/0nv8jDLgakxdbFKrex88XkRV6OgHR4kiY5cX5+NBCelKwmhaiJV3RQNB7vK0ynsJ7tveasiyB6mYzjspZrDrdFIubheHIR7I8qjw5aPYa0LP+LArJfRI2IYzcifuaMbm1MjikP7ejQRLj65oIfPgr27WLmC8UzpFYmROcqxpi1VO91AU07nDvQwQ9WxFQylzkdXqX8POC2uWbBZ4SvoFHqPdJksOVtnbqE7vrTzZ0PcfWtd0HwplbmRzdHJlYW0KZW5kb2JqCjIwIDAgb2JqCjw8IC9GaWx0ZXIgL0ZsYXRlRGVjb2RlIC9MZW5ndGggMjQ5ID4+CnN0cmVhbQp4nD1QO45EIQzrOYUv8CTyI3AeRqstZu/frgOaKVBMfrYzJNARgUcMMZSv4yWtoK6Bv4tC8W7i64PCIKtDUiDOeg+IdOymNpETOh2cMz9hN2OOwEUxBpzpdKY9ByY5+8IKhHMbZexWSCeJqiKO6jOOKZ4qe594FiztyDZbJ5I95CDhUlKJyaWflMo/bcqUCjpm0QQsErngZBNNOMu7SVKMGZQy6h6mdiJ9rDzIozroZE3OrCOZ2dNP25n4HHC3X9pkTpXHdB7M+Jy0zoM5Fbr344k2B02N2ujs9xNpKi9Sux1anX51EpXdGOcYEpdnfxnfZP/5B/6HWiIKZW5kc3RyZWFtCmVuZG9iagoyMSAwIG9iago8PCAvRmlsdGVyIC9GbGF0ZURlY29kZSAvTGVuZ3RoIDE2NCA+PgpzdHJlYW0KeJxFkMdxBTEMQ++qAiUwgAr1rMfzD+v+r4b000F6GEIMYk/CsFxXcWF0w4+3LTMNf0cZ7sb6MmO81VggJ+gDDJGJq9Gk+nbFGar05NVirqOiXC86IhLMkuOrQCN8OrLHk7a2M/10Xh/sIe8T/yoq525hAS6q7kD5Uh/x1I/ZUeqaoY8qK2seatpXhF0RSts+LqcyTt29A1rhvZWrPdrvPx52OvIKZW5kc3RyZWFtCmVuZG9iagoyMiAwIG9iago8PCAvRmlsdGVyIC9GbGF0ZURlY29kZSAvTGVuZ3RoIDgzID4+CnN0cmVhbQp4nD3MORKAMAgF0J5T/COEyCL3cRyLeP9WMNEGHqt6oCE4g7rBreFgyrp0E+9T49XGnBIJqHhKTZa6C3rUtL7Uvmjgu+vmS9WJP83PF50Pux0Z3QplbmRzdHJlYW0KZW5kb2JqCjIzIDAgb2JqCjw8IC9GaWx0ZXIgL0ZsYXRlRGVjb2RlIC9MZW5ndGggNDcgPj4Kc3RyZWFtCnicMzK3UDBQsDQBEoYWJgrmZgYKKYZclhBWLhdMLAfMAtGWcAoinsGVBgC5Zw0nCmVuZHN0cmVhbQplbmRvYmoKMjQgMCBvYmoKPDwgL0ZpbHRlciAvRmxhdGVEZWNvZGUgL0xlbmd0aCAyNTggPj4Kc3RyZWFtCnicRZFLcgQgCET3noIjgPzkPJNKZTG5/zYNzmQ2dpeo/YRKI6YSLOcUeTB9yfLNZLbpdzlWOxsFFEUomMlV6LECqztTxJlriWrrY2XkuNM7BsUbzl05qWRxo4x1VHUqcEzPlfVR3fl2WZR9Rw5lCtiscxxs4MptwxgnRput7g73iSBPJ1NHxe0g2fAHJ419lasrcJ1s9tFLMA4E/UITmOSLQOsMgcbNU/TkEuzj43bngWBveRFI2RDIkSEYHYJ2nVz/4tb5vf9xhjvPtRmuHO/id5jWdsdfYpIVcwGL3Cmo52suWtcZOt6TM8fkpvuGzrlgl7uDTO/5P9bP+v4DHilm+gplbmRzdHJlYW0KZW5kb2JqCjI1IDAgb2JqCjw8IC9GaWx0ZXIgL0ZsYXRlRGVjb2RlIC9MZW5ndGggMTYzID4+CnN0cmVhbQp4nEWQOxIDIQxDe06hI/gjAz7PZjIpNvdvY9hsUsDTWCCDuxOC1NqCieiCh7Yl3QXvrQRnY/zpNm41EuQEdYBWpONolFJ9ucVplXTxaDZzKwutEx1mDnqUoxmgEDoV3u2i5HKm7s75Q3D1X/W/Yt05m4mBycodCM3qU9z5NjuiurrJ/qTH3KzXfivsVWFpWUvLCbedu2ZACdxTOdqrPT8fCjr2CmVuZHN0cmVhbQplbmRvYmoKMjYgMCBvYmoKPDwgL0ZpbHRlciAvRmxhdGVEZWNvZGUgL0xlbmd0aCAzMzQgPj4Kc3RyZWFtCnicLVJLcsUgDNtzCl2gM/gH5DzpdLp4vf+2kpNFRg5g9DHlholKfFkgt6PWxLeNzECF4a+rzIXPSNvIOojLkIu4ki2Fe0Qs5DHEPMSC76vxHh75rMzJswfGL9l3Dyv21IRlIePFGdphFcdhFeRYsHUhqnt4U6TDqSTY44v/PsVzLQQtfEbQgF/kn6+O4PmSFmn3mG3TrnqwTDuqpLAcbE9zXiZfWme5Oh7PB8n2rtgRUrsCFIW5M85z4SjTVka0FnY2SGpcbG+O/VhK0IVuXEaKI5CfqSI8oKTJzCYK4o+cHnIqA2Hqmq50chtVcaeezDWbi7czSWbrvkixmcJ5XTiz/gxTZrV5J89yotSpCO+xZ0vQ0Dmunr2WWWh0mxO8pITPxk5PTr5XM+shORUJqWJaV8FpFJliCdsSX1NRU5p6Gf778u7xO37+ASxzfHMKZW5kc3RyZWFtCmVuZG9iagoyNyAwIG9iago8PCAvRmlsdGVyIC9GbGF0ZURlY29kZSAvTGVuZ3RoIDE4ID4+CnN0cmVhbQp4nDM2tFAwgMMUQ640AB3mA1IKZW5kc3RyZWFtCmVuZG9iagoxNiAwIG9iago8PCAvQmFzZUZvbnQgL0JNUVFEVitEZWphVnVTYW5zIC9DaGFyUHJvY3MgMTcgMCBSCi9FbmNvZGluZyA8PAovRGlmZmVyZW5jZXMgWyAzMiAvc3BhY2UgNjcgL0MgOTcgL2EgMTAxIC9lIDEwNCAvaCAxMDcgL2sgL2wgL20gL24gMTE1IC9zIF0KL1R5cGUgL0VuY29kaW5nID4+Ci9GaXJzdENoYXIgMCAvRm9udEJCb3ggWyAtMTAyMSAtNDYzIDE3OTQgMTIzMyBdIC9Gb250RGVzY3JpcHRvciAxNSAwIFIKL0ZvbnRNYXRyaXggWyAwLjAwMSAwIDAgMC4wMDEgMCAwIF0gL0xhc3RDaGFyIDI1NSAvTmFtZSAvQk1RUURWK0RlamFWdVNhbnMKL1N1YnR5cGUgL1R5cGUzIC9UeXBlIC9Gb250IC9XaWR0aHMgMTQgMCBSID4+CmVuZG9iagoxNSAwIG9iago8PCAvQXNjZW50IDkyOSAvQ2FwSGVpZ2h0IDAgL0Rlc2NlbnQgLTIzNiAvRmxhZ3MgMzIKL0ZvbnRCQm94IFsgLTEwMjEgLTQ2MyAxNzk0IDEyMzMgXSAvRm9udE5hbWUgL0JNUVFEVitEZWphVnVTYW5zCi9JdGFsaWNBbmdsZSAwIC9NYXhXaWR0aCAxMzQyIC9TdGVtViAwIC9UeXBlIC9Gb250RGVzY3JpcHRvciAvWEhlaWdodCAwID4+CmVuZG9iagoxNCAwIG9iagpbIDYwMCA2MDAgNjAwIDYwMCA2MDAgNjAwIDYwMCA2MDAgNjAwIDYwMCA2MDAgNjAwIDYwMCA2MDAgNjAwIDYwMCA2MDAgNjAwCjYwMCA2MDAgNjAwIDYwMCA2MDAgNjAwIDYwMCA2MDAgNjAwIDYwMCA2MDAgNjAwIDYwMCA2MDAgMzE4IDQwMSA0NjAgODM4IDYzNgo5NTAgNzgwIDI3NSAzOTAgMzkwIDUwMCA4MzggMzE4IDM2MSAzMTggMzM3IDYzNiA2MzYgNjM2IDYzNiA2MzYgNjM2IDYzNiA2MzYKNjM2IDYzNiAzMzcgMzM3IDgzOCA4MzggODM4IDUzMSAxMDAwIDY4NCA2ODYgNjk4IDc3MCA2MzIgNTc1IDc3NSA3NTIgMjk1CjI5NSA2NTYgNTU3IDg2MyA3NDggNzg3IDYwMyA3ODcgNjk1IDYzNSA2MTEgNzMyIDY4NCA5ODkgNjg1IDYxMSA2ODUgMzkwIDMzNwozOTAgODM4IDUwMCA1MDAgNjEzIDYzNSA1NTAgNjM1IDYxNSAzNTIgNjM1IDYzNCAyNzggMjc4IDU3OSAyNzggOTc0IDYzNCA2MTIKNjM1IDYzNSA0MTEgNTIxIDM5MiA2MzQgNTkyIDgxOCA1OTIgNTkyIDUyNSA2MzYgMzM3IDYzNiA4MzggNjAwIDYzNiA2MDAgMzE4CjM1MiA1MTggMTAwMCA1MDAgNTAwIDUwMCAxMzQyIDYzNSA0MDAgMTA3MCA2MDAgNjg1IDYwMCA2MDAgMzE4IDMxOCA1MTggNTE4CjU5MCA1MDAgMTAwMCA1MDAgMTAwMCA1MjEgNDAwIDEwMjMgNjAwIDUyNSA2MTEgMzE4IDQwMSA2MzYgNjM2IDYzNiA2MzYgMzM3CjUwMCA1MDAgMTAwMCA0NzEgNjEyIDgzOCAzNjEgMTAwMCA1MDAgNTAwIDgzOCA0MDEgNDAxIDUwMCA2MzYgNjM2IDMxOCA1MDAKNDAxIDQ3MSA2MTIgOTY5IDk2OSA5NjkgNTMxIDY4NCA2ODQgNjg0IDY4NCA2ODQgNjg0IDk3NCA2OTggNjMyIDYzMiA2MzIgNjMyCjI5NSAyOTUgMjk1IDI5NSA3NzUgNzQ4IDc4NyA3ODcgNzg3IDc4NyA3ODcgODM4IDc4NyA3MzIgNzMyIDczMiA3MzIgNjExIDYwNQo2MzAgNjEzIDYxMyA2MTMgNjEzIDYxMyA2MTMgOTgyIDU1MCA2MTUgNjE1IDYxNSA2MTUgMjc4IDI3OCAyNzggMjc4IDYxMiA2MzQKNjEyIDYxMiA2MTIgNjEyIDYxMiA4MzggNjEyIDYzNCA2MzQgNjM0IDYzNCA1OTIgNjM1IDU5MiBdCmVuZG9iagoxNyAwIG9iago8PCAvQyAxOCAwIFIgL2EgMTkgMCBSIC9lIDIwIDAgUiAvaCAyMSAwIFIgL2sgMjIgMCBSIC9sIDIzIDAgUiAvbSAyNCAwIFIKL24gMjUgMCBSIC9zIDI2IDAgUiAvc3BhY2UgMjcgMCBSID4+CmVuZG9iagozIDAgb2JqCjw8IC9GMSAxNiAwIFIgPj4KZW5kb2JqCjQgMCBvYmoKPDwgL0ExIDw8IC9DQSAwIC9UeXBlIC9FeHRHU3RhdGUgL2NhIDEgPj4KL0EyIDw8IC9DQSAxIC9UeXBlIC9FeHRHU3RhdGUgL2NhIDEgPj4gPj4KZW5kb2JqCjUgMCBvYmoKPDwgPj4KZW5kb2JqCjYgMCBvYmoKPDwgPj4KZW5kb2JqCjcgMCBvYmoKPDwgL0kxIDEzIDAgUiA+PgplbmRvYmoKMTMgMCBvYmoKPDwgL0JpdHNQZXJDb21wb25lbnQgOCAvQ29sb3JTcGFjZSBbL0luZGV4ZWQgL0RldmljZVJHQiAyICj///9/f38AAAApXQovRGVjb2RlUGFybXMgPDwgL0NvbG9ycyAxIC9Db2x1bW5zIDE1MCAvUHJlZGljdG9yIDEwID4+Ci9GaWx0ZXIgL0ZsYXRlRGVjb2RlIC9IZWlnaHQgODIgL0xlbmd0aCAyOCAwIFIgL1N1YnR5cGUgL0ltYWdlCi9UeXBlIC9YT2JqZWN0IC9XaWR0aCAxNTAgPj4Kc3RyZWFtCnic7c6xDYBAEMCwh/2HpgYhoXzDFc4AkdcxsvU34D2sElYJq4RVwiphlR6stdX9cW6FhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWF9c2aElYJq4RVwiphlbBKQ1kXX+swDQplbmRzdHJlYW0KZW5kb2JqCjI4IDAgb2JqCjEwMgplbmRvYmoKMiAwIG9iago8PCAvQ291bnQgMSAvS2lkcyBbIDExIDAgUiBdIC9UeXBlIC9QYWdlcyA+PgplbmRvYmoKMjkgMCBvYmoKPDwgL0NyZWF0aW9uRGF0ZSAoRDoyMDIyMDYxMDA5NTQwOCswMicwMCcpCi9DcmVhdG9yIChNYXRwbG90bGliIHYzLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZykKL1Byb2R1Y2VyIChNYXRwbG90bGliIHBkZiBiYWNrZW5kIHYzLjUuMSkgPj4KZW5kb2JqCnhyZWYKMCAzMAowMDAwMDAwMDAwIDY1NTM1IGYgCjAwMDAwMDAwMTYgMDAwMDAgbiAKMDAwMDAwNTU4MCAwMDAwMCBuIAowMDAwMDA1MDAwIDAwMDAwIG4gCjAwMDAwMDUwMzIgMDAwMDAgbiAKMDAwMDAwNTEzMSAwMDAwMCBuIAowMDAwMDA1MTUyIDAwMDAwIG4gCjAwMDAwMDUxNzMgMDAwMDAgbiAKMDAwMDAwMDA2NSAwMDAwMCBuIAowMDAwMDAwMzM3IDAwMDAwIG4gCjAwMDAwMDA2NDMgMDAwMDAgbiAKMDAwMDAwMDIwOCAwMDAwMCBuIAowMDAwMDAwNjIzIDAwMDAwIG4gCjAwMDAwMDUyMDUgMDAwMDAgbiAKMDAwMDAwMzgyMSAwMDAwMCBuIAowMDAwMDAzNjE0IDAwMDAwIG4gCjAwMDAwMDMyNDggMDAwMDAgbiAKMDAwMDAwNDg3NCAwMDAwMCBuIAowMDAwMDAwNjYzIDAwMDAwIG4gCjAwMDAwMDA5NzEgMDAwMDAgbiAKMDAwMDAwMTM1MSAwMDAwMCBuIAowMDAwMDAxNjczIDAwMDAwIG4gCjAwMDAwMDE5MTAgMDAwMDAgbiAKMDAwMDAwMjA2NSAwMDAwMCBuIAowMDAwMDAyMTg0IDAwMDAwIG4gCjAwMDAwMDI1MTUgMDAwMDAgbiAKMDAwMDAwMjc1MSAwMDAwMCBuIAowMDAwMDAzMTU4IDAwMDAwIG4gCjAwMDAwMDU1NjAgMDAwMDAgbiAKMDAwMDAwNTY0MCAwMDAwMCBuIAp0cmFpbGVyCjw8IC9JbmZvIDI5IDAgUiAvUm9vdCAxIDAgUiAvU2l6ZSAzMCA+PgpzdGFydHhyZWYKNTc5NwolJUVPRgo=\n",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"163.89pt\" height=\"111.058125pt\" viewBox=\"0 0 163.89 111.058125\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2022-06-10T09:54:08.577278</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M -0 111.058125 \n",
       "L 163.89 111.058125 \n",
       "L 163.89 0 \n",
       "L -0 0 \n",
       "L -0 111.058125 \n",
       "z\n",
       "\" style=\"fill: none\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g clip-path=\"url(#p4a1fd773e7)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "iVBORw0KGgoAAAANSUhEUgAAAJYAAABSCAYAAAC2eC1AAAABC0lEQVR4nO3UUQqDQBAFwRhy73FPbu4gNopU/Q+8hWa3mTk+cLHv3QN4J2GREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWid/Zw33fL5zxHGfftda6dshDzMypOz8WCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFoltZo67R/A+fiwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSf4fmC50MFDSrAAAAAElFTkSuQmCC\" id=\"image404c28641c\" transform=\"scale(1 -1)translate(0 -82)\" x=\"7.2\" y=\"-21.858125\" width=\"150\" height=\"82\"/>\n",
       "   </g>\n",
       "   <g id=\"text_1\">\n",
       "    <!-- Channel mask -->\n",
       "    <g transform=\"translate(39.284063 16.318125)scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-43\" d=\"M 4122 4306 \n",
       "L 4122 3641 \n",
       "Q 3803 3938 3442 4084 \n",
       "Q 3081 4231 2675 4231 \n",
       "Q 1875 4231 1450 3742 \n",
       "Q 1025 3253 1025 2328 \n",
       "Q 1025 1406 1450 917 \n",
       "Q 1875 428 2675 428 \n",
       "Q 3081 428 3442 575 \n",
       "Q 3803 722 4122 1019 \n",
       "L 4122 359 \n",
       "Q 3791 134 3420 21 \n",
       "Q 3050 -91 2638 -91 \n",
       "Q 1578 -91 968 557 \n",
       "Q 359 1206 359 2328 \n",
       "Q 359 3453 968 4101 \n",
       "Q 1578 4750 2638 4750 \n",
       "Q 3056 4750 3426 4639 \n",
       "Q 3797 4528 4122 4306 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6d\" d=\"M 3328 2828 \n",
       "Q 3544 3216 3844 3400 \n",
       "Q 4144 3584 4550 3584 \n",
       "Q 5097 3584 5394 3201 \n",
       "Q 5691 2819 5691 2113 \n",
       "L 5691 0 \n",
       "L 5113 0 \n",
       "L 5113 2094 \n",
       "Q 5113 2597 4934 2840 \n",
       "Q 4756 3084 4391 3084 \n",
       "Q 3944 3084 3684 2787 \n",
       "Q 3425 2491 3425 1978 \n",
       "L 3425 0 \n",
       "L 2847 0 \n",
       "L 2847 2094 \n",
       "Q 2847 2600 2669 2842 \n",
       "Q 2491 3084 2119 3084 \n",
       "Q 1678 3084 1418 2786 \n",
       "Q 1159 2488 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1356 3278 1631 3431 \n",
       "Q 1906 3584 2284 3584 \n",
       "Q 2666 3584 2933 3390 \n",
       "Q 3200 3197 3328 2828 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
       "L 2834 2853 \n",
       "Q 2591 2978 2328 3040 \n",
       "Q 2066 3103 1784 3103 \n",
       "Q 1356 3103 1142 2972 \n",
       "Q 928 2841 928 2578 \n",
       "Q 928 2378 1081 2264 \n",
       "Q 1234 2150 1697 2047 \n",
       "L 1894 2003 \n",
       "Q 2506 1872 2764 1633 \n",
       "Q 3022 1394 3022 966 \n",
       "Q 3022 478 2636 193 \n",
       "Q 2250 -91 1575 -91 \n",
       "Q 1294 -91 989 -36 \n",
       "Q 684 19 347 128 \n",
       "L 347 722 \n",
       "Q 666 556 975 473 \n",
       "Q 1284 391 1588 391 \n",
       "Q 1994 391 2212 530 \n",
       "Q 2431 669 2431 922 \n",
       "Q 2431 1156 2273 1281 \n",
       "Q 2116 1406 1581 1522 \n",
       "L 1381 1569 \n",
       "Q 847 1681 609 1914 \n",
       "Q 372 2147 372 2553 \n",
       "Q 372 3047 722 3315 \n",
       "Q 1072 3584 1716 3584 \n",
       "Q 2034 3584 2315 3537 \n",
       "Q 2597 3491 2834 3397 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6b\" d=\"M 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 1991 \n",
       "L 2875 3500 \n",
       "L 3609 3500 \n",
       "L 1753 1863 \n",
       "L 3688 0 \n",
       "L 2938 0 \n",
       "L 1159 1709 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-43\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-68\" x=\"69.824219\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"133.203125\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6e\" x=\"194.482422\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6e\" x=\"257.861328\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"321.240234\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"382.763672\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"410.546875\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6d\" x=\"442.333984\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"539.746094\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-73\" x=\"601.025391\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6b\" x=\"653.125\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p4a1fd773e7\">\n",
       "   <rect x=\"7.2\" y=\"22.318125\" width=\"149.49\" height=\"81.54\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 216x108 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkerboard_mask = create_checkerboard_mask(h=8, w=8).expand(-1,2,-1,-1)\n",
    "channel_mask = create_channel_mask(c_in=2).expand(-1,-1,8,8)\n",
    "\n",
    "show_imgs(checkerboard_mask.transpose(0,1), \"Checkerboard mask\")\n",
    "show_imgs(channel_mask.transpose(0,1), \"Channel mask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a last aspect of coupling layers, we need to decide for the deep neural network we want to apply in the coupling layers. The input to the layers is an image, and hence we stick with a CNN. Because the input to a transformation depends on all transformations before, it is crucial to ensure a good gradient flow through the CNN back to the input, which can be optimally achieved by a ResNet-like architecture. Specifically, we use a Gated ResNet that adds a $\\sigma$-gate to the skip connection, similarly to the input gate in LSTMs. The details are not necessarily important here, and the network is strongly inspired from Flow++ [3] in case you are interested in building even stronger models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatELU(nn.Module):\n",
    "    \"\"\"\n",
    "    Activation function that applies ELU in both direction (inverted and plain). \n",
    "    Allows non-linearity while providing strong gradients for any input (important for final convolution)\n",
    "    \"\"\"\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.cat([F.elu(x), F.elu(-x)], dim=1)\n",
    "\n",
    "    \n",
    "class LayerNormChannels(nn.Module):\n",
    "    \n",
    "    def __init__(self, c_in):\n",
    "        \"\"\"\n",
    "        This module applies layer norm across channels in an image. Has been shown to work well with ResNet connections.\n",
    "        Inputs: \n",
    "            c_in - Number of channels of the input\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.layer_norm = nn.LayerNorm(c_in)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = self.layer_norm(x)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        return x\n",
    "\n",
    "    \n",
    "class GatedConv(nn.Module):\n",
    "    \n",
    "    def __init__(self, c_in, c_hidden):\n",
    "        \"\"\"\n",
    "        This module applies a two-layer convolutional ResNet block with input gate\n",
    "        Inputs:\n",
    "            c_in - Number of channels of the input\n",
    "            c_hidden - Number of hidden dimensions we want to model (usually similar to c_in)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(c_in, c_hidden, kernel_size=3, padding=1),\n",
    "            ConcatELU(),\n",
    "            nn.Conv2d(2*c_hidden, 2*c_in, kernel_size=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        val, gate = out.chunk(2, dim=1)\n",
    "        return x + val * torch.sigmoid(gate)\n",
    "\n",
    "    \n",
    "class GatedConvNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, c_in, c_hidden=32, c_out=-1, num_layers=3):\n",
    "        \"\"\"\n",
    "        Module that summarizes the previous blocks to a full convolutional neural network.\n",
    "        Inputs:\n",
    "            c_in - Number of input channels\n",
    "            c_hidden - Number of hidden dimensions to use within the network\n",
    "            c_out - Number of output channels. If -1, 2 times the input channels are used (affine coupling)\n",
    "            num_layers - Number of gated ResNet blocks to apply\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        c_out = c_out if c_out > 0 else 2 * c_in\n",
    "        layers = []\n",
    "        layers += [nn.Conv2d(c_in, c_hidden, kernel_size=3, padding=1)]\n",
    "        for layer_index in range(num_layers):\n",
    "            layers += [GatedConv(c_hidden, c_hidden),\n",
    "                       LayerNormChannels(c_hidden)\n",
    "                      ]\n",
    "        layers += [ConcatELU(),\n",
    "                   nn.Conv2d(2*c_hidden, c_out, kernel_size=3, padding=1)]\n",
    "        self.nn = nn.Sequential(*layers)\n",
    "        \n",
    "        self.nn[-1].weight.data.zero_()\n",
    "        self.nn[-1].bias.data.zero_()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.nn(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "\n",
    "Finally, we can add Dequantization, Variational Dequantization and Coupling Layers together to build our full normalizing flow on MNIST images. We apply 8 coupling layers in the main flow, and 4 for variational dequantization if applied. We apply a checkerboard mask throughout the network as with a single channel (black-white images), we cannot apply channel mask. The overall architecture is visualized below.\n",
    "\n",
    "\n",
    "<center width=\"100%\" style=\"padding: 20px\"><img src=\"vanilla_flow.svg\" width=\"900px\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_simple_flow(use_vardeq=True):\n",
    "    flow_layers = []\n",
    "    if use_vardeq:\n",
    "        vardeq_layers = [CouplingLayer(network=GatedConvNet(c_in=2, c_out=2, c_hidden=16),\n",
    "                                       mask=create_checkerboard_mask(h=28, w=28, invert=(i%2==1)),\n",
    "                                       c_in=1) for i in range(4)]\n",
    "        flow_layers += [VariationalDequantization(var_flows=vardeq_layers)]\n",
    "    else:\n",
    "        flow_layers += [Dequantization()]\n",
    "    \n",
    "    for i in range(8):\n",
    "        flow_layers += [CouplingLayer(network=GatedConvNet(c_in=1, c_hidden=32),\n",
    "                                      mask=create_checkerboard_mask(h=28, w=28, invert=(i%2==1)),\n",
    "                                      c_in=1)]\n",
    "        \n",
    "    flow_model = ImageFlow(flow_layers).to(device)\n",
    "    return flow_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For implementing the training loop, we use the framework of PyTorch Lightning and reduce the code overhead. If interested, you can take a look at the generated tensorboard file, in particularly the graph to see an overview of flow transformations that are applied. Note that we again provide pre-trained models (see later on in the notebook) as normalizing flows are particularly expensive to train. We have also run validation and testing as this can take some time as well with the added importance sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_flow(flow, model_name=\"MNISTFlow\"):\n",
    "    # Create a PyTorch Lightning trainer\n",
    "    trainer = pl.Trainer(default_root_dir=os.path.join(CHECKPOINT_PATH, model_name), \n",
    "                         gpus=1 if torch.cuda.is_available() else 0, \n",
    "                         max_epochs=200, \n",
    "                         gradient_clip_val=1.0,\n",
    "                         callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"min\", monitor=\"val_bpd\"),\n",
    "                                    LearningRateMonitor(\"epoch\")],\n",
    "                        check_val_every_n_epoch=5)\n",
    "    trainer.logger._log_graph = True\n",
    "    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n",
    "    \n",
    "    train_data_loader = data.DataLoader(train_set, batch_size=128, shuffle=True, drop_last=True, pin_memory=True, num_workers=8, persistent_workers=True)\n",
    "    result = None\n",
    "    \n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    pretrained_filename = os.path.join(CHECKPOINT_PATH, model_name + \".ckpt\")\n",
    "    if False and os.path.isfile(pretrained_filename):\n",
    "        print(\"Found pretrained model, loading...\")\n",
    "        ckpt = torch.load(pretrained_filename)\n",
    "        flow.load_state_dict(ckpt['state_dict'])\n",
    "        result = ckpt.get(\"result\", None)\n",
    "    else:\n",
    "        print(\"Start training\", model_name)\n",
    "        trainer.fit(flow, train_data_loader, val_loader)\n",
    "    \n",
    "    # Test best model on validation and test set if no result has been found\n",
    "    # Testing can be expensive due to the importance sampling.\n",
    "    if result is None:\n",
    "        val_result = trainer.test(flow, val_loader, verbose=False)\n",
    "        start_time = time.time()\n",
    "        test_result = trainer.test(flow, test_loader, verbose=False)\n",
    "        duration = time.time() - start_time\n",
    "        result = {\"test\": test_result, \"val\": val_result, \"time\": duration / len(test_loader) / flow.import_samples}\n",
    "    \n",
    "    return flow, result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-scale architecture\n",
    "\n",
    "One disadvantage of normalizing flows is that they operate on the exact same dimensions as the input. If the input is high-dimensional, so is the latent space, which requires larger computational cost to learn suitable transformations. However, particularly in the image domain, many pixels contain less information in the sense that we could remove them without loosing the semantical information of the image. \n",
    "\n",
    "Based on this intuition, deep normalizing flows on images commonly apply a multi-scale architecture [1]. After the first $N$ flow transformations, we split off half of the latent dimensions and directly evaluate them on the prior. The other half is run through $N$ more flow transformations, and depending on the size of the input, we split it again in half or stop overall at this position. The two operations involved in this setup is `Squeeze` and `Split` which we will review more closely and implement below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squeeze and Split\n",
    "\n",
    "When we want to remove half of the pixels in an image, we have the problem of deciding which variables to cut, and how to rearrange the image. Thus, the squeezing operation is commonly used before split, which divides the image into subsquares of shape $2\\times 2\\times C$, and reshapes them into $1\\times 1\\times 4C$ blocks. Effectively, we reduce the height and width of the image by a factor of 2 while scaling the number of channels by 4. Afterwards, we can perform the split operation over channels without the need of rearranging the pixels. The smaller scale also makes the overall architecture more efficient. Visually, the squeeze operation should transform the input as follows:\n",
    "\n",
    "<center><img src=\"Squeeze_operation.svg\" width=\"40%\"/></center>\n",
    "\n",
    "The input of $4\\times 4\\times 1$ is scaled to $2\\times 2\\times 4$ following the idea of grouping the pixels in $2\\times 2\\times 1$ subsquares. Next, let's try to implement this layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqueezeFlow(nn.Module):\n",
    "    \n",
    "    def forward(self, z, ldj, reverse=False):\n",
    "        B, C, H, W = z.shape\n",
    "        if not reverse: \n",
    "            # Forward direction: H x W x C => H/2 x W/2 x 4C\n",
    "            z = z.reshape(B, C, H//2, 2, W//2, 2)\n",
    "            z = z.permute(0, 1, 3, 5, 2, 4)\n",
    "            z = z.reshape(B, 4*C, H//2, W//2)\n",
    "        else: \n",
    "            # Reverse direction: H/2 x W/2 x 4C => H x W x C\n",
    "            z = z.reshape(B, C//4, 2, 2, H, W)\n",
    "            z = z.permute(0, 1, 4, 2, 5, 3)\n",
    "            z = z.reshape(B, C//4, H*2, W*2)\n",
    "        return z, ldj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on, we can verify our implementation by comparing our output with the example figure above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image (before)\n",
      " tensor([[[[ 1,  2,  3,  4],\n",
      "          [ 5,  6,  7,  8],\n",
      "          [ 9, 10, 11, 12],\n",
      "          [13, 14, 15, 16]]]])\n",
      "\n",
      "Image (forward)\n",
      " tensor([[[[ 1,  2,  5,  6],\n",
      "          [ 3,  4,  7,  8]],\n",
      "\n",
      "         [[ 9, 10, 13, 14],\n",
      "          [11, 12, 15, 16]]]])\n",
      "\n",
      "Image (reverse)\n",
      " tensor([[[[ 1,  2,  3,  4],\n",
      "          [ 5,  6,  7,  8],\n",
      "          [ 9, 10, 11, 12],\n",
      "          [13, 14, 15, 16]]]])\n"
     ]
    }
   ],
   "source": [
    "sq_flow = SqueezeFlow()\n",
    "rand_img = torch.arange(1,17).view(1, 1, 4, 4)\n",
    "print(\"Image (before)\\n\", rand_img)\n",
    "forward_img, _ = sq_flow(rand_img, ldj=None, reverse=False)\n",
    "print(\"\\nImage (forward)\\n\", forward_img.permute(0,2,3,1)) # Permute for readability\n",
    "reconst_img, _ = sq_flow(forward_img, ldj=None, reverse=True)\n",
    "print(\"\\nImage (reverse)\\n\", reconst_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The split operation divides the input into two parts, and evaluates one part directly on the prior. So that our flow operation fits to the implementation of the previous layers, we will return the prior probability of the first part as the log determinant jacobian of the layer. It has the same effect as if we would combine all variable splits at the end of the flow, and evaluate them together on the prior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitFlow(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.prior = torch.distributions.normal.Normal(loc=0.0, scale=1.0)\n",
    "    \n",
    "    def forward(self, z, ldj, reverse=False):\n",
    "        if not reverse:\n",
    "            z, z_split = z.chunk(2, dim=1)\n",
    "            ldj += self.prior.log_prob(z_split).sum(dim=[1,2,3])\n",
    "        else:\n",
    "            z_split = self.prior.sample(sample_shape=z.shape).to(device)\n",
    "            z = torch.cat([z, z_split], dim=1)\n",
    "            ldj -= self.prior.log_prob(z_split).sum(dim=[1,2,3])\n",
    "        return z, ldj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a multi-scale flow\n",
    "\n",
    "After defining the squeeze and split operation, we are finally able to build our own multi-scale flow. Deep normalizing flows such as Glow and Flow++ [2,3] often apply a split operation directly after squeezing. However, with shallow flows, we need to be more thoughtful about where to place the split operation as we need at least a minimum amount of transformations on each variable. Our setup is inspired by the original RealNVP architecture [1] which is shallower than other, more recent state-of-the-art architectures. \n",
    "\n",
    "Hence, for the MNIST dataset, we will apply the first squeeze operation after two coupling layers, but don't apply a split operation yet. Because we have only used two coupling layers and each the variable has been only transformed once, a split operation would be too early. We apply two more coupling layers before finally applying a split flow and squeeze again. The last four coupling layers operate on a scale of $7\\times 7\\times 8$. The full flow architecture is shown below.\n",
    "\n",
    "<center width=\"100%\" style=\"padding: 20px\"><img src=\"multiscale_flow.svg\" width=\"1100px\"></center>\n",
    "\n",
    "Note that while the feature maps inside the coupling layers reduce with the height and width of the input, the increased number of channels is not directly considered. To counteract this, we increase the hidden dimensions for the coupling layers on the squeezed input. The dimensions are often scaled by 2 as this approximately increases the computation cost by 4 canceling with the squeezing operation. However, we will choose the hidden dimensionalities $32, 48, 64$ for the three scales respectively to keep the number of parameters reasonable and show the efficiency of multi-scale architectures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multiscale_flow():\n",
    "    flow_layers = []\n",
    "    \n",
    "    vardeq_layers = [CouplingLayer(network=GatedConvNet(c_in=2, c_out=2, c_hidden=16),\n",
    "                                   mask=create_checkerboard_mask(h=28, w=28, invert=(i%2==1)),\n",
    "                                   c_in=1) for i in range(4)]\n",
    "    flow_layers += [VariationalDequantization(vardeq_layers)]\n",
    "    \n",
    "    flow_layers += [CouplingLayer(network=GatedConvNet(c_in=1, c_hidden=32),\n",
    "                                  mask=create_checkerboard_mask(h=28, w=28, invert=(i%2==1)),\n",
    "                                  c_in=1) for i in range(2)]\n",
    "    flow_layers += [SqueezeFlow()]\n",
    "    for i in range(2):\n",
    "        flow_layers += [CouplingLayer(network=GatedConvNet(c_in=4, c_hidden=48),\n",
    "                                      mask=create_channel_mask(c_in=4, invert=(i%2==1)),\n",
    "                                      c_in=4)]\n",
    "    flow_layers += [SplitFlow(),\n",
    "                    SqueezeFlow()]\n",
    "    for i in range(4):\n",
    "        flow_layers += [CouplingLayer(network=GatedConvNet(c_in=8, c_hidden=64),\n",
    "                                      mask=create_channel_mask(c_in=8, invert=(i%2==1)),\n",
    "                                      c_in=8)]\n",
    "\n",
    "    flow_model = ImageFlow(flow_layers).to(device)\n",
    "    return flow_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can show the difference in number of parameters below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 333,592\n",
      "Number of parameters: 377,636\n",
      "Number of parameters: 1,059,210\n"
     ]
    }
   ],
   "source": [
    "def print_num_params(model):\n",
    "    num_params = sum([np.prod(p.shape) for p in model.parameters()])\n",
    "    print(\"Number of parameters: {:,}\".format(num_params))\n",
    "\n",
    "print_num_params(create_simple_flow(use_vardeq=False))\n",
    "print_num_params(create_simple_flow(use_vardeq=True))\n",
    "print_num_params(create_multiscale_flow())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the multi-scale flow has almost 3 times the parameters of the single scale flow, it is not necessarily more computationally expensive than its counterpart. We will compare the runtime in the following experiments as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing the flows\n",
    "\n",
    "In the last part of the notebook, we will train all the models we have implemented above, and try to analyze the effect of the multi-scale architecture and variational dequantization.\n",
    "\n",
    "### Training flow variants\n",
    "\n",
    "Before we can analyse the flow models, we need to train them first. We provide pre-trained models that contain the validation and test performance, and run-time information. As flow models are computationally expensive, we advice you to rely on those pretrained models for a first run through the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type       | Params | In sizes | Out sizes\n",
      "------------------------------------------------------------\n",
      "0 | flows | ModuleList | 333 K  | ?        | ?        \n",
      "------------------------------------------------------------\n",
      "333 K     Trainable params\n",
      "0         Non-trainable params\n",
      "333 K     Total params\n",
      "1.334     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training MNISTFlow_simple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py:983: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Scalars are not close!\n",
      "\n",
      "Absolute difference: 0.07523536682128906 (up to 1e-05 allowed)\n",
      "Relative difference: 0.0030093485494703484 (up to 1e-05 allowed)\n",
      "\n",
      "  _check_trace(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db85c822f6b4e129ba27bef48c145be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:726: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py:983: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Scalars are not close!\n",
      "\n",
      "Absolute difference: 0.0025191307067871094 (up to 1e-05 allowed)\n",
      "Relative difference: 0.001099329508881877 (up to 1e-05 allowed)\n",
      "\n",
      "  _check_trace(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "791cfab72a8f4c759d7dc2815cdaca96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py:983: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Scalars are not close!\n",
      "\n",
      "Absolute difference: 0.03911709785461426 (up to 1e-05 allowed)\n",
      "Relative difference: 0.01694422859966101 (up to 1e-05 allowed)\n",
      "\n",
      "  _check_trace(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe31888f113d4608ba976e40cda10c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type       | Params | In sizes | Out sizes\n",
      "------------------------------------------------------------\n",
      "0 | flows | ModuleList | 377 K  | ?        | ?        \n",
      "------------------------------------------------------------\n",
      "377 K     Trainable params\n",
      "0         Non-trainable params\n",
      "377 K     Total params\n",
      "1.511     Total estimated model params size (MB)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training MNISTFlow_vardeq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py:983: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Scalars are not close!\n",
      "\n",
      "Absolute difference: 0.33090782165527344 (up to 1e-05 allowed)\n",
      "Relative difference: 0.013023213148737913 (up to 1e-05 allowed)\n",
      "\n",
      "  _check_trace(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type       | Params | In sizes | Out sizes\n",
      "------------------------------------------------------------\n",
      "0 | flows | ModuleList | 1.1 M  | ?        | ?        \n",
      "------------------------------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "4.237     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training MNISTFlow_multiscale\n",
      "KeyboardInterrupt: \n",
      "\n",
      "At:\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py(34): _get_interpreter_name_for_var\n",
      "  /tmp/ipykernel_941215/611720880.py(47): forward\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py(1098): _slow_forward\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py(1110): _call_impl\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/container.py(141): forward\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py(1098): _slow_forward\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py(1110): _call_impl\n",
      "  /tmp/ipykernel_941215/611720880.py(78): forward\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py(1098): _slow_forward\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py(1110): _call_impl\n",
      "  /tmp/ipykernel_941215/2207169096.py(35): forward\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py(1098): _slow_forward\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py(1110): _call_impl\n",
      "  /tmp/ipykernel_941215/2045456721.py(21): dequant\n",
      "  /tmp/ipykernel_941215/1533989549.py(16): forward\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py(1098): _slow_forward\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py(1110): _call_impl\n",
      "  /tmp/ipykernel_941215/1925916185.py(25): encode\n",
      "  /tmp/ipykernel_941215/1925916185.py(34): _get_likelihood\n",
      "  /tmp/ipykernel_941215/1925916185.py(19): forward\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py(1098): _slow_forward\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py(1110): _call_impl\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py(958): trace_module\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py(741): trace\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/tensorboard/_pytorch_graph.py(291): graph\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/tensorboard/writer.py(736): add_graph\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/loggers/tensorboard.py(247): log_graph\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/utilities/rank_zero.py(32): wrapped_fn\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py(1293): _log_hyperparams\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py(1224): _run\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py(811): _fit_impl\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py(723): _call_and_handle_interrupt\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py(770): fit\n",
      "  /tmp/ipykernel_941215/2430944633.py(25): train_flow\n",
      "  /tmp/ipykernel_941215/3044067802.py(4): <cell line: 4>\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3397): run_code\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3337): run_ast_nodes\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3134): run_cell_async\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/core/async_helpers.py(129): _pseudo_sync_runner\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/core/interactiveshell.py(2935): _run_cell\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/core/interactiveshell.py(2880): run_cell\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/ipykernel/zmqshell.py(532): run_cell\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/ipykernel/ipkernel.py(360): do_execute\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/ipykernel/kernelbase.py(662): execute_request\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/ipykernel/kernelbase.py(367): dispatch_shell\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/ipykernel/kernelbase.py(460): process_one\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/ipykernel/kernelbase.py(471): dispatch_queue\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/asyncio/events.py(81): _run\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/asyncio/base_events.py(1859): _run_once\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/asyncio/base_events.py(570): run_forever\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/tornado/platform/asyncio.py(199): start\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/ipykernel/kernelapp.py(677): start\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/traitlets/config/application.py(846): launch_instance\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/ipykernel_launcher.py(16): <module>\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/runpy.py(86): _run_code\n",
      "  /home/plippe/anaconda3/envs/torch/lib/python3.8/runpy.py(193): _run_module_as_main\n",
      "\n",
      "Error occurs, No graph saved\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "KeyboardInterrupt: \n\nAt:\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py(34): _get_interpreter_name_for_var\n  /tmp/ipykernel_941215/611720880.py(47): forward\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py(1098): _slow_forward\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py(1110): _call_impl\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/container.py(141): forward\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py(1098): _slow_forward\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py(1110): _call_impl\n  /tmp/ipykernel_941215/611720880.py(78): forward\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py(1098): _slow_forward\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py(1110): _call_impl\n  /tmp/ipykernel_941215/2207169096.py(35): forward\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py(1098): _slow_forward\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py(1110): _call_impl\n  /tmp/ipykernel_941215/2045456721.py(21): dequant\n  /tmp/ipykernel_941215/1533989549.py(16): forward\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py(1098): _slow_forward\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py(1110): _call_impl\n  /tmp/ipykernel_941215/1925916185.py(25): encode\n  /tmp/ipykernel_941215/1925916185.py(34): _get_likelihood\n  /tmp/ipykernel_941215/1925916185.py(19): forward\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py(1098): _slow_forward\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py(1110): _call_impl\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py(958): trace_module\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py(741): trace\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/tensorboard/_pytorch_graph.py(291): graph\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/tensorboard/writer.py(736): add_graph\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/loggers/tensorboard.py(247): log_graph\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/utilities/rank_zero.py(32): wrapped_fn\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py(1293): _log_hyperparams\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py(1224): _run\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py(811): _fit_impl\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py(723): _call_and_handle_interrupt\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py(770): fit\n  /tmp/ipykernel_941215/2430944633.py(25): train_flow\n  /tmp/ipykernel_941215/3044067802.py(4): <cell line: 4>\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3397): run_code\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3337): run_ast_nodes\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3134): run_cell_async\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/core/async_helpers.py(129): _pseudo_sync_runner\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/core/interactiveshell.py(2935): _run_cell\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/core/interactiveshell.py(2880): run_cell\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/ipykernel/zmqshell.py(532): run_cell\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/ipykernel/ipkernel.py(360): do_execute\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/ipykernel/kernelbase.py(662): execute_request\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/ipykernel/kernelbase.py(367): dispatch_shell\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/ipykernel/kernelbase.py(460): process_one\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/ipykernel/kernelbase.py(471): dispatch_queue\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/asyncio/events.py(81): _run\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/asyncio/base_events.py(1859): _run_once\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/asyncio/base_events.py(570): run_forever\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/tornado/platform/asyncio.py(199): start\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/ipykernel/kernelapp.py(677): start\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/traitlets/config/application.py(846): launch_instance\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/ipykernel_launcher.py(16): <module>\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/runpy.py(86): _run_code\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/runpy.py(193): _run_module_as_main\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m flow_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimple\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], flow_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimple\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m train_flow(create_simple_flow(use_vardeq\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMNISTFlow_simple\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m flow_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvardeq\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], flow_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvardeq\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m train_flow(create_simple_flow(use_vardeq\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMNISTFlow_vardeq\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m flow_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiscale\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], flow_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiscale\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_flow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcreate_multiscale_flow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMNISTFlow_multiscale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36mtrain_flow\u001b[0;34m(flow, model_name)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart training\u001b[39m\u001b[38;5;124m\"\u001b[39m, model_name)\n\u001b[0;32m---> 25\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Test best model on validation and test set if no result has been found\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Testing can be expensive due to the importance sampling.\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:770\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;124;03mRuns the full optimization routine.\u001b[39;00m\n\u001b[1;32m    753\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;124;03m    datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.\u001b[39;00m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m--> 770\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:723\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 723\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;66;03m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:811\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    807\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m ckpt_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_ckpt_path(\n\u001b[1;32m    809\u001b[0m     ckpt_path, model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    810\u001b[0m )\n\u001b[0;32m--> 811\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1224\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_fit_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1222\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_lightning_module_hook(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_fit_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1224\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_hyperparams\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mrestore_checkpoint_after_setup:\n\u001b[1;32m   1227\u001b[0m     log\u001b[38;5;241m.\u001b[39mdetail(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: restoring module and callbacks from checkpoint path: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mckpt_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1293\u001b[0m, in \u001b[0;36mTrainer._log_hyperparams\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hparams_initial \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1292\u001b[0m     logger\u001b[38;5;241m.\u001b[39mlog_hyperparams(hparams_initial)\n\u001b[0;32m-> 1293\u001b[0m \u001b[43mlogger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1294\u001b[0m logger\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/utilities/rank_zero.py:32\u001b[0m, in \u001b[0;36mrank_zero_only.<locals>.wrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Any]:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rank_zero_only\u001b[38;5;241m.\u001b[39mrank \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 32\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/loggers/tensorboard.py:247\u001b[0m, in \u001b[0;36mTensorBoardLogger.log_graph\u001b[0;34m(self, model, input_array)\u001b[0m\n\u001b[1;32m    245\u001b[0m     input_array \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39m_apply_batch_transfer_handler(input_array)\n\u001b[1;32m    246\u001b[0m     model\u001b[38;5;241m.\u001b[39m_running_torchscript \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_array\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m     model\u001b[38;5;241m.\u001b[39m_running_torchscript \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/tensorboard/writer.py:736\u001b[0m, in \u001b[0;36mSummaryWriter.add_graph\u001b[0;34m(self, model, input_to_model, verbose, use_strict_trace)\u001b[0m\n\u001b[1;32m    733\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_once(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorboard.logging.add_graph\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;66;03m# A valid PyTorch model should have a 'forward' method\u001b[39;00m\n\u001b[0;32m--> 736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_file_writer()\u001b[38;5;241m.\u001b[39madd_graph(\u001b[43mgraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_to_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_strict_trace\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    737\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;66;03m# Caffe2 models do not have the 'forward' method\u001b[39;00m\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcaffe2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m caffe2_pb2\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/tensorboard/_pytorch_graph.py:297\u001b[0m, in \u001b[0;36mgraph\u001b[0;34m(model, args, verbose, use_strict_trace)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[38;5;28mprint\u001b[39m(e)\n\u001b[1;32m    296\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError occurs, No graph saved\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 297\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28mprint\u001b[39m(graph)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/tensorboard/_pytorch_graph.py:291\u001b[0m, in \u001b[0;36mgraph\u001b[0;34m(model, args, verbose, use_strict_trace)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39monnx\u001b[38;5;241m.\u001b[39mselect_model_mode_for_export(model, torch\u001b[38;5;241m.\u001b[39monnx\u001b[38;5;241m.\u001b[39mTrainingMode\u001b[38;5;241m.\u001b[39mEVAL):  \u001b[38;5;66;03m# TODO: move outside of torch.onnx?\u001b[39;00m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 291\u001b[0m         trace \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_strict_trace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m         graph \u001b[38;5;241m=\u001b[39m trace\u001b[38;5;241m.\u001b[39mgraph\n\u001b[1;32m    293\u001b[0m         torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_jit_pass_inline(graph)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py:741\u001b[0m, in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func\n\u001b[1;32m    740\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m--> 741\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforward\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_trace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrap_check_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_inputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_tolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_module_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    754\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(func, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule)\n\u001b[1;32m    756\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    757\u001b[0m ):\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trace_module(\n\u001b[1;32m    759\u001b[0m         func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m,\n\u001b[1;32m    760\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m: example_inputs},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    767\u001b[0m         _module_class,\n\u001b[1;32m    768\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py:958\u001b[0m, in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    954\u001b[0m     argument_names \u001b[38;5;241m=\u001b[39m get_callable_argument_names(func)\n\u001b[1;32m    956\u001b[0m example_inputs \u001b[38;5;241m=\u001b[39m make_tuple(example_inputs)\n\u001b[0;32m--> 958\u001b[0m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_c\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_method_from_trace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvar_lookup_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43margument_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    967\u001b[0m check_trace_method \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_c\u001b[38;5;241m.\u001b[39m_get_method(method_name)\n\u001b[1;32m    969\u001b[0m \u001b[38;5;66;03m# Check the trace against new traces created from user-specified inputs\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1098\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1096\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1098\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mImageFlow.forward\u001b[0;34m(self, imgs)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, imgs):\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# The forward function is only used for visualizing the graph\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_likelihood\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mImageFlow._get_likelihood\u001b[0;34m(self, imgs, return_ll)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_likelihood\u001b[39m(\u001b[38;5;28mself\u001b[39m, imgs, return_ll\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    Given a batch of images, return the likelihood of those. \u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m    If return_ll is True, this function returns the log likelihood of the input.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m    Otherwise, the ouptut metric is bits per dimension (scaled negative log likelihood)\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m     z, ldj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     log_pz \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprior\u001b[38;5;241m.\u001b[39mlog_prob(z)\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m     36\u001b[0m     log_px \u001b[38;5;241m=\u001b[39m ldj \u001b[38;5;241m+\u001b[39m log_pz\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mImageFlow.encode\u001b[0;34m(self, imgs)\u001b[0m\n\u001b[1;32m     23\u001b[0m z, ldj \u001b[38;5;241m=\u001b[39m imgs, torch\u001b[38;5;241m.\u001b[39mzeros(imgs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m flow \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflows:\n\u001b[0;32m---> 25\u001b[0m     z, ldj \u001b[38;5;241m=\u001b[39m \u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mldj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m z, ldj\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1098\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1096\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1098\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mDequantization.forward\u001b[0;34m(self, z, ldj, reverse)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, z, ldj, reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m reverse:\n\u001b[0;32m---> 16\u001b[0m         z, ldj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdequant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mldj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m         z, ldj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid(z, ldj, reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36mVariationalDequantization.dequant\u001b[0;34m(self, z, ldj)\u001b[0m\n\u001b[1;32m     19\u001b[0m deq_noise, ldj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid(deq_noise, ldj, reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m flow \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflows:\n\u001b[0;32m---> 21\u001b[0m     deq_noise, ldj \u001b[38;5;241m=\u001b[39m \u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeq_noise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mldj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_img\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m deq_noise, ldj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid(deq_noise, ldj, reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# After the flows, apply u as in standard dequantization\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1098\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1096\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1098\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36mCouplingLayer.forward\u001b[0;34m(self, z, ldj, reverse, orig_img)\u001b[0m\n\u001b[1;32m     33\u001b[0m     nn_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork(z_in)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 35\u001b[0m     nn_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mz_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_img\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m s, t \u001b[38;5;241m=\u001b[39m nn_out\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Stabilize scaling output\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1098\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1096\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1098\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36mGatedConvNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1098\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1096\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1098\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1098\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1096\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1098\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36mGatedConv.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     46\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet(x)\n\u001b[0;32m---> 47\u001b[0m     val, gate \u001b[38;5;241m=\u001b[39m \u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m+\u001b[39m val \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(gate)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: KeyboardInterrupt: \n\nAt:\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py(34): _get_interpreter_name_for_var\n  /tmp/ipykernel_941215/611720880.py(47): forward\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py(1098): _slow_forward\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py(1110): _call_impl\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/container.py(141): forward\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py(1098): _slow_forward\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py(1110): _call_impl\n  /tmp/ipykernel_941215/611720880.py(78): forward\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py(1098): _slow_forward\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py(1110): _call_impl\n  /tmp/ipykernel_941215/2207169096.py(35): forward\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py(1098): _slow_forward\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py(1110): _call_impl\n  /tmp/ipykernel_941215/2045456721.py(21): dequant\n  /tmp/ipykernel_941215/1533989549.py(16): forward\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py(1098): _slow_forward\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py(1110): _call_impl\n  /tmp/ipykernel_941215/1925916185.py(25): encode\n  /tmp/ipykernel_941215/1925916185.py(34): _get_likelihood\n  /tmp/ipykernel_941215/1925916185.py(19): forward\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py(1098): _slow_forward\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py(1110): _call_impl\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py(958): trace_module\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/jit/_trace.py(741): trace\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/tensorboard/_pytorch_graph.py(291): graph\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/tensorboard/writer.py(736): add_graph\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/loggers/tensorboard.py(247): log_graph\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/utilities/rank_zero.py(32): wrapped_fn\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py(1293): _log_hyperparams\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py(1224): _run\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py(811): _fit_impl\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py(723): _call_and_handle_interrupt\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py(770): fit\n  /tmp/ipykernel_941215/2430944633.py(25): train_flow\n  /tmp/ipykernel_941215/3044067802.py(4): <cell line: 4>\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3397): run_code\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3337): run_ast_nodes\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3134): run_cell_async\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/core/async_helpers.py(129): _pseudo_sync_runner\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/core/interactiveshell.py(2935): _run_cell\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/core/interactiveshell.py(2880): run_cell\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/ipykernel/zmqshell.py(532): run_cell\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/ipykernel/ipkernel.py(360): do_execute\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/ipykernel/kernelbase.py(662): execute_request\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/ipykernel/kernelbase.py(367): dispatch_shell\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/ipykernel/kernelbase.py(460): process_one\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/ipykernel/kernelbase.py(471): dispatch_queue\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/asyncio/events.py(81): _run\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/asyncio/base_events.py(1859): _run_once\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/asyncio/base_events.py(570): run_forever\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/tornado/platform/asyncio.py(199): start\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/ipykernel/kernelapp.py(677): start\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/traitlets/config/application.py(846): launch_instance\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/site-packages/ipykernel_launcher.py(16): <module>\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/runpy.py(86): _run_code\n  /home/plippe/anaconda3/envs/torch/lib/python3.8/runpy.py(193): _run_module_as_main\n"
     ]
    }
   ],
   "source": [
    "flow_dict = {\"simple\": {}, \"vardeq\": {}, \"multiscale\": {}}\n",
    "flow_dict[\"simple\"][\"model\"], flow_dict[\"simple\"][\"result\"] = train_flow(create_simple_flow(use_vardeq=False), model_name=\"MNISTFlow_simple\")\n",
    "flow_dict[\"vardeq\"][\"model\"], flow_dict[\"vardeq\"][\"result\"] = train_flow(create_simple_flow(use_vardeq=True), model_name=\"MNISTFlow_vardeq\")\n",
    "flow_dict[\"multiscale\"][\"model\"], flow_dict[\"multiscale\"][\"result\"] = train_flow(create_multiscale_flow(), model_name=\"MNISTFlow_multiscale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Density modeling and sampling\n",
    "\n",
    "Firstly, we can compare the models on their quantitative results. The following table shows all important statistics. The inference time specifies the time needed to determine the probability for a batch of 64 images for each model, and the sampling time the duration it took to sample a batch of 64 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- Some HTML code to increase font size in the following table -->\n",
       "<style>\n",
       "th {font-size: 120%;}\n",
       "td {font-size: 120%;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<!-- Some HTML code to increase font size in the following table -->\n",
    "<style>\n",
    "th {font-size: 120%;}\n",
    "td {font-size: 120%;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Model     </th><th>Validation Bpd  </th><th>Test Bpd  </th><th>Inference time  </th><th>Sampling time  </th><th>Num Parameters  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>simple    </td><td>1.090 bpd       </td><td>1.088 bpd </td><td>17 ms           </td><td>0 ms           </td><td>335,128         </td></tr>\n",
       "<tr><td>vardeq    </td><td>1.054 bpd       </td><td>1.052 bpd </td><td>23 ms           </td><td>0 ms           </td><td>379,556         </td></tr>\n",
       "<tr><td>multiscale</td><td>1.030 bpd       </td><td>1.028 bpd </td><td>21 ms           </td><td>0 ms           </td><td>1,062,090       </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tabulate\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "table = [[key, \n",
    "          \"%4.3f bpd\" % flow_dict[key][\"result\"][\"val\"][0][\"test_bpd\"], \n",
    "          \"%4.3f bpd\" % flow_dict[key][\"result\"][\"test\"][0][\"test_bpd\"], \n",
    "          \"%2.0f ms\" % (1000 * flow_dict[key][\"result\"][\"time\"]),\n",
    "          \"%2.0f ms\" % (1000 * flow_dict[key][\"result\"].get(\"samp_time\", 0)),\n",
    "          \"{:,}\".format(sum([np.prod(p.shape) for p in flow_dict[key][\"model\"].parameters()]))] \n",
    "         for key in flow_dict]\n",
    "display(HTML(tabulate.tabulate(table, tablefmt='html', headers=[\"Model\", \"Validation Bpd\", \"Test Bpd\", \"Inference time\", \"Sampling time\", \"Num Parameters\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have intially expected, using variational dequantization improves upon standard dequantization in terms of bits per dimension. Although the difference with 0.04bpd doesn't seem impressive first, it is a considerably step for generative models (most state-of-the-art models improve upon previous models in a range of 0.02-0.1bpd on CIFAR with three times as high bpd). While it takes longer to evaluate the probability of an image due to the variational dequantization, which also leads to a longer training time, it does not have an effect on the sampling time. This is because inverting variational dequantization is the same as dequantization: finding the next lower integer.\n",
    "\n",
    "When we compare the two models to multi-scale architecture, we can see that the bits per dimension score again dropped by about 0.04bpd. Additionally, the inference time and sampling time improved notably despite having more parameters. Thus, we see that the multi-scale flow is not only stronger for density modeling, but also more efficient. \n",
    "\n",
    "Next, we can test the sampling quality of the models. We should note that the samples for variational dequantization and standard dequantization are very similar, and hence we visualize here only the ones for variational dequantization and the multi-scale model. However, feel free to also test out the `\"simple\"` model. The seeds are set to obtain reproducable generations and are not cherry picked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 44\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m pl\u001b[38;5;241m.\u001b[39mseed_everything(\u001b[38;5;241m44\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[43mflow_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvardeq\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m show_imgs(samples\u001b[38;5;241m.\u001b[39mcpu())\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mImageFlow.sample\u001b[0;34m(self, img_shape, z_init)\u001b[0m\n\u001b[1;32m     54\u001b[0m ldj \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(img_shape[\u001b[38;5;241m0\u001b[39m], device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m flow \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflows):\n\u001b[0;32m---> 56\u001b[0m     z, ldj \u001b[38;5;241m=\u001b[39m \u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mldj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m z\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36mCouplingLayer.forward\u001b[0;34m(self, z, ldj, reverse, orig_img)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03mInputs:\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m    z - Latent input to the flow\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m                          input to condition the flow on (e.g. original image)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Apply network to masked input\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m z_in \u001b[38;5;241m=\u001b[39m \u001b[43mz\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmask\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orig_img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     nn_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork(z_in)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(44)\n",
    "samples = flow_dict[\"vardeq\"][\"model\"].sample(img_shape=[16,1,28,28])\n",
    "show_imgs(samples.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(44)\n",
    "samples = flow_dict[\"multiscale\"][\"model\"].sample(img_shape=[16,8,7,7])\n",
    "show_imgs(samples.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the few samples, we can see a clear difference between the simple and the multi-scale model. The single-scale model has only learned local, small correlations while the multi-scale model was able to learn full, global relations that form digits. This show-cases another benefit of the multi-scale model. In contrast to VAEs, the outputs are sharp as normalizing flows can naturally model complex, multi-modal distributions while VAEs have the independent decoder output noise. Nevertheless, the samples from this flow are far from perfect as not all samples show true digits. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolation in latent space\n",
    "\n",
    "Another popular test for the smoothness of the latent space of generative models is to interpolate between two training examples. As normalizing flows are strictly invertible, we can guarantee that any image is represented in the latent space. We again compare the variational dequantization model with the multi-scale model below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def interpolate(model, img1, img2, num_steps=8):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        model - object of ImageFlow class that represents the (trained) flow model\n",
    "        img1, img2 - Image tensors of shape [1, 28, 28]. Images between which should be interpolated.\n",
    "        num_steps - Number of interpolation steps. 8 interpolation steps mean 6 intermediate pictures besides img1 and img2\n",
    "    \"\"\"\n",
    "    imgs = torch.stack([img1, img2], dim=0).to(model.device)\n",
    "    z, _ = model.encode(imgs)\n",
    "    alpha = torch.linspace(0, 1, steps=num_steps, device=z.device).view(-1, 1, 1, 1)\n",
    "    interpolations = z[0:1] * alpha + z[1:2] * (1 - alpha)\n",
    "    interp_imgs = model.sample(interpolations.shape[:1] + imgs.shape[1:], z_init=interpolations)\n",
    "    show_imgs(interp_imgs, row_size=8)\n",
    "\n",
    "exmp_imgs, _ = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(42)\n",
    "for i in range(2):\n",
    "    interpolate(flow_dict[\"vardeq\"][\"model\"], exmp_imgs[2*i], exmp_imgs[2*i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(42)\n",
    "for i in range(2):\n",
    "    interpolate(flow_dict[\"multiscale\"][\"model\"], exmp_imgs[2*i], exmp_imgs[2*i+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interpolations of the multi-scale model result in more realistic digits (first row $7\\leftrightarrow 8\\leftrightarrow 6$, second row $9\\leftrightarrow 4\\leftrightarrow 6$), while the variational dequantization model focuses on local patterns that globally do not form a digit. For the multi-scale model, we actually did not do the \"true\" interpolation between the two images as we did not consider the variables that were split along the flow (they have been sampled randomly for all samples). However, as we will see in the next experiment, the early variables do not effect the overall image much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of latents in different levels of multi-scale\n",
    "\n",
    "In the following we will focus more on the multi-scale flow. We want to analyse what information is being stored in the variables split at early layers, and what information for the final variables. For this, we sample 8 images where each of them share the same final latent variables, but differ in the other part of the latent variables. Below we visualize three examples of this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pl.seed_everything(44)\n",
    "for _ in range(3):\n",
    "    z_init = flow_dict[\"multiscale\"][\"model\"].prior.sample(sample_shape=[1,8,7,7])\n",
    "    z_init = z_init.expand(8, -1, -1, -1)\n",
    "    samples = flow_dict[\"multiscale\"][\"model\"].sample(img_shape=z_init.shape, z_init=z_init)\n",
    "    show_imgs(samples.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the early split variables indeed have a smaller effect on the image. Still, small differences can be spot when we look carefully at the borders of the digits. For instance, the hole at the top of the 8 changes for different samples although all of them represent the same coarse structure. This shows that the flow indeed learns to separate the higher-level information in the final variables, while the early split ones contain local noise patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Dequantization\n",
    "\n",
    "As a final part of this notebook, we will look at the effect of variational dequantization. We have motivated variational dequantization by the issue of sharp edges/boarders being difficult to model, and a flow would rather prefer smooth, prior-like distributions. To check how what noise distribution $q(u|x)$ the flows in the variational dequantization module have learned, we can plot a histogram of output values from the dequantization and variational dequantization module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_dequant_distribution(model : ImageFlow, imgs : torch.Tensor, title:str=None):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        model - The flow of which we want to visualize the dequantization distribution\n",
    "        imgs - Example training images of which we want to visualize the dequantization distribution \n",
    "    \"\"\"\n",
    "    imgs = imgs.to(device)\n",
    "    ldj = torch.zeros(imgs.shape[0], dtype=torch.float32).to(device)\n",
    "    with torch.no_grad():\n",
    "        dequant_vals = []\n",
    "        for _ in tqdm(range(8), leave=False):\n",
    "            d, _ = model.flows[0](imgs, ldj, reverse=False)\n",
    "            dequant_vals.append(d)\n",
    "        dequant_vals = torch.cat(dequant_vals, dim=0)\n",
    "    dequant_vals = dequant_vals.view(-1).cpu().numpy()\n",
    "    sns.set()\n",
    "    plt.figure(figsize=(10,3))\n",
    "    plt.hist(dequant_vals, bins=256, color=to_rgb(\"C0\")+(0.5,), edgecolor=\"C0\", density=True)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "sample_imgs, _ = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_dequant_distribution(flow_dict[\"simple\"][\"model\"], sample_imgs, title=\"Dequantization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_dequant_distribution(flow_dict[\"vardeq\"][\"model\"], sample_imgs, title=\"Variational dequantization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dequantization distribution in the first plot shows that the MNIST images have a strong bias towards 0 (black), and the distribution of them have a sharp border as mentioned before. The variational dequantization module has indeed learned a much smoother distribution with a Gaussian-like curve which can be modeled much better. For the other values, we would need to visualize the distribution $q(u|x)$ on a deeper level, depending on $x$. However, as all $u$'s interact and depend on each other, we would need to visualize a distribution in 784 dimensions, which is not that intuitive anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In conclusion, we have seen how to implement our own normalizing flow, and what difficulties arise if we want to apply them on images. Dequantization is a crucial step in mapping the discrete images into continuous space to prevent underisable delta-peak solutions. While dequantization creates hypercubes with hard border, variational dequantization allows us to fit a flow much better on the data. This allows us to obtain a lower bits per dimension score, while not affecting the sampling speed. The most common flow element, the coupling layer, is simple to implement, and yet effective. Furthermore, multi-scale architectures help to capture the global image context while allowing us to efficiently scale up the flow. Normalizing flows are an interesting alternative to VAEs as they allow an exact likelihood estimate in continuous space, and we have the guarantee that every possible input $x$ has a corresponding latent vector $z$. However, even beyond continuous inputs and images, flows can be applied and allow us to exploit the data structure in latent space, as e.g. on graphs for the task of molecule generation [6]. Recent advances in [Neural ODEs](https://arxiv.org/pdf/1806.07366.pdf) allow a flow with infinite number of layers, called Continuous Normalizing Flows, whose potential is yet to fully explore. Overall, normalizing flows are an exciting research area which will continue over the next couple of years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Dinh, L., Sohl-Dickstein, J., and Bengio, S. (2017). Density estimation using Real NVP, In: 5th International Conference on Learning Representations, ICLR 2017. [Link](https://arxiv.org/abs/1605.08803)\n",
    "\n",
    "[2] Kingma, D. P., and Dhariwal, P. (2018). Glow: Generative Flow with Invertible 1x1 Convolutions, In: Advances in Neural Information Processing Systems, vol. 31, pp. 10215--10224. [Link](http://papers.nips.cc/paper/8224-glow-generative-flow-with-invertible-1x1-convolutions.pdf)\n",
    "\n",
    "[3] Ho, J., Chen, X., Srinivas, A., Duan, Y., and Abbeel, P. (2019). Flow++: Improving Flow-Based Generative Models with Variational Dequantization and Architecture Design, in Proceedings of the 36th International Conference on Machine Learning, vol. 97, pp. 27222730. [Link](https://arxiv.org/abs/1902.00275)\n",
    "\n",
    "[4] Durkan, C., Bekasov, A., Murray, I., and Papamakarios, G. (2019). Neural Spline Flows, In: Advances in Neural Information Processing Systems, pp. 75097520. [Link](http://papers.neurips.cc/paper/8969-neural-spline-flows.pdf)\n",
    "\n",
    "[5] Hoogeboom, E., Cohen, T. S., and Tomczak, J. M. (2020). Learning Discrete Distributions by Dequantization, arXiv preprint arXiv2001.11235v1. [Link](https://arxiv.org/abs/2001.11235)\n",
    "\n",
    "[6] Lippe, P., and Gavves, E. (2021). Categorical Normalizing Flows via Continuous Transformations, In: International Conference on Learning Representations, ICLR 2021. [Link](https://openreview.net/pdf?id=-GLNZeVDuik)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[![Star our repository](https://img.shields.io/static/v1.svg?logo=star&label=&message=Star%20Our%20Repository&color=yellow)](https://github.com/phlippe/uvadlc_notebooks/)  If you found this tutorial helpful, consider -ing our repository.    \n",
    "[![Ask questions](https://img.shields.io/static/v1.svg?logo=star&label=&message=Ask%20Questions&color=9cf)](https://github.com/phlippe/uvadlc_notebooks/issues)  For any questions, typos, or bugs that you found, please raise an issue on GitHub. \n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
